import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st
import re
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
from collections import defaultdict
import pickle
import os

class FastSimilarCaseSearch:
    def __init__(self, csv_path):
        """ë¹ ë¥¸ ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰ê¸° ì´ˆê¸°í™”"""
        self.csv_path = csv_path
        self.cache_file = 'similarity_cache.pkl'
        self.load_or_create_cache()
    
    def load_or_create_cache(self):
        """ìºì‹œ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±"""
        if os.path.exists(self.cache_file):
            try:
                with open(self.cache_file, 'rb') as f:
                    cache_data = pickle.load(f)
                    self.df = cache_data['df']
                    self.vectorizer = cache_data['vectorizer']
                    self.tfidf_matrix = cache_data['tfidf_matrix']
                st.success("âœ… ìºì‹œì—ì„œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
            except:
                self.create_cache()
        else:
            self.create_cache()
    
    def create_cache(self):
        """ìºì‹œ ìƒì„±"""
        with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘... (ì²˜ìŒ ì‹¤í–‰ì‹œ ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤)"):
            # ë°ì´í„° ë¡œë“œ (low_memory=Falseë¡œ ê²½ê³  ì œê±°)
            self.df = pd.read_csv(self.csv_path, encoding='cp949', low_memory=False)
            self.preprocess_data()
            self.create_similarity_matrix()
            
            # ìºì‹œ ì €ì¥
            cache_data = {
                'df': self.df,
                'vectorizer': self.vectorizer,
                'tfidf_matrix': self.tfidf_matrix
            }
            with open(self.cache_file, 'wb') as f:
                pickle.dump(cache_data, f)
            st.success("âœ… ìºì‹œ ìƒì„± ì™„ë£Œ!")
    
    def preprocess_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬ (ìµœì í™”)"""
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        self.df.columns = self.df.columns.str.strip()
        
        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        self.df = self.df.fillna('')
        
        # í…ìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬ (í•„ìš”í•œ ì»¬ëŸ¼ë§Œ)
        text_columns = ['ì‚¬ê³ ì„¤ëª…', 'ìƒí’ˆë¶„ë¥˜ëª…', 'ì‚¬ê³ ìœ í˜•ëª…']
        for col in text_columns:
            if col in self.df.columns:
                self.df[col] = self.df[col].astype(str).str.strip()
        
        # ê¸ˆì•¡ ë°ì´í„° ì •ë¦¬
        amount_columns = ['ì›í™”ì‚¬ê³ ê¸ˆì•¡', 'ì›í™”ë³´í—˜ê¸ˆì•¡']
        for col in amount_columns:
            if col in self.df.columns:
                self.df[col] = pd.to_numeric(self.df[col], errors='coerce').fillna(0)
    
    def create_similarity_matrix(self):
        """ìœ ì‚¬ë„ í–‰ë ¬ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
        # í…ìŠ¤íŠ¸ ë°ì´í„° ê²°í•© (ë” í’ë¶€í•œ ì •ë³´ í¬í•¨)
        text_data = []
        for idx, row in self.df.iterrows():
            # ì‚¬ê³ ì„¤ëª…ì„ ìš°ì„ ì ìœ¼ë¡œ, ìƒí’ˆë¶„ë¥˜ì™€ ì‚¬ê³ ìœ í˜•ë„ í¬í•¨
            description = str(row.get('ì‚¬ê³ ì„¤ëª…', '')).strip()
            product_category = str(row.get('ìƒí’ˆë¶„ë¥˜ëª…', '')).strip()
            case_type = str(row.get('ì‚¬ê³ ìœ í˜•ëª…', '')).strip()
            product_name = str(row.get('ìƒí’ˆëª…', '')).strip()
            
            # ì‚¬ê³ ì„¤ëª…ì´ ìˆëŠ” ê²½ìš° ìš°ì„ , ì—†ìœ¼ë©´ ë‹¤ë¥¸ ì •ë³´ í™œìš©
            if description and description != 'nan':
                text = f"{description} {product_category} {case_type}"
            else:
                text = f"{product_category} {case_type} {product_name}"
            
            text_data.append(text)
        
        # TF-IDF ë²¡í„°í™” (ë” ì •í™•í•œ ì„¤ì •)
        self.vectorizer = TfidfVectorizer(
            max_features=2000,  # íŠ¹ì„± ìˆ˜ ë” ì¦ê°€
            stop_words=None,
            ngram_range=(1, 4),  # n-gram ë²”ìœ„ ë” ì¦ê°€
            min_df=1,  # ìµœì†Œ ë¬¸ì„œ ë¹ˆë„ ê°ì†Œ
            max_df=0.98,  # ë” ê´€ëŒ€í•˜ê²Œ
            analyzer='word',
            token_pattern=r'(?u)\b\w+\b'  # í•œê¸€ í¬í•¨
        )
        
        self.tfidf_matrix = self.vectorizer.fit_transform(text_data)
    
    def search_similar_cases_by_category(self, query_text, currency_code=None, amount=None, 
                                       payment_method=None, top_k_per_category=1):
        """ì‹¬ì‚¬í•­ëª©ë³„ë¡œ ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰ (ìµœì í™”)"""
        # ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ë²¡í„°í™”
        query_vector = self.vectorizer.transform([query_text])
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()
        
        # ì‹¬ì‚¬í•­ëª©ë³„ë¡œ ê·¸ë£¹í™”
        category_results = defaultdict(list)
        
        # ìƒìœ„ 500ê°œë§Œ ì²˜ë¦¬ (ë” ë§ì€ í›„ë³´)
        top_indices = np.argsort(similarities)[-500:][::-1]
        
        for idx in top_indices:
            row = self.df.iloc[idx]
            category = row.get('ì‹¬ì‚¬í•­ëª©ëª…', 'ê¸°íƒ€')
            similarity = similarities[idx]
            
            # í•„í„°ë§ ì¡°ê±´ ì ìš©
            if currency_code and str(row.get('ì‚¬ê³ í†µí™”ì½”ë“œ_ZZ067', '')).strip() != str(currency_code).strip():
                continue
                
            if amount and amount > 0:
                case_amount = row.get('ì›í™”ì‚¬ê³ ê¸ˆì•¡', 0)
                if case_amount > 0:
                    # ê¸ˆì•¡ ë²”ìœ„ í•„í„°ë§ (ë” ê´€ëŒ€í•˜ê²Œ - 100% ì´ë‚´)
                    amount_diff = abs(case_amount - amount) / amount
                    if amount_diff > 1.0:
                        continue
            
            # ê²°ì œë°©ë²• í•„í„°ë§ ì œê±°
            pass
            
            # ì‚¬ê³ ì„¤ëª… ê¸¸ì´ë¥¼ ê³ ë ¤í•œ ê°€ì¤‘ì¹˜ ê³„ì‚°
            description = str(row.get('ì‚¬ê³ ì„¤ëª…', '')).strip()
            description_length = len(description) if description and description != 'nan' else 0
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ ë³´ë„ˆìŠ¤ (ì¿¼ë¦¬ì™€ ì‚¬ê³ ì„¤ëª…ì— ê³µí†µ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë³´ë„ˆìŠ¤)
            query_lower = query_text.lower()
            desc_lower = description.lower()
            keyword_bonus = 0
            
            # ì£¼ìš” í‚¤ì›Œë“œë“¤ë¡œ ë§¤ì¹­ í™•ì¸
            keywords = query_lower.split()
            for keyword in keywords:
                if len(keyword) > 2 and keyword in desc_lower:  # 2ê¸€ì ì´ìƒ í‚¤ì›Œë“œë§Œ
                    keyword_bonus += 0.05
            
            # ì‚¬ê³ ì„¤ëª…ì´ ê¸¸ìˆ˜ë¡ ìœ ì‚¬ë„ì— ë³´ë„ˆìŠ¤ ì ìˆ˜ ì¶”ê°€ (ìµœëŒ€ 0.1)
            description_bonus = min(description_length / 1000, 0.1) if description_length > 50 else 0
            adjusted_similarity = similarity + description_bonus + keyword_bonus
            
            result = {
                'index': idx,
                'similarity': similarity,
                'adjusted_similarity': adjusted_similarity,
                'ë³´ìƒíŒŒì¼ë²ˆí˜¸': row.get('ë³´ìƒíŒŒì¼ë²ˆí˜¸_x', ''),
                'ì‚¬ê³ ë²ˆí˜¸': row.get('ì‚¬ê³ ë²ˆí˜¸', ''),
                'ì‹¬ì‚¬í•­ëª©ëª…': category,
                'ì‚¬ê³ ì„¤ëª…': description,
                'ì›í™”ì‚¬ê³ ê¸ˆì•¡': row.get('ì›í™”ì‚¬ê³ ê¸ˆì•¡', 0),
                'ìˆ˜ì¶œìƒí’ˆì½”ë“œ': row.get('ìˆ˜ì¶œë³´í—˜ê³„ì•½ë²ˆí˜¸', ''),
                'ì‚¬ê³ ìœ í˜•': row.get('ì‚¬ê³ ìœ í˜•ëª…', ''),
                'ì—…ì¢…í•œê¸€ëª…': row.get('ìƒí’ˆë¶„ë¥˜ëª…', ''),
                'ì‚¬ê³ í†µí™”ì½”ë“œ': row.get('ì‚¬ê³ í†µí™”ì½”ë“œ_ZZ067', ''),
                'ê²°ì œë°©ë²•ì½”ë“œ': row.get('ê²°ì œë°©ë²•', ''),
                'ì›í™”ë³´í—˜ê¸ˆì•¡': row.get('ì›í™”ë³´í—˜ê¸ˆì•¡', 0),
                'ë¶€ë³´ìœ¨': row.get('ë¶€ë³´ìœ¨', ''),
                'ë³´í—˜ì„±ë¦½ì¼ì': row.get('ë³´í—˜ì„±ë¦½ì¼ì', ''),
                'ì‚¬ê³ ì ‘ìˆ˜ì¼ì': row.get('ì‚¬ê³ ì ‘ìˆ˜ì¼ì', '')
            }
            
            category_results[category].append(result)
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¡°ì •ëœ ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ ê²°ê³¼ë§Œ ì„ íƒ
        final_results = {}
        for category, results in category_results.items():
            results.sort(key=lambda x: x['adjusted_similarity'], reverse=True)
            # ìœ ì‚¬ë„ ì„ê³„ê°’ì„ ë” ë‚®ì¶¤ (0.01 ì´ìƒ)
            filtered_results = [r for r in results if r['similarity'] >= 0.01]
            final_results[category] = filtered_results[:top_k_per_category]
        
        return final_results
    
    def get_statistics_by_category(self, category_column='ì‹¬ì‚¬í•­ëª©ëª…'):
        """ì‹¬ì‚¬í•­ëª©ë³„ í†µê³„"""
        if category_column not in self.df.columns:
            return None
        
        stats = self.df[category_column].value_counts()
        return stats
    
    def format_amount(self, amount):
        """ê¸ˆì•¡ í¬ë§·íŒ…"""
        if pd.isna(amount) or amount == 0:
            return "0ì›"
        return f"{amount:,.0f}ì›"
    
    def format_date(self, date_value):
        """ë‚ ì§œ í¬ë§·íŒ…"""
        if pd.isna(date_value) or date_value == '':
            return "ì •ë³´ ì—†ìŒ"
        try:
            if isinstance(date_value, str):
                # YYYYMMDD í˜•ì‹ìœ¼ë¡œ ê°€ì •
                if len(str(date_value)) == 8:
                    return f"{str(date_value)[:4]}-{str(date_value)[4:6]}-{str(date_value)[6:8]}"
            return str(date_value)
        except:
            return str(date_value)

def main():
    st.set_page_config(
        page_title="ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰",
        page_icon="ğŸ”",
        layout="wide"
    )
    
    st.title("ğŸ” ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰ (ë¹ ë¥¸ ë²„ì „)")
    st.markdown("---")
    
    # ë°ì´í„° ë¡œë“œ
    try:
        search_engine = FastSimilarCaseSearch('Data/case.csv')
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return
    
    # ì‚¬ì´ë“œë°” - ê²€ìƒ‰ ì¡°ê±´
    st.sidebar.header("ğŸ” ê²€ìƒ‰ ì¡°ê±´")
    
    # í…ìŠ¤íŠ¸ ê²€ìƒ‰
    query_text = st.sidebar.text_area(
        "ì‚¬ê³  ì„¤ëª… ë˜ëŠ” í‚¤ì›Œë“œ",
        placeholder="ì‚¬ê³  ë‚´ìš©ì„ ìì„¸íˆ ì…ë ¥í•´ì£¼ì„¸ìš”...",
        height=100
    )
    
    # í†µí™” ì½”ë“œ
    currency_options = [''] + sorted(list(search_engine.df['ì‚¬ê³ í†µí™”ì½”ë“œ_ZZ067'].unique()))
    selected_currency = st.sidebar.selectbox("í†µí™” ì½”ë“œ", currency_options)
    
    # ê¸ˆì•¡ ë²”ìœ„
    amount = st.sidebar.number_input(
        "ì‚¬ê³  ê¸ˆì•¡ (ì›)",
        min_value=0,
        value=0,
        step=1000000
    )
    
    # ê²°ì œ ë°©ë²• (ì œê±°ë¨)
    selected_payment = None
    
    # ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ ìˆ˜
    results_per_category = st.sidebar.slider(
        "ì‹¬ì‚¬í•­ëª©ë³„ ê²°ê³¼ ìˆ˜",
        min_value=1,
        max_value=5,
        value=1
    )
    
    # ê²€ìƒ‰ ë²„íŠ¼
    search_button = st.sidebar.button("ğŸ” ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰", type="primary")
    
    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ (ì‹¬ì‚¬í•­ëª©ë³„)")
        
        if search_button and query_text.strip():
            with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                results = search_engine.search_similar_cases_by_category(
                    query_text=query_text,
                    currency_code=selected_currency if selected_currency else None,
                    amount=amount if amount > 0 else None,
                    payment_method=selected_payment if selected_payment else None,
                    top_k_per_category=results_per_category
                )
            
            if results:
                total_cases = sum(len(cases) for cases in results.values())
                st.success(f"âœ… {len(results)}ê°œ ì‹¬ì‚¬í•­ëª©ì—ì„œ ì´ {total_cases}ê°œì˜ ìœ ì‚¬ì‚¬ë¡€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                
                # ì‹¬ì‚¬í•­ëª©ë³„ë¡œ íƒ­ ìƒì„±
                if len(results) > 1:
                    tab_names = list(results.keys())
                    tabs = st.tabs(tab_names)
                    
                    for i, (category, cases) in enumerate(results.items()):
                        with tabs[i]:
                            st.write(f"**{category}** ì¹´í…Œê³ ë¦¬ì—ì„œ ì°¾ì€ ìœ ì‚¬ì‚¬ë¡€:")
                            
                            for j, case in enumerate(cases, 1):
                                with st.expander(f"ì‚¬ë¡€ {j}: ìœ ì‚¬ë„ {case['adjusted_similarity']:.3f} (ì›ë³¸: {case['similarity']:.3f})"):
                                    col_a, col_b = st.columns(2)
                                    
                                    with col_a:
                                        st.write(f"**ë³´ìƒíŒŒì¼ë²ˆí˜¸:** {case['ë³´ìƒíŒŒì¼ë²ˆí˜¸']}")
                                        st.write(f"**ì‚¬ê³ ë²ˆí˜¸:** {case['ì‚¬ê³ ë²ˆí˜¸']}")
                                        st.write(f"**ì‹¬ì‚¬í•­ëª©ëª…:** {case['ì‹¬ì‚¬í•­ëª©ëª…']}")
                                        st.write(f"**ì‚¬ê³ ê¸ˆì•¡:** {search_engine.format_amount(case['ì›í™”ì‚¬ê³ ê¸ˆì•¡'])}")
                                        st.write(f"**ë³´í—˜ê¸ˆì•¡:** {search_engine.format_amount(case['ì›í™”ë³´í—˜ê¸ˆì•¡'])}")
                                        st.write(f"**í†µí™”ì½”ë“œ:** {case['ì‚¬ê³ í†µí™”ì½”ë“œ']}")
                                    
                                    with col_b:
                                        st.write(f"**ìˆ˜ì¶œìƒí’ˆì½”ë“œ:** {case['ìˆ˜ì¶œìƒí’ˆì½”ë“œ']}")
                                        st.write(f"**ì‚¬ê³ ìœ í˜•:** {case['ì‚¬ê³ ìœ í˜•']}")
                                        st.write(f"**ì—…ì¢…:** {case['ì—…ì¢…í•œê¸€ëª…']}")
                                        st.write(f"**ê²°ì œë°©ë²•:** {case['ê²°ì œë°©ë²•ì½”ë“œ']}")
                                        st.write(f"**ë¶€ë³´ìœ¨:** {case['ë¶€ë³´ìœ¨']}%")
                                        st.write(f"**ë³´í—˜ì„±ë¦½ì¼:** {search_engine.format_date(case['ë³´í—˜ì„±ë¦½ì¼ì'])}")
                                    
                                    st.write("**ì‚¬ê³ ì„¤ëª…:**")
                                    st.text_area(
                                        f"ì‚¬ê³ ì„¤ëª…_{category}_{j}",
                                        value=case['ì‚¬ê³ ì„¤ëª…'],
                                        height=100,
                                        disabled=True,
                                        key=f"desc_{category}_{j}"
                                    )
                else:
                    # ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ì¸ ê²½ìš°
                    category, cases = list(results.items())[0]
                    st.write(f"**{category}** ì¹´í…Œê³ ë¦¬ì—ì„œ ì°¾ì€ ìœ ì‚¬ì‚¬ë¡€:")
                    
                    for j, case in enumerate(cases, 1):
                        with st.expander(f"ì‚¬ë¡€ {j}: ìœ ì‚¬ë„ {case['adjusted_similarity']:.3f} (ì›ë³¸: {case['similarity']:.3f})"):
                            col_a, col_b = st.columns(2)
                            
                            with col_a:
                                st.write(f"**ë³´ìƒíŒŒì¼ë²ˆí˜¸:** {case['ë³´ìƒíŒŒì¼ë²ˆí˜¸']}")
                                st.write(f"**ì‚¬ê³ ë²ˆí˜¸:** {case['ì‚¬ê³ ë²ˆí˜¸']}")
                                st.write(f"**ì‹¬ì‚¬í•­ëª©ëª…:** {case['ì‹¬ì‚¬í•­ëª©ëª…']}")
                                st.write(f"**ì‚¬ê³ ê¸ˆì•¡:** {search_engine.format_amount(case['ì›í™”ì‚¬ê³ ê¸ˆì•¡'])}")
                                st.write(f"**ë³´í—˜ê¸ˆì•¡:** {search_engine.format_amount(case['ì›í™”ë³´í—˜ê¸ˆì•¡'])}")
                                st.write(f"**í†µí™”ì½”ë“œ:** {case['ì‚¬ê³ í†µí™”ì½”ë“œ']}")
                            
                            with col_b:
                                st.write(f"**ìˆ˜ì¶œìƒí’ˆì½”ë“œ:** {case['ìˆ˜ì¶œìƒí’ˆì½”ë“œ']}")
                                st.write(f"**ì‚¬ê³ ìœ í˜•:** {case['ì‚¬ê³ ìœ í˜•']}")
                                st.write(f"**ì—…ì¢…:** {case['ì—…ì¢…í•œê¸€ëª…']}")
                                st.write(f"**ê²°ì œë°©ë²•:** {case['ê²°ì œë°©ë²•ì½”ë“œ']}")
                                st.write(f"**ë¶€ë³´ìœ¨:** {case['ë¶€ë³´ìœ¨']}%")
                                st.write(f"**ë³´í—˜ì„±ë¦½ì¼:** {search_engine.format_date(case['ë³´í—˜ì„±ë¦½ì¼ì'])}")
                            
                            st.write("**ì‚¬ê³ ì„¤ëª…:**")
                            st.text_area(
                                f"ì‚¬ê³ ì„¤ëª…_{category}_{j}",
                                value=case['ì‚¬ê³ ì„¤ëª…'],
                                height=100,
                                disabled=True,
                                key=f"desc_{category}_{j}"
                            )
            else:
                st.warning("âš ï¸ ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ìœ ì‚¬ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        elif search_button:
            st.warning("âš ï¸ ê²€ìƒ‰í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with col2:
        st.subheader("ğŸ“ˆ í†µê³„ ì •ë³´")
        
        # ì‹¬ì‚¬í•­ëª©ë³„ í†µê³„
        stats = search_engine.get_statistics_by_category()
        if stats is not None:
            st.write("**ì‹¬ì‚¬í•­ëª©ë³„ ì‚¬ë¡€ ìˆ˜:**")
            for category, count in stats.head(10).items():
                st.write(f"â€¢ {category}: {count}ê±´")
            
            # ì°¨íŠ¸ ìƒì„±
            fig = px.pie(
                values=stats.head(10).values,
                names=stats.head(10).index,
                title="ì‹¬ì‚¬í•­ëª©ë³„ ë¶„í¬"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # ì „ì²´ í†µê³„
        st.write("**ì „ì²´ í†µê³„:**")
        st.write(f"â€¢ ì´ ì‚¬ë¡€ ìˆ˜: {len(search_engine.df):,}ê±´")
        st.write(f"â€¢ í‰ê·  ì‚¬ê³ ê¸ˆì•¡: {search_engine.format_amount(search_engine.df['ì›í™”ì‚¬ê³ ê¸ˆì•¡'].mean())}")
        st.write(f"â€¢ ìµœëŒ€ ì‚¬ê³ ê¸ˆì•¡: {search_engine.format_amount(search_engine.df['ì›í™”ì‚¬ê³ ê¸ˆì•¡'].max())}")
        
        # í†µí™”ë³„ í†µê³„
        currency_stats = search_engine.df['ì‚¬ê³ í†µí™”ì½”ë“œ_ZZ067'].value_counts()
        st.write("**í†µí™”ë³„ ë¶„í¬:**")
        for currency, count in currency_stats.head(5).items():
            st.write(f"â€¢ {currency}: {count}ê±´")

if __name__ == "__main__":
    main() 