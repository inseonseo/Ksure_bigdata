import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import torch
from transformers import AutoModel, AutoTokenizer
from collections import Counter
import pickle
import warnings
import re
import time
warnings.filterwarnings('ignore')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë³´í—˜ì‚¬ê³  íŒì • ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="ğŸ“‹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ê¹”ë”í•œ CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        background-color: #f8f9fa;
        padding: 2rem;
        border-radius: 10px;
        border-left: 5px solid #007bff;
        margin-bottom: 2rem;
    }
    
    .metric-box {
        background-color: white;
        padding: 1.5rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #007bff;
        text-align: center;
    }
    
    .prediction-box {
        background-color: #e3f2fd;
        padding: 2rem;
        border-radius: 10px;
        border: 2px solid #2196f3;
        text-align: center;
        margin: 1rem 0;
    }
    
    .success-box {
        background-color: #e8f5e8;
        border: 2px solid #4caf50;
    }
    
    .error-box {
        background-color: #ffebee;
        border: 2px solid #f44336;
    }
    
    .warning-box {
        background-color: #fff3e0;
        border: 2px solid #ff9800;
    }
    
    .case-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #dee2e6;
        margin: 0.5rem 0;
    }
    
    .similarity-bar {
        background-color: #007bff;
        height: 20px;
        border-radius: 10px;
        margin: 5px 0;
    }
</style>
""", unsafe_allow_html=True)

class PracticalInsuranceSystem:
    def __init__(self):
        self.model = None
        self.kosimcse_model = None
        self.kosimcse_tokenizer = None
        self.text_vectorizer = None
        self.label_encoders = {}
        self.feature_importance = None
        
        # ì‹¤í—˜ì„ í†µí•´ ìµœì í™”ëœ ê³ ì • ê°€ì¤‘ì¹˜
        self.optimal_weights = {
            'text_similarity': 0.45,
            'accident_type': 0.25,
            'country': 0.15,
            'amount_similarity': 0.10,
            'insurance_type': 0.05
        }
        
        # ìºì‹œ ê´€ë¦¬
        self.embeddings_cache = {}
        self.similarity_cache = {}
    
    @st.cache_resource
    def load_kosimcse_model(_self):
        """KoSimCSE ëª¨ë¸ ë¡œë“œ (ìºì‹œ ì ìš©)"""
        try:
            model_name = "BM-K/KoSimCSE-roberta-multitask"
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = AutoModel.from_pretrained(model_name)
            model.eval()
            return model, tokenizer
        except Exception as e:
            st.error(f"AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None, None
    
    def initialize_ai_model(self):
        """AI ëª¨ë¸ ì´ˆê¸°í™”"""
        if self.kosimcse_model is None:
            with st.spinner("AI ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘..."):
                self.kosimcse_model, self.kosimcse_tokenizer = self.load_kosimcse_model()
        return self.kosimcse_model is not None
    
    def preprocess_text(self, text):
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        if pd.isna(text) or text == '':
            return ""
        
        text = str(text).strip()
        
        # ì˜ë¯¸ì—†ëŠ” í…ìŠ¤íŠ¸ í•„í„°ë§
        meaningless_patterns = [
            r'^ì„¤ëª…ì—†ìŒ$', r'^ì²¨ë¶€íŒŒì¼ì°¸ê³ $', r'^í•´ë‹¹ì—†ìŒ$', r'^-$',
            r'^ì—†ìŒ$', r'^ê¸°íƒ€$', r'^ë¯¸ìƒ$'
        ]
        
        for pattern in meaningless_patterns:
            if re.match(pattern, text, re.IGNORECASE):
                return ""
        
        return text
    
    def get_text_embeddings(self, texts, batch_size=4):
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (ë°°ì¹˜ í¬ê¸° ì¤„ì—¬ì„œ ì†ë„ ê°œì„ )"""
        if not self.initialize_ai_model():
            return None
        
        processed_texts = [self.preprocess_text(text) for text in texts]
        valid_texts = [text for text in processed_texts if text]
        
        if not valid_texts:
            return None
        
        embeddings = []
        
        try:
            for i in range(0, len(valid_texts), batch_size):
                batch_texts = valid_texts[i:i + batch_size]
                
                inputs = self.kosimcse_tokenizer(
                    batch_texts,
                    padding=True,
                    truncation=True,
                    max_length=256,  # ê¸¸ì´ ì œí•œìœ¼ë¡œ ì†ë„ ê°œì„ 
                    return_tensors="pt"
                )
                
                with torch.no_grad():
                    outputs = self.kosimcse_model(**inputs)
                    batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()
                    embeddings.extend(batch_embeddings)
            
            return np.array(embeddings)
            
        except Exception as e:
            st.error(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None
    
    def calculate_similarity_scores(self, query_case, candidates_df, max_candidates=100):
        """ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚° (ìµœì í™”ë¨)"""
        # í›„ë³´ ìˆ˜ ì œí•œìœ¼ë¡œ ì†ë„ ê°œì„ 
        if len(candidates_df) > max_candidates:
            candidates_df = candidates_df.sample(n=max_candidates, random_state=42)
        
        similarities = []
        
        # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°
        query_text = query_case.get('ì‚¬ê³ ì„¤ëª…', '')
        if query_text and len(query_text) > 10:
            candidate_texts = candidates_df['ì‚¬ê³ ì„¤ëª…'].tolist()
            
            # AI ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
            all_texts = [query_text] + candidate_texts
            embeddings = self.get_text_embeddings(all_texts)
            
            if embeddings is not None and len(embeddings) > 1:
                query_embedding = embeddings[0:1]
                candidate_embeddings = embeddings[1:]
                text_similarities = cosine_similarity(query_embedding, candidate_embeddings)[0]
            else:
                # í´ë°±: ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
                text_similarities = []
                query_words = set(query_text.lower().split())
                for candidate_text in candidate_texts:
                    if pd.notna(candidate_text):
                        candidate_words = set(str(candidate_text).lower().split())
                        if query_words and candidate_words:
                            jaccard_sim = len(query_words.intersection(candidate_words)) / len(query_words.union(candidate_words))
                            text_similarities.append(jaccard_sim)
                        else:
                            text_similarities.append(0.0)
                    else:
                        text_similarities.append(0.0)
                text_similarities = np.array(text_similarities)
        else:
            text_similarities = np.zeros(len(candidates_df))
        
        # í†µí•© ìœ ì‚¬ë„ ê³„ì‚°
        for i, (idx, candidate) in enumerate(candidates_df.iterrows()):
            score = 0.0
            weights = self.optimal_weights
            
            # 1. í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
            if i < len(text_similarities):
                score += weights['text_similarity'] * text_similarities[i]
            
            # 2. ì‚¬ê³ ìœ í˜• ìœ ì‚¬ë„
            if query_case.get('ì‚¬ê³ ìœ í˜•ëª…') == candidate.get('ì‚¬ê³ ìœ í˜•ëª…'):
                score += weights['accident_type']
            elif self._group_accident_type(query_case.get('ì‚¬ê³ ìœ í˜•ëª…')) == self._group_accident_type(candidate.get('ì‚¬ê³ ìœ í˜•ëª…')):
                score += weights['accident_type'] * 0.7
            
            # 3. ìˆ˜ì…êµ­ ì¼ì¹˜
            if query_case.get('ìˆ˜ì…êµ­') == candidate.get('ìˆ˜ì…êµ­'):
                score += weights['country']
            
            # 4. ê¸ˆì•¡ëŒ€ ìœ ì‚¬ë„
            query_amount = query_case.get('ì›í™”ì‚¬ê³ ê¸ˆì•¡', 0)
            candidate_amount = candidate.get('ì›í™”ì‚¬ê³ ê¸ˆì•¡', 0)
            
            if query_amount > 0 and candidate_amount > 0:
                amount_ratio = min(query_amount, candidate_amount) / max(query_amount, candidate_amount)
                score += weights['amount_similarity'] * amount_ratio
            
            # 5. ë³´í—˜ì¢…ëª© ì¼ì¹˜
            if query_case.get('ë³´í—˜ì¢…ëª©') == candidate.get('ë³´í—˜ì¢…ëª©'):
                score += weights['insurance_type']
            
            similarities.append((score, text_similarities[i] if i < len(text_similarities) else 0.0, candidate))
        
        # ì •ë ¬ í›„ ë°˜í™˜
        similarities.sort(key=lambda x: x[0], reverse=True)
        return similarities
    
    def _group_accident_type(self, accident_type):
        """ì‚¬ê³ ìœ í˜• ê·¸ë£¹í™”"""
        if pd.isna(accident_type):
            return 'ê¸°íƒ€'
        
        if 'ì‹ ìš©ìœ„í—˜' in accident_type:
            if 'ì§€ê¸‰ì§€ì²´' in accident_type:
                return 'ì‹ ìš©ìœ„í—˜-ì§€ê¸‰ì§€ì²´'
            elif 'íŒŒì‚°' in accident_type:
                return 'ì‹ ìš©ìœ„í—˜-íŒŒì‚°'
            elif 'ì§€ê¸‰ë¶ˆëŠ¥' in accident_type or 'ì§€ê¸‰ê±°ì ˆ' in accident_type:
                return 'ì‹ ìš©ìœ„í—˜-ì§€ê¸‰ë¶ˆëŠ¥/ê±°ì ˆ'
            else:
                return 'ì‹ ìš©ìœ„í—˜-ê¸°íƒ€'
        elif 'ë¹„ìƒìœ„í—˜' in accident_type:
            return 'ë¹„ìƒìœ„í—˜'
        elif 'ê²€ì—­ìœ„í—˜' in accident_type:
            return 'ê²€ì—­ìœ„í—˜'
        else:
            return 'ê¸°íƒ€ìœ„í—˜'
    
    def train_prediction_model(self, df):
        """ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€"""
        try:
            # íŠ¹ì„± ì „ì²˜ë¦¬
            df_processed = df.copy()
            
            # ê¸ˆì•¡ êµ¬ê°„ ìƒì„±
            df_processed['ê¸ˆì•¡êµ¬ê°„'] = pd.cut(
                df_processed['ì›í™”ì‚¬ê³ ê¸ˆì•¡'].fillna(0),
                bins=[0, 10000000, 50000000, 100000000, 500000000, float('inf')],
                labels=['1ì²œë§Œì›ë¯¸ë§Œ', '1ì²œë§Œ-5ì²œë§Œì›', '5ì²œë§Œ-1ì–µì›', '1ì–µ-5ì–µì›', '5ì–µì›ì´ìƒ']
            )
            
            # ì‚¬ê³ ìœ í˜• ê·¸ë£¹í™”
            df_processed['ì‚¬ê³ ìœ í˜•ê·¸ë£¹'] = df_processed['ì‚¬ê³ ìœ í˜•ëª…'].apply(self._group_accident_type)
            
            # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
            categorical_features = ['ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©', 'ì‚¬ê³ ìœ í˜•ê·¸ë£¹', 'ê¸ˆì•¡êµ¬ê°„', 'ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…']
            
            for feature in categorical_features:
                le = LabelEncoder()
                df_processed[f'{feature}_encoded'] = le.fit_transform(df_processed[feature].fillna('Unknown'))
                self.label_encoders[feature] = le
            
            # íŠ¹ì„± ì„ íƒ
            feature_columns = [f'{feature}_encoded' for feature in categorical_features]
            feature_columns.extend(['ì›í™”ì‚¬ê³ ê¸ˆì•¡'])
            
            X = df_processed[feature_columns].fillna(0)
            y = df_processed['íŒì •êµ¬ë¶„']
            
            # ëª¨ë¸ í•™ìŠµ
            self.model = RandomForestClassifier(
                n_estimators=50,  # íŠ¸ë¦¬ ìˆ˜ ì¤„ì—¬ì„œ ì†ë„ ê°œì„ 
                max_depth=8,
                random_state=42,
                class_weight='balanced',
                n_jobs=-1  # ë³‘ë ¬ ì²˜ë¦¬
            )
            
            # êµì°¨ ê²€ì¦
            cv_scores = cross_val_score(self.model, X, y, cv=5, scoring='accuracy')
            
            # ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ
            self.model.fit(X, y)
            
            # íŠ¹ì„± ì¤‘ìš”ë„
            self.feature_importance = pd.DataFrame({
                'feature': X.columns,
                'importance': self.model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            return {
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std(),
                'feature_importance': self.feature_importance
            }
            
        except Exception as e:
            st.error(f"ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
            return None

@st.cache_data
def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    try:
        df = pd.read_csv('data/design.csv', encoding='cp949')
        
        # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
        date_columns = ['íŒì •ì¼', 'íŒì •ê²°ì¬ì¼', 'ì‚¬ê³ ì ‘ìˆ˜ì¼ì', 'ë³´í—˜ê¸ˆì²­êµ¬ì¼']
        for col in date_columns:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce')
        
        # ê¸ˆì•¡ ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜
        amount_columns = ['ì›í™”ì‚¬ê³ ê¸ˆì•¡', 'ì›í™”íŒì •ê¸ˆì•¡']
        for col in amount_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def create_main_dashboard(df):
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ"""
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“‹ ë³´í—˜ì‚¬ê³  íŒì • ë¶„ì„ ì‹œìŠ¤í…œ</h1>
        <p>AI ê¸°ë°˜ ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰ìœ¼ë¡œ ì‹ ì†í•˜ê³  ì •í™•í•œ íŒì • ì§€ì›</p>
    </div>
    """, unsafe_allow_html=True)
    
    # í•µì‹¬ ì§€í‘œ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="metric-box">
            <h3>ì „ì²´ ì‚¬ê³ </h3>
            <h2>{len(df):,}ê±´</h2>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        payment_rate = (df['íŒì •êµ¬ë¶„'] == 'ì§€ê¸‰').mean() * 100
        st.markdown(f"""
        <div class="metric-box">
            <h3>ì§€ê¸‰ ë¹„ìœ¨</h3>
            <h2>{payment_rate:.1f}%</h2>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        max_rounds = df['íŒì •íšŒì°¨'].max()
        st.markdown(f"""
        <div class="metric-box">
            <h3>ìµœëŒ€ íŒì •íšŒì°¨</h3>
            <h2>{max_rounds}íšŒ</h2>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        meaningful_desc = len(df[
            (df['ì‚¬ê³ ì„¤ëª…'].notna()) & 
            (df['ì‚¬ê³ ì„¤ëª…'].str.len() > 10) &
            (~df['ì‚¬ê³ ì„¤ëª…'].str.contains('ì„¤ëª…ì—†ìŒ|ì²¨ë¶€íŒŒì¼ì°¸ê³ |í•´ë‹¹ì—†ìŒ', na=False, case=False))
        ])
        desc_rate = meaningful_desc / len(df) * 100
        st.markdown(f"""
        <div class="metric-box">
            <h3>AI ë¶„ì„ ê°€ëŠ¥</h3>
            <h2>{desc_rate:.1f}%</h2>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # ì£¼ìš” ì°¨íŠ¸
    col1, col2 = st.columns(2)
    
    with col1:
        # ìˆ˜ì…êµ­ë³„ ìƒìœ„ 10ê°œ
        country_counts = df['ìˆ˜ì…êµ­'].value_counts().head(10)
        fig1 = px.bar(
            x=country_counts.values,
            y=country_counts.index,
            orientation='h',
            title="ìƒìœ„ 10ê°œêµ­ ì‚¬ê³  ë°œìƒ í˜„í™©",
            color_discrete_sequence=['#007bff']
        )
        fig1.update_layout(height=400, showlegend=False)
        st.plotly_chart(fig1, use_container_width=True)
    
    with col2:
        # íŒì •êµ¬ë¶„ë³„ ë¶„í¬
        decision_counts = df['íŒì •êµ¬ë¶„'].value_counts()
        colors = ['#28a745', '#dc3545', '#ffc107', '#6c757d']
        
        fig2 = px.pie(
            values=decision_counts.values,
            names=decision_counts.index,
            title="íŒì •êµ¬ë¶„ë³„ ë¶„í¬",
            color_discrete_sequence=colors
        )
        fig2.update_layout(height=400)
        st.plotly_chart(fig2, use_container_width=True)

def create_similarity_search_interface(system, df):
    """ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤"""
    st.subheader("ğŸ” ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰")
    
    # AI ëª¨ë¸ ìƒíƒœ
    model_ready = system.initialize_ai_model()
    if model_ready:
        st.success("âœ… AI í…ìŠ¤íŠ¸ ë¶„ì„ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
    else:
        st.warning("âš ï¸ AI ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€ - ê¸°ë³¸ ê²€ìƒ‰ ëª¨ë“œ")
    
    # ê²€ìƒ‰ í¼
    with st.form("search_form"):
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.write("**ğŸ“‹ ì‚¬ê³  ì •ë³´ ì…ë ¥**")
            
            input_country = st.selectbox(
                "ìˆ˜ì…êµ­:",
                options=df['ìˆ˜ì…êµ­'].value_counts().head(20).index
            )
            
            input_insurance = st.selectbox(
                "ë³´í—˜ì¢…ëª©:",
                options=df['ë³´í—˜ì¢…ëª©'].value_counts().head(10).index
            )
            
            input_accident_type = st.selectbox(
                "ì‚¬ê³ ìœ í˜•:",
                options=df['ì‚¬ê³ ìœ í˜•ëª…'].value_counts().head(10).index
            )
            
            input_amount = st.number_input(
                "ì‚¬ê³ ê¸ˆì•¡ (ì›):",
                min_value=0,
                value=50000000,
                step=1000000,
                format="%d"
            )
            
            input_description = st.text_area(
                "ì‚¬ê³ ì„¤ëª…:",
                placeholder="ì‚¬ê³ ì˜ êµ¬ì²´ì ì¸ ìƒí™©ì„ ì…ë ¥í•˜ì„¸ìš”...",
                height=120
            )
        
        with col2:
            st.write("**ğŸ”§ ê²€ìƒ‰ ì˜µì…˜**")
            
            # í•„í„° ì˜µì…˜
            filter_same_country = st.checkbox("ë™ì¼ ìˆ˜ì…êµ­ë§Œ", value=False)
            filter_same_type = st.checkbox("ë™ì¼ ì‚¬ê³ ìœ í˜•ë§Œ", value=False)
            filter_same_insurance = st.checkbox("ë™ì¼ ë³´í—˜ì¢…ëª©ë§Œ", value=False)
            
            max_results = st.slider("ìµœëŒ€ ê²°ê³¼ ìˆ˜:", 3, 10, 5)
            
            st.write("**âš–ï¸ í˜„ì¬ ê°€ì¤‘ì¹˜**")
            st.write("â€¢ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„: 45%")
            st.write("â€¢ ì‚¬ê³ ìœ í˜•: 25%")
            st.write("â€¢ ìˆ˜ì…êµ­: 15%")
            st.write("â€¢ ê¸ˆì•¡ìœ ì‚¬ë„: 10%")
            st.write("â€¢ ë³´í—˜ì¢…ëª©: 5%")
        
        submitted = st.form_submit_button("ğŸ” ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰", type="primary")
    
    if submitted:
        start_time = time.time()
        
        # ì…ë ¥ ë°ì´í„° êµ¬ì„±
        case_data = {
            'ìˆ˜ì…êµ­': input_country,
            'ë³´í—˜ì¢…ëª©': input_insurance,
            'ì‚¬ê³ ìœ í˜•ëª…': input_accident_type,
            'ì›í™”ì‚¬ê³ ê¸ˆì•¡': input_amount,
            'ì‚¬ê³ ì„¤ëª…': input_description
        }
        
        with st.spinner("ìœ ì‚¬ì‚¬ë¡€ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
            # í•„í„°ë§ ì ìš©
            search_df = df.copy()
            
            if filter_same_country:
                search_df = search_df[search_df['ìˆ˜ì…êµ­'] == input_country]
            if filter_same_type:
                search_df = search_df[search_df['ì‚¬ê³ ìœ í˜•ëª…'] == input_accident_type]
            if filter_same_insurance:
                search_df = search_df[search_df['ë³´í—˜ì¢…ëª©'] == input_insurance]
            
            # ì˜ë¯¸ìˆëŠ” ì„¤ëª…ì´ ìˆëŠ” ì‚¬ë¡€ ìš°ì„ 
            if input_description:
                meaningful_df = search_df[
                    (search_df['ì‚¬ê³ ì„¤ëª…'].notna()) & 
                    (search_df['ì‚¬ê³ ì„¤ëª…'].str.len() > 10) &
                    (~search_df['ì‚¬ê³ ì„¤ëª…'].str.contains('ì„¤ëª…ì—†ìŒ|ì²¨ë¶€íŒŒì¼ì°¸ê³ |í•´ë‹¹ì—†ìŒ', na=False, case=False))
                ]
                if len(meaningful_df) > 50:
                    search_df = meaningful_df
            
            # ìœ ì‚¬ë„ ê³„ì‚°
            similarities = system.calculate_similarity_scores(case_data, search_df, max_candidates=200)
            top_similar = similarities[:max_results]
            
            search_time = time.time() - start_time
        
        # ê²°ê³¼ í‘œì‹œ
        if top_similar:
            # ì˜ˆì¸¡ ê²°ê³¼
            similar_decisions = [case[2]['íŒì •êµ¬ë¶„'] for case in top_similar]
            decision_counts = Counter(similar_decisions)
            predicted_decision = decision_counts.most_common(1)[0][0]
            confidence = decision_counts[predicted_decision] / len(similar_decisions)
            
            # ì˜ˆì¸¡ ê²°ê³¼ ë°•ìŠ¤
            if predicted_decision == 'ì§€ê¸‰':
                box_class = "prediction-box success-box"
            elif predicted_decision == 'ë©´ì±…':
                box_class = "prediction-box error-box"
            else:
                box_class = "prediction-box warning-box"
            
            st.markdown(f"""
            <div class="{box_class}">
                <h2>ğŸ¯ ì˜ˆìƒ íŒì •: {predicted_decision}</h2>
                <p>ì‹ ë¢°ë„: {confidence:.1%} | ê²€ìƒ‰ ì‹œê°„: {search_time:.1f}ì´ˆ</p>
                <small>ìƒìœ„ {len(top_similar)}ê°œ ìœ ì‚¬ì‚¬ë¡€ ë¶„ì„ ê²°ê³¼</small>
            </div>
            """, unsafe_allow_html=True)
            
            # í†µê³„ ì°¨íŠ¸
            col1, col2 = st.columns(2)
            
            with col1:
                # íŒì •êµ¬ë¶„ ë¶„í¬
                decision_df = pd.DataFrame(list(decision_counts.items()), columns=['íŒì •êµ¬ë¶„', 'ê±´ìˆ˜'])
                fig_pred = px.pie(
                    decision_df,
                    values='ê±´ìˆ˜',
                    names='íŒì •êµ¬ë¶„',
                    title="ìœ ì‚¬ì‚¬ë¡€ íŒì •êµ¬ë¶„ ë¶„í¬",
                    color_discrete_sequence=['#28a745', '#dc3545', '#ffc107']
                )
                st.plotly_chart(fig_pred, use_container_width=True)
            
            with col2:
                # ìœ ì‚¬ë„ ì ìˆ˜ ë¶„í¬
                scores = [sim[0] for sim in top_similar]
                fig_sim = px.bar(
                    x=list(range(1, len(scores) + 1)),
                    y=scores,
                    title="ìœ ì‚¬ë„ ì ìˆ˜ ë¶„í¬",
                    labels={'x': 'ìˆœìœ„', 'y': 'ìœ ì‚¬ë„ ì ìˆ˜'},
                    color_discrete_sequence=['#007bff']
                )
                fig_sim.update_layout(showlegend=False)
                st.plotly_chart(fig_sim, use_container_width=True)
            
            # ìƒì„¸ ê²°ê³¼
            st.subheader("ğŸ“‹ ìœ ì‚¬ì‚¬ë¡€ ìƒì„¸ ì •ë³´")
            
            for i, (total_score, text_sim, similar_case) in enumerate(top_similar):
                with st.expander(f"#{i+1} ìœ ì‚¬ë„ {total_score:.3f} - {similar_case['íŒì •êµ¬ë¶„']} ({similar_case['ì‚¬ê³ ìœ í˜•ëª…']})"):
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**ğŸ“‹ ì‚¬ë¡€ ì •ë³´**")
                        st.write(f"â€¢ ë³´ìƒíŒŒì¼ë²ˆí˜¸: `{similar_case['ë³´ìƒíŒŒì¼ë²ˆí˜¸']}`")
                        st.write(f"â€¢ ì‚¬ê³ ë²ˆí˜¸: `{similar_case['ì‚¬ê³ ë²ˆí˜¸']}`")
                        st.write(f"â€¢ ìˆ˜ì…êµ­: **{similar_case['ìˆ˜ì…êµ­']}**")
                        st.write(f"â€¢ ë³´í—˜ì¢…ëª©: {similar_case['ë³´í—˜ì¢…ëª©']}")
                        
                        if pd.notna(similar_case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']):
                            amount_str = f"{similar_case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']:,.0f}ì›"
                            if similar_case['ì›í™”ì‚¬ê³ ê¸ˆì•¡'] >= 100000000:
                                amount_str += f" ({similar_case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']/100000000:.1f}ì–µì›)"
                            st.write(f"â€¢ ì‚¬ê³ ê¸ˆì•¡: **{amount_str}**")
                    
                    with col2:
                        st.write("**âš–ï¸ íŒì • ì •ë³´**")
                        
                        if similar_case['íŒì •êµ¬ë¶„'] == 'ì§€ê¸‰':
                            st.success(f"íŒì •êµ¬ë¶„: {similar_case['íŒì •êµ¬ë¶„']}")
                        elif similar_case['íŒì •êµ¬ë¶„'] == 'ë©´ì±…':
                            st.error(f"íŒì •êµ¬ë¶„: {similar_case['íŒì •êµ¬ë¶„']}")
                        else:
                            st.warning(f"íŒì •êµ¬ë¶„: {similar_case['íŒì •êµ¬ë¶„']}")
                        
                        st.write(f"â€¢ íŒì •ì‚¬ìœ : **{similar_case['íŒì •ì‚¬ìœ ']}**")
                        st.write(f"â€¢ íŒì •íšŒì°¨: {similar_case['íŒì •íšŒì°¨']}íšŒ")
                        st.write(f"â€¢ ì‚¬ê³ ì§„í–‰ìƒíƒœ: {similar_case['ì‚¬ê³ ì§„í–‰ìƒíƒœ']}")
                    
                    # ìœ ì‚¬ë„ ì ìˆ˜ ì‹œê°í™”
                    st.write("**ğŸ“Š ìœ ì‚¬ë„ ë¶„ì„**")
                    similarity_pct = min(total_score * 100, 100)  # float32 ì—ëŸ¬ ë°©ì§€
                    st.progress(float(similarity_pct) / 100)  # float ë³€í™˜ìœ¼ë¡œ ì—ëŸ¬ ë°©ì§€
                    st.caption(f"í†µí•© ìœ ì‚¬ë„: {total_score:.1%} | í…ìŠ¤íŠ¸ ìœ ì‚¬ë„: {text_sim:.1%}")
                    
                    if pd.notna(similar_case['ì‚¬ê³ ì„¤ëª…']) and len(str(similar_case['ì‚¬ê³ ì„¤ëª…'])) > 10:
                        st.write("**ğŸ“ ì‚¬ê³ ì„¤ëª…**")
                        st.markdown(f"> {similar_case['ì‚¬ê³ ì„¤ëª…']}")
        else:
            st.warning("ì¡°ê±´ì— ë§ëŠ” ìœ ì‚¬ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def create_model_performance_tab(system, df):
    """ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„ íƒ­"""
    st.subheader("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„")
    
    if system.model is None:
        if st.button("ğŸ“š ëª¨ë¸ í•™ìŠµ ì‹¤í–‰"):
            with st.spinner("ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ì¤‘..."):
                results = system.train_prediction_model(df)
                if results:
                    st.session_state.model_results = results
                    st.success("ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    
    if hasattr(st.session_state, 'model_results') and st.session_state.model_results:
        results = st.session_state.model_results
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("êµì°¨ê²€ì¦ í‰ê·  ì •í™•ë„", f"{results['cv_mean']:.3f}")
        with col2:
            st.metric("í‘œì¤€í¸ì°¨", f"{results['cv_std']:.3f}")
        with col3:
            st.metric("ì‹ ë¢°êµ¬ê°„", f"Â±{1.96*results['cv_std']:.3f}")
        
        # íŠ¹ì„± ì¤‘ìš”ë„
        if 'feature_importance' in results:
            fig = px.bar(
                results['feature_importance'].head(10),
                x='importance',
                y='feature',
                orientation='h',
                title="ìƒìœ„ 10ê°œ íŠ¹ì„± ì¤‘ìš”ë„",
                color_discrete_sequence=['#007bff']
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        # ê°€ì¤‘ì¹˜ ë¶„ì„
        st.write("**âš–ï¸ ìµœì í™”ëœ ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜ (ì‹¤í—˜ ê²°ê³¼ ê¸°ë°˜)**")
        weights_df = pd.DataFrame(list(system.optimal_weights.items()), 
                                 columns=['íŠ¹ì„±', 'ê°€ì¤‘ì¹˜'])
        
        fig_weights = px.bar(
            weights_df,
            x='ê°€ì¤‘ì¹˜',
            y='íŠ¹ì„±',
            orientation='h',
            title="ìœ ì‚¬ë„ ê³„ì‚° ê°€ì¤‘ì¹˜ ë¶„í¬",
            color_discrete_sequence=['#28a745']
        )
        fig_weights.update_layout(height=300)
        st.plotly_chart(fig_weights, use_container_width=True)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ë°ì´í„° ë¡œë“œ
    df = load_data()
    if df is None:
        st.error("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if 'insurance_system' not in st.session_state:
        st.session_state.insurance_system = PracticalInsuranceSystem()
    
    system = st.session_state.insurance_system
    
    # íƒ­ êµ¬ì„±
    tab1, tab2, tab3 = st.tabs([
        "ğŸ“Š ì „ì²´ í˜„í™©", 
        "ğŸ” ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰", 
        "ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥"
    ])
    
    with tab1:
        create_main_dashboard(df)
    
    with tab2:
        create_similarity_search_interface(system, df)
    
    with tab3:
        create_model_performance_tab(system, df)
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #6c757d; padding: 1rem;">
        <p>ğŸ“‹ ë³´í—˜ì‚¬ê³  íŒì • ë¶„ì„ ì‹œìŠ¤í…œ</p>
        <small>ì‹¤ë¬´ì§„ì„ ìœ„í•œ AI ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì§€ì› ë„êµ¬</small>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()