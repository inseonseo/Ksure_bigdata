import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import seaborn as sns
import matplotlib.pyplot as plt
from collections import Counter
import pickle
import warnings
import re
from datetime import datetime
warnings.filterwarnings('ignore')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë³´í—˜ì‚¬ê³  íŒì • íë¦„ ë¶„ì„ ë° ì˜ˆì¸¡ ì‹œìŠ¤í…œ",
    page_icon="ğŸ¢",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    
    .metric-card {
        background: #f0f2f6;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #1f77b4;
    }
    
    .prediction-result {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        text-align: center;
        margin: 1rem 0;
    }
    
    .similar-case {
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
        background: #fafafa;
    }
</style>
""", unsafe_allow_html=True)

class InsuranceAnalysisSystem:
    def __init__(self):
        self.model = None
        self.text_vectorizer = None
        self.label_encoders = {}
        self.feature_importance = None
        self.optimal_weights = {
            'text_similarity': 0.4,
            'accident_type': 0.25,
            'country': 0.15,
            'amount_range': 0.15,
            'insurance_type': 0.05
        }
    
    def preprocess_features(self, df):
        """íŠ¹ì„± ì „ì²˜ë¦¬"""
        df_processed = df.copy()
        
        # ê¸ˆì•¡ êµ¬ê°„ ìƒì„±
        df_processed['ê¸ˆì•¡êµ¬ê°„'] = pd.cut(
            df_processed['ì›í™”ì‚¬ê³ ê¸ˆì•¡'].fillna(0),
            bins=[0, 10000000, 50000000, 100000000, 500000000, float('inf')],
            labels=['1ì²œë§Œì›ë¯¸ë§Œ', '1ì²œë§Œ-5ì²œë§Œì›', '5ì²œë§Œ-1ì–µì›', '1ì–µ-5ì–µì›', '5ì–µì›ì´ìƒ']
        )
        
        # ì‚¬ê³ ìœ í˜• ê·¸ë£¹í™”
        df_processed['ì‚¬ê³ ìœ í˜•ê·¸ë£¹'] = df_processed['ì‚¬ê³ ìœ í˜•ëª…'].apply(self._group_accident_type)
        
        # í…ìŠ¤íŠ¸ íŠ¹ì„±
        df_processed['ì‚¬ê³ ì„¤ëª…_ê¸¸ì´'] = df_processed['ì‚¬ê³ ì„¤ëª…'].fillna('').str.len()
        df_processed['ì‚¬ê³ ì„¤ëª…_ìœ íš¨'] = (
            (df_processed['ì‚¬ê³ ì„¤ëª…'].notna()) & 
            (df_processed['ì‚¬ê³ ì„¤ëª…'].str.len() > 10) &
            (~df_processed['ì‚¬ê³ ì„¤ëª…'].str.contains('ì„¤ëª…ì—†ìŒ|ì²¨ë¶€íŒŒì¼ì°¸ê³ |í•´ë‹¹ì—†ìŒ', na=False, case=False))
        )
        
        return df_processed
    
    def _group_accident_type(self, accident_type):
        """ì‚¬ê³ ìœ í˜• ê·¸ë£¹í™”"""
        if pd.isna(accident_type):
            return 'ê¸°íƒ€'
        
        if 'ì‹ ìš©ìœ„í—˜' in accident_type:
            if 'ì§€ê¸‰ì§€ì²´' in accident_type:
                return 'ì‹ ìš©ìœ„í—˜-ì§€ê¸‰ì§€ì²´'
            elif 'íŒŒì‚°' in accident_type:
                return 'ì‹ ìš©ìœ„í—˜-íŒŒì‚°'
            elif 'ì§€ê¸‰ë¶ˆëŠ¥' in accident_type or 'ì§€ê¸‰ê±°ì ˆ' in accident_type:
                return 'ì‹ ìš©ìœ„í—˜-ì§€ê¸‰ë¶ˆëŠ¥/ê±°ì ˆ'
            else:
                return 'ì‹ ìš©ìœ„í—˜-ê¸°íƒ€'
        elif 'ë¹„ìƒìœ„í—˜' in accident_type:
            return 'ë¹„ìƒìœ„í—˜'
        elif 'ê²€ì—­ìœ„í—˜' in accident_type:
            return 'ê²€ì—­ìœ„í—˜'
        else:
            return 'ê¸°íƒ€ìœ„í—˜'
    
    def train_prediction_model(self, df):
        """ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ"""
        df_processed = self.preprocess_features(df)
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        categorical_features = ['ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©', 'ì‚¬ê³ ìœ í˜•ê·¸ë£¹', 'ê¸ˆì•¡êµ¬ê°„', 'ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…']
        
        for feature in categorical_features:
            le = LabelEncoder()
            df_processed[f'{feature}_encoded'] = le.fit_transform(df_processed[feature].fillna('Unknown'))
            self.label_encoders[feature] = le
        
        # íŠ¹ì„± ì„ íƒ
        feature_columns = [f'{feature}_encoded' for feature in categorical_features]
        feature_columns.extend(['ì‚¬ê³ ì„¤ëª…_ê¸¸ì´', 'ì›í™”ì‚¬ê³ ê¸ˆì•¡'])
        
        X = df_processed[feature_columns].fillna(0)
        y = df_processed['íŒì •êµ¬ë¶„']
        
        # í•™ìŠµ/ê²€ì¦ ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # ëª¨ë¸ í•™ìŠµ
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            class_weight='balanced'
        )
        
        self.model.fit(X_train, y_train)
        
        # íŠ¹ì„± ì¤‘ìš”ë„
        self.feature_importance = pd.DataFrame({
            'feature': X.columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        train_score = self.model.score(X_train, y_train)
        test_score = self.model.score(X_test, y_test)
        
        return {
            'train_score': train_score,
            'test_score': test_score,
            'feature_importance': self.feature_importance
        }
    
    def calculate_similarity_score(self, query_case, candidate_case):
        """ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        weights = self.optimal_weights
        
        # 1. í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ (ê°„ë‹¨í•œ Jaccard ìœ ì‚¬ë„)
        if 'text_similarity' in weights and 'ì‚¬ê³ ì„¤ëª…' in query_case and 'ì‚¬ê³ ì„¤ëª…' in candidate_case:
            query_text = str(query_case['ì‚¬ê³ ì„¤ëª…']).lower()
            candidate_text = str(candidate_case['ì‚¬ê³ ì„¤ëª…']).lower()
            
            query_words = set(query_text.split())
            candidate_words = set(candidate_text.split())
            
            if query_words and candidate_words:
                jaccard_sim = len(query_words.intersection(candidate_words)) / len(query_words.union(candidate_words))
                score += weights['text_similarity'] * jaccard_sim
        
        # 2. ì‚¬ê³ ìœ í˜• ìœ ì‚¬ë„
        if 'accident_type' in weights:
            if query_case.get('ì‚¬ê³ ìœ í˜•ëª…') == candidate_case.get('ì‚¬ê³ ìœ í˜•ëª…'):
                score += weights['accident_type']
            elif self._group_accident_type(query_case.get('ì‚¬ê³ ìœ í˜•ëª…')) == self._group_accident_type(candidate_case.get('ì‚¬ê³ ìœ í˜•ëª…')):
                score += weights['accident_type'] * 0.7
        
        # 3. ìˆ˜ì…êµ­ ì¼ì¹˜
        if 'country' in weights and query_case.get('ìˆ˜ì…êµ­') == candidate_case.get('ìˆ˜ì…êµ­'):
            score += weights['country']
        
        # 4. ê¸ˆì•¡ëŒ€ ìœ ì‚¬ë„
        if 'amount_range' in weights:
            query_amount = query_case.get('ì›í™”ì‚¬ê³ ê¸ˆì•¡', 0)
            candidate_amount = candidate_case.get('ì›í™”ì‚¬ê³ ê¸ˆì•¡', 0)
            
            if query_amount > 0 and candidate_amount > 0:
                amount_ratio = min(query_amount, candidate_amount) / max(query_amount, candidate_amount)
                score += weights['amount_range'] * amount_ratio
        
        # 5. ë³´í—˜ì¢…ëª© ì¼ì¹˜
        if 'insurance_type' in weights and query_case.get('ë³´í—˜ì¢…ëª©') == candidate_case.get('ë³´í—˜ì¢…ëª©'):
            score += weights['insurance_type']
        
        return score

@st.cache_data
def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    try:
        df = pd.read_csv('KoSimCSE/new/design.csv', encoding='cp949')
        
        # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
        date_columns = ['íŒì •ì¼', 'íŒì •ê²°ì¬ì¼', 'ì‚¬ê³ ì ‘ìˆ˜ì¼ì', 'ë³´í—˜ê¸ˆì²­êµ¬ì¼']
        for col in date_columns:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce')
        
        # ê¸ˆì•¡ ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜
        amount_columns = ['ì›í™”ì‚¬ê³ ê¸ˆì•¡', 'ì›í™”íŒì •ê¸ˆì•¡']
        for col in amount_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def create_overview_dashboard(df):
    """ì „ì²´ í˜„í™© ëŒ€ì‹œë³´ë“œ"""
    st.markdown('<div class="main-header"><h1>ğŸ“Š ë³´í—˜ì‚¬ê³  íŒì • íë¦„ ë¶„ì„ ë° ì˜ˆì¸¡ ì‹œìŠ¤í…œ</h1></div>', unsafe_allow_html=True)
    
    # í•µì‹¬ ì§€í‘œ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_cases = len(df)
        st.markdown(f"""
        <div class="metric-card">
            <h3>ì „ì²´ ì‚¬ê³ ê±´ìˆ˜</h3>
            <h2>{total_cases:,}ê±´</h2>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        payment_rate = (df['íŒì •êµ¬ë¶„'] == 'ì§€ê¸‰').mean() * 100
        st.markdown(f"""
        <div class="metric-card">
            <h3>ì§€ê¸‰ ë¹„ìœ¨</h3>
            <h2>{payment_rate:.1f}%</h2>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        avg_amount = df['ì›í™”ì‚¬ê³ ê¸ˆì•¡'].mean() / 100000000
        st.markdown(f"""
        <div class="metric-card">
            <h3>í‰ê·  ì‚¬ê³ ê¸ˆì•¡</h3>
            <h2>{avg_amount:.1f}ì–µì›</h2>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        meaningful_desc = len(df[
            (df['ì‚¬ê³ ì„¤ëª…'].notna()) & 
            (df['ì‚¬ê³ ì„¤ëª…'].str.len() > 10) &
            (~df['ì‚¬ê³ ì„¤ëª…'].str.contains('ì„¤ëª…ì—†ìŒ|ì²¨ë¶€íŒŒì¼ì°¸ê³ |í•´ë‹¹ì—†ìŒ', na=False, case=False))
        ])
        desc_rate = meaningful_desc / len(df) * 100
        st.markdown(f"""
        <div class="metric-card">
            <h3>ìœ íš¨ ì„¤ëª… ë¹„ìœ¨</h3>
            <h2>{desc_rate:.1f}%</h2>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # ì£¼ìš” ì°¨íŠ¸ë“¤
    col1, col2 = st.columns(2)
    
    with col1:
        # ìˆ˜ì…êµ­ë³„ ìƒìœ„ 10ê°œ
        country_counts = df['ìˆ˜ì…êµ­'].value_counts().head(10)
        fig1 = px.bar(
            x=country_counts.values,
            y=country_counts.index,
            orientation='h',
            title="ğŸŒ ìƒìœ„ 10ê°œêµ­ ì‚¬ê³  ë°œìƒ í˜„í™©",
            labels={'x': 'ì‚¬ê³  ê±´ìˆ˜', 'y': 'ìˆ˜ì…êµ­'},
            color=country_counts.values,
            color_continuous_scale='viridis'
        )
        fig1.update_layout(height=400, showlegend=False)
        st.plotly_chart(fig1, use_container_width=True)
    
    with col2:
        # íŒì •êµ¬ë¶„ë³„ ë¶„í¬
        decision_counts = df['íŒì •êµ¬ë¶„'].value_counts()
        colors = ['#2E8B57' if x == 'ì§€ê¸‰' else '#DC143C' if x == 'ë©´ì±…' else '#4682B4' 
                 for x in decision_counts.index]
        
        fig2 = px.pie(
            values=decision_counts.values,
            names=decision_counts.index,
            title="âš–ï¸ íŒì •êµ¬ë¶„ë³„ ë¶„í¬",
            color_discrete_sequence=colors
        )
        fig2.update_traces(textposition='inside', textinfo='percent+label')
        fig2.update_layout(height=400)
        st.plotly_chart(fig2, use_container_width=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        # ì‚¬ê³ ìœ í˜•ë³„ ìƒìœ„ 8ê°œ
        accident_types = df['ì‚¬ê³ ìœ í˜•ëª…'].value_counts().head(8)
        fig3 = px.bar(
            x=accident_types.index,
            y=accident_types.values,
            title="âš ï¸ ì£¼ìš” ì‚¬ê³ ìœ í˜•ë³„ ë°œìƒ í˜„í™©",
            labels={'x': 'ì‚¬ê³ ìœ í˜•', 'y': 'ê±´ìˆ˜'},
            color=accident_types.values,
            color_continuous_scale='plasma'
        )
        fig3.update_layout(height=400, xaxis_tickangle=-45, showlegend=False)
        st.plotly_chart(fig3, use_container_width=True)
    
    with col2:
        # ê¸ˆì•¡êµ¬ê°„ë³„ ë¶„í¬
        df_amount = df[df['ì›í™”ì‚¬ê³ ê¸ˆì•¡'].notna() & (df['ì›í™”ì‚¬ê³ ê¸ˆì•¡'] > 0)].copy()
        df_amount['ê¸ˆì•¡êµ¬ê°„'] = pd.cut(
            df_amount['ì›í™”ì‚¬ê³ ê¸ˆì•¡'],
            bins=[0, 10000000, 50000000, 100000000, 500000000, 1000000000, float('inf')],
            labels=['1ì²œë§Œì› ë¯¸ë§Œ', '1ì²œë§Œ-5ì²œë§Œì›', '5ì²œë§Œ-1ì–µì›', '1ì–µ-5ì–µì›', '5ì–µ-10ì–µì›', '10ì–µì› ì´ìƒ']
        )
        
        amount_dist = df_amount['ê¸ˆì•¡êµ¬ê°„'].value_counts().sort_index()
        fig4 = px.bar(
            x=amount_dist.index,
            y=amount_dist.values,
            title="ğŸ’° ì‚¬ê³ ê¸ˆì•¡ êµ¬ê°„ë³„ ë¶„í¬",
            labels={'x': 'ê¸ˆì•¡êµ¬ê°„', 'y': 'ê±´ìˆ˜'},
            color=amount_dist.values,
            color_continuous_scale='blues'
        )
        fig4.update_layout(height=400, xaxis_tickangle=-45, showlegend=False)
        st.plotly_chart(fig4, use_container_width=True)

def create_process_flow_analysis(df):
    """ë³´ìƒ í”„ë¡œì„¸ìŠ¤ íë¦„ ë¶„ì„"""
    st.subheader("ğŸ”„ ë³´ìƒ í”„ë¡œì„¸ìŠ¤ íë¦„ ë¶„ì„")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # íŒì •íšŒì°¨ë³„ ë¶„í¬
        round_counts = df['íŒì •íšŒì°¨'].value_counts().sort_index()
        fig1 = px.bar(
            x=round_counts.index,
            y=round_counts.values,
            title="íŒì •íšŒì°¨ë³„ ì‚¬ê³  ë¶„í¬",
            labels={'x': 'íŒì •íšŒì°¨', 'y': 'ê±´ìˆ˜'},
            color=round_counts.values,
            color_continuous_scale='greens'
        )
        fig1.update_layout(height=400, showlegend=False)
        st.plotly_chart(fig1, use_container_width=True)
        
        # í†µê³„ ì •ë³´
        st.write("**ğŸ“Š íŒì •íšŒì°¨ í†µê³„:**")
        st.write(f"â€¢ í‰ê·  íŒì •íšŒì°¨: {df['íŒì •íšŒì°¨'].mean():.1f}íšŒ")
        st.write(f"â€¢ ìµœëŒ€ íŒì •íšŒì°¨: {df['íŒì •íšŒì°¨'].max()}íšŒ")
        st.write(f"â€¢ 1íšŒì°¨ë¡œ ì¢…ë£Œ: {(df['íŒì •íšŒì°¨'] == 1).sum():,}ê±´ ({(df['íŒì •íšŒì°¨'] == 1).mean()*100:.1f}%)")
        st.write(f"â€¢ 2íšŒì°¨ ì´ìƒ: {(df['íŒì •íšŒì°¨'] >= 2).sum():,}ê±´ ({(df['íŒì •íšŒì°¨'] >= 2).mean()*100:.1f}%)")
    
    with col2:
        # ì‚¬ê³ ì§„í–‰ìƒíƒœë³„ ë¶„í¬
        status_counts = df['ì‚¬ê³ ì§„í–‰ìƒíƒœ'].value_counts().head(8)
        fig2 = px.pie(
            values=status_counts.values,
            names=status_counts.index,
            title="ì‚¬ê³ ì§„í–‰ìƒíƒœë³„ ë¶„í¬ (ìƒìœ„ 8ê°œ)",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        fig2.update_traces(textposition='inside', textinfo='percent+label')
        fig2.update_layout(height=400)
        st.plotly_chart(fig2, use_container_width=True)
    
    # íŒì •íšŒì°¨ë³„ íŒì •êµ¬ë¶„ ë³€í™” ë¶„ì„
    st.write("**ğŸ”„ íŒì •íšŒì°¨ë³„ íŒì •êµ¬ë¶„ ë³€í™”:**")
    
    # ì‚¬ê³ ë²ˆí˜¸ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ íŒì •íšŒì°¨ë³„ ë³€í™” ì¶”ì 
    case_progression = df.groupby('ì‚¬ê³ ë²ˆí˜¸').apply(
        lambda x: x.sort_values('íŒì •íšŒì°¨')[['íŒì •íšŒì°¨', 'íŒì •êµ¬ë¶„']].to_dict('records')
    )
    
    # 1ì°¨â†’2ì°¨ ë³€í™” íŒ¨í„´ ë¶„ì„
    transitions = []
    for case_data in case_progression:
        if len(case_data) >= 2:
            first_decision = case_data[0]['íŒì •êµ¬ë¶„']
            second_decision = case_data[1]['íŒì •êµ¬ë¶„']
            transitions.append(f"{first_decision} â†’ {second_decision}")
    
    if transitions:
        transition_counts = Counter(transitions)
        transition_df = pd.DataFrame(list(transition_counts.items()), columns=['ë³€í™”íŒ¨í„´', 'ê±´ìˆ˜'])
        transition_df = transition_df.sort_values('ê±´ìˆ˜', ascending=False).head(10)
        
        fig3 = px.bar(
            transition_df,
            x='ê±´ìˆ˜',
            y='ë³€í™”íŒ¨í„´',
            orientation='h',
            title="1ì°¨â†’2ì°¨ íŒì •êµ¬ë¶„ ë³€í™” íŒ¨í„´ (ìƒìœ„ 10ê°œ)",
            color='ê±´ìˆ˜',
            color_continuous_scale='viridis'
        )
        fig3.update_layout(height=400, showlegend=False)
        st.plotly_chart(fig3, use_container_width=True)

def create_prediction_interface(analysis_system, df):
    """ì˜ˆì¸¡ ì¸í„°í˜ì´ìŠ¤"""
    st.subheader("ğŸ”® ì‚¬ê³  íŒì • ì˜ˆì¸¡ ë° ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰")
    
    # ëª¨ë¸ í•™ìŠµ ìƒíƒœ í™•ì¸
    if analysis_system.model is None:
        st.warning("âš ï¸ ì˜ˆì¸¡ ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'ëª¨ë¸ í•™ìŠµ ì‹¤í–‰'ì„ í´ë¦­í•´ì£¼ì„¸ìš”.")
        return
    
    st.write("**ìƒˆë¡œìš´ ì‚¬ê³  ì •ë³´ë¥¼ ì…ë ¥í•˜ì—¬ ì˜ˆìƒ íŒì •ê³¼ ìœ ì‚¬ì‚¬ë¡€ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.**")
    
    # ì…ë ¥ í¼
    with st.form("prediction_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ğŸ“‹ ê¸°ë³¸ ì •ë³´**")
            
            input_country = st.selectbox(
                "ìˆ˜ì…êµ­:",
                options=df['ìˆ˜ì…êµ­'].value_counts().head(20).index,
                help="ì‚¬ê³ ê°€ ë°œìƒí•œ ìˆ˜ì…êµ­ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            input_insurance = st.selectbox(
                "ë³´í—˜ì¢…ëª©:",
                options=df['ë³´í—˜ì¢…ëª©'].value_counts().head(15).index,
                help="í•´ë‹¹í•˜ëŠ” ë³´í—˜ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            input_accident_type = st.selectbox(
                "ì‚¬ê³ ìœ í˜•:",
                options=df['ì‚¬ê³ ìœ í˜•ëª…'].value_counts().head(15).index,
                help="ì‚¬ê³ ì˜ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            input_product_group = st.selectbox(
                "ìƒí’ˆë¶„ë¥˜ê·¸ë£¹:",
                options=['ì„ íƒì•ˆí•¨'] + list(df['ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…'].value_counts().head(15).index),
                help="ìˆ˜ì¶œí’ˆëª©ì˜ ë¶„ë¥˜ê·¸ë£¹ì„ ì„ íƒí•˜ì„¸ìš”"
            )
        
        with col2:
            st.write("**ğŸ’° ê¸ˆì•¡ ë° ìƒì„¸ ì •ë³´**")
            
            input_amount = st.number_input(
                "ì‚¬ê³ ê¸ˆì•¡ (ì›):",
                min_value=0,
                value=50000000,
                step=1000000,
                format="%d",
                help="ì‚¬ê³ ë¡œ ì¸í•œ ì†ì‹¤ ê¸ˆì•¡ì„ ì…ë ¥í•˜ì„¸ìš”"
            )
            
            input_description = st.text_area(
                "ì‚¬ê³ ì„¤ëª…:",
                placeholder="ì‚¬ê³ ì˜ ìƒì„¸í•œ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. ì˜ˆ: ìˆ˜ì…ìê°€ ëŒ€ê¸ˆ ì§€ê¸‰ì„ ì§€ì—°í•˜ì—¬ ë°œìƒí•œ ì‚¬ê³ ì…ë‹ˆë‹¤...",
                height=120,
                help="ì‚¬ê³ ì˜ êµ¬ì²´ì ì¸ ìƒí™©ê³¼ ì›ì¸ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”"
            )
        
        submitted = st.form_submit_button("ğŸ¯ ì˜ˆì¸¡ ë° ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰", type="primary")
    
    if submitted:
        # ì…ë ¥ ë°ì´í„° êµ¬ì„±
        case_data = {
            'ìˆ˜ì…êµ­': input_country,
            'ë³´í—˜ì¢…ëª©': input_insurance,
            'ì‚¬ê³ ìœ í˜•ëª…': input_accident_type,
            'ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…': input_product_group if input_product_group != 'ì„ íƒì•ˆí•¨' else None,
            'ì›í™”ì‚¬ê³ ê¸ˆì•¡': input_amount,
            'ì‚¬ê³ ì„¤ëª…': input_description
        }
        
        with st.spinner("ë¶„ì„ ì¤‘..."):
            # ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰
            similarities = []
            for idx, row in df.iterrows():
                sim_score = analysis_system.calculate_similarity_score(case_data, row)
                similarities.append((sim_score, row))
            
            # ìƒìœ„ ìœ ì‚¬ì‚¬ë¡€
            similarities.sort(key=lambda x: x[0], reverse=True)
            top_similar = similarities[:10]
            
            # ì˜ˆì¸¡ ê²°ê³¼ (ìœ ì‚¬ì‚¬ë¡€ ê¸°ë°˜)
            similar_decisions = [case[1]['íŒì •êµ¬ë¶„'] for case in top_similar[:5]]
            decision_counts = Counter(similar_decisions)
            predicted_decision = decision_counts.most_common(1)[0][0]
            confidence = decision_counts[predicted_decision] / len(similar_decisions)
            
            # ê²°ê³¼ í‘œì‹œ
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.markdown(f"""
                <div class="prediction-result">
                    <h2>ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼</h2>
                    <h1>{predicted_decision}</h1>
                    <p>ì‹ ë¢°ë„: {confidence:.1%}</p>
                    <small>ìƒìœ„ 5ê°œ ìœ ì‚¬ì‚¬ë¡€ ê¸°ë°˜ ì˜ˆì¸¡</small>
                </div>
                """, unsafe_allow_html=True)
                
                # íŒì •êµ¬ë¶„ë³„ ë¶„í¬
                decision_df = pd.DataFrame(list(decision_counts.items()), columns=['íŒì •êµ¬ë¶„', 'ê±´ìˆ˜'])
                fig_pred = px.pie(
                    decision_df,
                    values='ê±´ìˆ˜',
                    names='íŒì •êµ¬ë¶„',
                    title="ìœ ì‚¬ì‚¬ë¡€ íŒì •êµ¬ë¶„ ë¶„í¬",
                    color_discrete_map={'ì§€ê¸‰': '#2E8B57', 'ë©´ì±…': '#DC143C', 'ì§€ê¸‰ìœ ì˜ˆ': '#4682B4'}
                )
                st.plotly_chart(fig_pred, use_container_width=True)
            
            with col2:
                # ìœ ì‚¬ë„ ë¶„í¬
                sim_scores = [sim[0] for sim in top_similar]
                fig_sim = px.bar(
                    x=list(range(1, len(sim_scores) + 1)),
                    y=sim_scores,
                    title="ìƒìœ„ 10ê°œ ìœ ì‚¬ì‚¬ë¡€ ìœ ì‚¬ë„ ì ìˆ˜",
                    labels={'x': 'ìˆœìœ„', 'y': 'ìœ ì‚¬ë„ ì ìˆ˜'},
                    color=sim_scores,
                    color_continuous_scale='viridis'
                )
                fig_sim.update_layout(showlegend=False)
                st.plotly_chart(fig_sim, use_container_width=True)
            
            # ìƒì„¸ ìœ ì‚¬ì‚¬ë¡€
            st.subheader("ğŸ“‹ ìƒìœ„ ìœ ì‚¬ì‚¬ë¡€ ìƒì„¸ ì •ë³´")
            
            for i, (sim_score, similar_case) in enumerate(top_similar[:5]):
                with st.expander(f"#{i+1} ìœ ì‚¬ë„ {sim_score:.3f} - {similar_case['íŒì •êµ¬ë¶„']} ({similar_case['ì‚¬ê³ ìœ í˜•ëª…']})"):
                    
                    # ìœ ì‚¬ë„ ì§„í–‰ë°”
                    st.progress(sim_score)
                    st.caption(f"ìœ ì‚¬ë„: {sim_score:.1%}")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**ğŸ“‹ ì‚¬ë¡€ ì •ë³´**")
                        st.write(f"â€¢ ë³´ìƒíŒŒì¼ë²ˆí˜¸: `{similar_case['ë³´ìƒíŒŒì¼ë²ˆí˜¸']}`")
                        st.write(f"â€¢ ì‚¬ê³ ë²ˆí˜¸: `{similar_case['ì‚¬ê³ ë²ˆí˜¸']}`")
                        st.write(f"â€¢ ìˆ˜ì…êµ­: **{similar_case['ìˆ˜ì…êµ­']}**")
                        st.write(f"â€¢ ë³´í—˜ì¢…ëª©: {similar_case['ë³´í—˜ì¢…ëª©']}")
                        st.write(f"â€¢ ìƒí’ˆë¶„ë¥˜: {similar_case['ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…']}")
                        
                        if pd.notna(similar_case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']):
                            amount_str = f"{similar_case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']:,.0f}ì›"
                            if similar_case['ì›í™”ì‚¬ê³ ê¸ˆì•¡'] >= 100000000:
                                amount_str += f" ({similar_case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']/100000000:.1f}ì–µì›)"
                            st.write(f"â€¢ ì‚¬ê³ ê¸ˆì•¡: **{amount_str}**")
                    
                    with col2:
                        st.write("**âš–ï¸ íŒì • ì •ë³´**")
                        
                        # íŒì •êµ¬ë¶„ ìƒ‰ìƒ í‘œì‹œ
                        if similar_case['íŒì •êµ¬ë¶„'] == 'ì§€ê¸‰':
                            st.success(f"íŒì •êµ¬ë¶„: {similar_case['íŒì •êµ¬ë¶„']}")
                        elif similar_case['íŒì •êµ¬ë¶„'] == 'ë©´ì±…':
                            st.error(f"íŒì •êµ¬ë¶„: {similar_case['íŒì •êµ¬ë¶„']}")
                        else:
                            st.info(f"íŒì •êµ¬ë¶„: {similar_case['íŒì •êµ¬ë¶„']}")
                        
                        st.write(f"â€¢ íŒì •ì‚¬ìœ : **{similar_case['íŒì •ì‚¬ìœ ']}**")
                        st.write(f"â€¢ íŒì •íšŒì°¨: {similar_case['íŒì •íšŒì°¨']}íšŒ")
                        st.write(f"â€¢ ì‚¬ê³ ì§„í–‰ìƒíƒœ: {similar_case['ì‚¬ê³ ì§„í–‰ìƒíƒœ']}")
                        
                        if pd.notna(similar_case['í–¥í›„ê²°ì œì „ë§']) and similar_case['í–¥í›„ê²°ì œì „ë§'] != 'íŒë‹¨ë¶ˆê°€':
                            st.write(f"â€¢ í–¥í›„ê²°ì œì „ë§: {similar_case['í–¥í›„ê²°ì œì „ë§']}")
                    
                    if pd.notna(similar_case['ì‚¬ê³ ì„¤ëª…']) and len(str(similar_case['ì‚¬ê³ ì„¤ëª…'])) > 10:
                        st.write("**ğŸ“ ì‚¬ê³ ì„¤ëª…**")
                        st.markdown(f"> {similar_case['ì‚¬ê³ ì„¤ëª…']}")
                        
                        # ê³µí†µ í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŒ…
                        if input_description:
                            query_words = set(input_description.lower().split())
                            case_words = set(str(similar_case['ì‚¬ê³ ì„¤ëª…']).lower().split())
                            common_words = query_words.intersection(case_words)
                            
                            if common_words and len(common_words) > 0:
                                meaningful_words = [word for word in common_words if len(word) > 2]
                                if meaningful_words:
                                    st.write("**ğŸ”‘ ê³µí†µ í‚¤ì›Œë“œ:**")
                                    st.write(" â€¢ ".join([f"`{word}`" for word in meaningful_words[:10]]))

def create_analytics_dashboard(analysis_system, df):
    """ë¶„ì„ ëŒ€ì‹œë³´ë“œ"""
    st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # ê°€ì¤‘ì¹˜ ì„¤ì • í˜„í™©
        st.write("**âš–ï¸ í˜„ì¬ ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜ ì„¤ì •**")
        
        weights_df = pd.DataFrame(list(analysis_system.optimal_weights.items()), 
                                 columns=['íŠ¹ì„±', 'ê°€ì¤‘ì¹˜'])
        
        fig_weights = px.pie(
            weights_df,
            values='ê°€ì¤‘ì¹˜',
            names='íŠ¹ì„±',
            title="ìœ ì‚¬ë„ ê³„ì‚° ê°€ì¤‘ì¹˜ ë¶„í¬",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        st.plotly_chart(fig_weights, use_container_width=True)
        
        # ê°€ì¤‘ì¹˜ ìƒì„¸ ì •ë³´
        for _, row in weights_df.iterrows():
            st.write(f"â€¢ {row['íŠ¹ì„±']}: {row['ê°€ì¤‘ì¹˜']:.1%}")
    
    with col2:
        # í…ìŠ¤íŠ¸ ë°ì´í„° í’ˆì§ˆ ë¶„ì„
        st.write("**ğŸ“ í…ìŠ¤íŠ¸ ë°ì´í„° í’ˆì§ˆ ë¶„ì„**")
        
        df_text = df[df['ì‚¬ê³ ì„¤ëª…'].notna()].copy()
        df_text['ì„¤ëª…_ê¸¸ì´'] = df_text['ì‚¬ê³ ì„¤ëª…'].str.len()
        
        # ê¸¸ì´ë³„ ë¶„í¬
        length_bins = [0, 20, 50, 100, 200, 500, float('inf')]
        length_labels = ['20ì ë¯¸ë§Œ', '20-50ì', '50-100ì', '100-200ì', '200-500ì', '500ì ì´ìƒ']
        df_text['ê¸¸ì´_êµ¬ê°„'] = pd.cut(df_text['ì„¤ëª…_ê¸¸ì´'], bins=length_bins, labels=length_labels)
        
        length_dist = df_text['ê¸¸ì´_êµ¬ê°„'].value_counts()
        
        fig_length = px.bar(
            x=length_dist.values,
            y=length_dist.index,
            orientation='h',
            title="ì‚¬ê³ ì„¤ëª… ê¸¸ì´ë³„ ë¶„í¬",
            labels={'x': 'ê±´ìˆ˜', 'y': 'ê¸¸ì´ êµ¬ê°„'},
            color=length_dist.values,
            color_continuous_scale='blues'
        )
        st.plotly_chart(fig_length, use_container_width=True)
    
    # ì¶”ê°€ ë¶„ì„
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # ìˆ˜ì…êµ­ë³„ í‰ê·  ì‚¬ê³ ê¸ˆì•¡
        country_avg_amount = df.groupby('ìˆ˜ì…êµ­')['ì›í™”ì‚¬ê³ ê¸ˆì•¡'].mean().sort_values(ascending=False).head(10)
        
        fig_country_amount = px.bar(
            x=country_avg_amount.values / 100000000,
            y=country_avg_amount.index,
            orientation='h',
            title="ìˆ˜ì…êµ­ë³„ í‰ê·  ì‚¬ê³ ê¸ˆì•¡ (ì–µì›)",
            labels={'x': 'í‰ê·  ì‚¬ê³ ê¸ˆì•¡ (ì–µì›)', 'y': 'ìˆ˜ì…êµ­'},
            color=country_avg_amount.values,
            color_continuous_scale='reds'
        )
        fig_country_amount.update_layout(height=400, showlegend=False)
        st.plotly_chart(fig_country_amount, use_container_width=True)
    
    with col2:
        # ë³´í—˜ì¢…ëª©ë³„ ì§€ê¸‰ë¥ 
        insurance_payment_rate = df.groupby('ë³´í—˜ì¢…ëª©').apply(
            lambda x: (x['íŒì •êµ¬ë¶„'] == 'ì§€ê¸‰').mean() * 100
        ).sort_values(ascending=False).head(10)
        
        fig_payment_rate = px.bar(
            x=insurance_payment_rate.values,
            y=insurance_payment_rate.index,
            orientation='h',
            title="ë³´í—˜ì¢…ëª©ë³„ ì§€ê¸‰ë¥  (%)",
            labels={'x': 'ì§€ê¸‰ë¥  (%)', 'y': 'ë³´í—˜ì¢…ëª©'},
            color=insurance_payment_rate.values,
            color_continuous_scale='greens'
        )
        fig_payment_rate.update_layout(height=400, showlegend=False)
        st.plotly_chart(fig_payment_rate, use_container_width=True)
    
    with col3:
        # ì‚¬ê³ ìœ í˜•ë³„ í‰ê·  ì²˜ë¦¬ê¸°ê°„ (íŒì •ì¼ - ì‚¬ê³ ì ‘ìˆ˜ì¼ì)
        df_with_dates = df[(df['íŒì •ì¼'].notna()) & (df['ì‚¬ê³ ì ‘ìˆ˜ì¼ì'].notna())].copy()
        df_with_dates['ì²˜ë¦¬ê¸°ê°„'] = (df_with_dates['íŒì •ì¼'] - df_with_dates['ì‚¬ê³ ì ‘ìˆ˜ì¼ì']).dt.days
        
        processing_time = df_with_dates.groupby('ì‚¬ê³ ìœ í˜•ëª…')['ì²˜ë¦¬ê¸°ê°„'].mean().sort_values(ascending=False).head(10)
        
        fig_processing = px.bar(
            x=processing_time.values,
            y=processing_time.index,
            orientation='h',
            title="ì‚¬ê³ ìœ í˜•ë³„ í‰ê·  ì²˜ë¦¬ê¸°ê°„ (ì¼)",
            labels={'x': 'í‰ê·  ì²˜ë¦¬ê¸°ê°„ (ì¼)', 'y': 'ì‚¬ê³ ìœ í˜•'},
            color=processing_time.values,
            color_continuous_scale='oranges'
        )
        fig_processing.update_layout(height=400, showlegend=False)
        st.plotly_chart(fig_processing, use_container_width=True)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ë°ì´í„° ë¡œë“œ
    df = load_data()
    if df is None:
        st.error("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if 'analysis_system' not in st.session_state:
        st.session_state.analysis_system = InsuranceAnalysisSystem()
        st.session_state.model_trained = False
    
    analysis_system = st.session_state.analysis_system
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("ğŸ”§ ì‹œìŠ¤í…œ ì„¤ì •")
    
    # ëª¨ë¸ í•™ìŠµ
    if st.sidebar.button("ğŸ“š ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì‹¤í–‰"):
        with st.spinner("ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ì¤‘..."):
            try:
                model_results = analysis_system.train_prediction_model(df)
                st.session_state.model_trained = True
                st.sidebar.success(f"ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! (ì •í™•ë„: {model_results['test_score']:.3f})")
            except Exception as e:
                st.sidebar.error(f"ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
    
    # ê°€ì¤‘ì¹˜ ì¡°ì •
    st.sidebar.write("**âš–ï¸ ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜ ì¡°ì •**")
    st.sidebar.write("*ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ì—¬ ìœ ì‚¬ë„ ê³„ì‚°ì„ ìµœì í™”í•˜ì„¸ìš”*")
    
    text_weight = st.sidebar.slider("í…ìŠ¤íŠ¸ ìœ ì‚¬ë„", 0.0, 1.0, analysis_system.optimal_weights['text_similarity'], 0.05)
    accident_weight = st.sidebar.slider("ì‚¬ê³ ìœ í˜•", 0.0, 1.0, analysis_system.optimal_weights['accident_type'], 0.05)
    country_weight = st.sidebar.slider("ìˆ˜ì…êµ­", 0.0, 1.0, analysis_system.optimal_weights['country'], 0.05)
    amount_weight = st.sidebar.slider("ê¸ˆì•¡ëŒ€", 0.0, 1.0, analysis_system.optimal_weights['amount_range'], 0.05)
    insurance_weight = st.sidebar.slider("ë³´í—˜ì¢…ëª©", 0.0, 1.0, analysis_system.optimal_weights['insurance_type'], 0.05)
    
    # ê°€ì¤‘ì¹˜ ì •ê·œí™”
    total_weight = text_weight + accident_weight + country_weight + amount_weight + insurance_weight
    if total_weight > 0:
        analysis_system.optimal_weights = {
            'text_similarity': text_weight / total_weight,
            'accident_type': accident_weight / total_weight,
            'country': country_weight / total_weight,
            'amount_range': amount_weight / total_weight,
            'insurance_type': insurance_weight / total_weight
        }
    
    # ë©”ì¸ íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“Š ì „ì²´ í˜„í™©", 
        "ğŸ”„ í”„ë¡œì„¸ìŠ¤ íë¦„", 
        "ğŸ”® ì˜ˆì¸¡ ë° ê²€ìƒ‰", 
        "ğŸ“ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ"
    ])
    
    with tab1:
        create_overview_dashboard(df)
    
    with tab2:
        create_process_flow_analysis(df)
    
    with tab3:
        create_prediction_interface(analysis_system, df)
    
    with tab4:
        create_analytics_dashboard(analysis_system, df)
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 1rem;">
        <p>ğŸ¢ ë³´í—˜ì‚¬ê³  íŒì • íë¦„ ë¶„ì„ ë° ì˜ˆì¸¡ ì‹œìŠ¤í…œ</p>
        <small>ì‹¤ë¬´ì§„ì˜ ì˜ì‚¬ê²°ì • ì§€ì›ì„ ìœ„í•œ AI ê¸°ë°˜ ë¶„ì„ ë„êµ¬</small>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()