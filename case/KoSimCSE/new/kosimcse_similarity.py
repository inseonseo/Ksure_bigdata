import streamlit as st
import pandas as pd
import numpy as np
import torch
from transformers import AutoModel, AutoTokenizer
from sklearn.metrics.pairwise import cosine_similarity
import pickle
import os
from typing import List, Tuple
import re

class KoSimCSESimilaritySearch:
    def __init__(self, model_name="BM-K/KoSimCSE-roberta-multitask"):
        """KoSimCSE ëª¨ë¸ì„ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê²€ìƒ‰ í´ë˜ìŠ¤"""
        self.model_name = model_name
        self.tokenizer = None
        self.model = None
        self.embeddings_cache = {}
        self.cache_file = "kosimcse_embeddings_cache.pkl"
        
    def load_model(self):
        """KoSimCSE ëª¨ë¸ ë¡œë“œ"""
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModel.from_pretrained(self.model_name)
            self.model.eval()
            return True
        except Exception as e:
            st.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        if pd.isna(text) or text == '':
            return ""
        
        # ê¸°ë³¸ì ì¸ ì „ì²˜ë¦¬
        text = str(text).strip()
        
        # ì˜ë¯¸ì—†ëŠ” í…ìŠ¤íŠ¸ í•„í„°ë§
        meaningless_patterns = [
            r'^ì„¤ëª…ì—†ìŒ$', r'^ì²¨ë¶€íŒŒì¼ì°¸ê³ $', r'^í•´ë‹¹ì—†ìŒ$', r'^-$',
            r'^ì—†ìŒ$', r'^ê¸°íƒ€$', r'^ë¯¸ìƒ$'
        ]
        
        for pattern in meaningless_patterns:
            if re.match(pattern, text, re.IGNORECASE):
                return ""
        
        return text
    
    def get_embeddings(self, texts: List[str], batch_size: int = 16) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        if self.model is None or self.tokenizer is None:
            raise ValueError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        embeddings = []
        
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]
            
            # í† í°í™”
            inputs = self.tokenizer(
                batch_texts,
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors="pt"
            )
            
            # ì„ë² ë”© ìƒì„±
            with torch.no_grad():
                outputs = self.model(**inputs)
                # [CLS] í† í°ì˜ ì„ë² ë”© ì‚¬ìš©
                batch_embeddings = outputs.last_hidden_state[:, 0, :].numpy()
                embeddings.extend(batch_embeddings)
        
        return np.array(embeddings)
    
    def load_embeddings_cache(self) -> bool:
        """ìºì‹œëœ ì„ë² ë”© ë¡œë“œ"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'rb') as f:
                    self.embeddings_cache = pickle.load(f)
                return True
        except Exception as e:
            st.warning(f"ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False
    
    def save_embeddings_cache(self):
        """ì„ë² ë”© ìºì‹œ ì €ì¥"""
        try:
            with open(self.cache_file, 'wb') as f:
                pickle.dump(self.embeddings_cache, f)
        except Exception as e:
            st.warning(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def compute_similarity(self, query_text: str, candidate_texts: List[str], 
                          candidate_data: pd.DataFrame) -> List[Tuple[float, pd.Series]]:
        """ì¿¼ë¦¬ í…ìŠ¤íŠ¸ì™€ í›„ë³´ í…ìŠ¤íŠ¸ë“¤ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°"""
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        query_processed = self.preprocess_text(query_text)
        if not query_processed:
            return []
        
        candidate_processed = [self.preprocess_text(text) for text in candidate_texts]
        valid_indices = [i for i, text in enumerate(candidate_processed) if text]
        
        if not valid_indices:
            return []
        
        # ìœ íš¨í•œ í…ìŠ¤íŠ¸ë“¤ë§Œ ì„ íƒ
        valid_texts = [candidate_processed[i] for i in valid_indices]
        valid_data = candidate_data.iloc[valid_indices]
        
        # ì„ë² ë”© ê³„ì‚°
        try:
            query_embedding = self.get_embeddings([query_processed])
            candidate_embeddings = self.get_embeddings(valid_texts)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = cosine_similarity(query_embedding, candidate_embeddings)[0]
            
            # ê²°ê³¼ ì •ë ¬
            results = []
            for i, similarity in enumerate(similarities):
                results.append((similarity, valid_data.iloc[i]))
            
            results.sort(key=lambda x: x[0], reverse=True)
            return results
            
        except Exception as e:
            st.error(f"ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return []

def create_advanced_similarity_search(df, df_meaningful):
    """ê³ ê¸‰ ìœ ì‚¬ë„ ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤"""
    st.subheader("ğŸ¤– KoSimCSE ê¸°ë°˜ ê³ ê¸‰ ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰")
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    if 'similarity_model' not in st.session_state:
        st.session_state.similarity_model = KoSimCSESimilaritySearch()
    
    similarity_model = st.session_state.similarity_model
    
    # ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸
    if similarity_model.model is None:
        with st.spinner("KoSimCSE ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘..."):
            if not similarity_model.load_model():
                st.error("ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ TF-IDF ê¸°ë°˜ ê²€ìƒ‰ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
                return
        st.success("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    
    # ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤
    col1, col2 = st.columns([2, 1])
    
    with col1:
        query_text = st.text_area(
            "ì‚¬ê³ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”:",
            placeholder="ì˜ˆ: ìˆ˜ì…ìê°€ ëŒ€ê¸ˆ ì§€ê¸‰ì„ ì§€ì—°í•˜ì—¬ ë°œìƒí•œ ì‚¬ê³ ì…ë‹ˆë‹¤. L/C ì¡°ê±´ì´ì—ˆìœ¼ë‚˜ ìˆ˜ì…ìì˜ ì¬ì •ìƒí™© ì•…í™”ë¡œ...",
            height=120
        )
    
    with col2:
        st.write("**ê²€ìƒ‰ ì˜µì…˜:**")
        
        # ì¶”ê°€ í•„í„° ì¡°ê±´
        filter_country = st.selectbox(
            "ìˆ˜ì…êµ­ í•„í„°:",
            ['ì „ì²´'] + list(df['ìˆ˜ì…êµ­'].value_counts().head(15).index)
        )
        
        filter_accident_type = st.selectbox(
            "ì‚¬ê³ ìœ í˜• í•„í„°:",
            ['ì „ì²´'] + list(df['ì‚¬ê³ ìœ í˜•ëª…'].value_counts().head(10).index)
        )
        
        filter_decision = st.selectbox(
            "íŒì •êµ¬ë¶„ í•„í„°:",
            ['ì „ì²´'] + list(df['íŒì •êµ¬ë¶„'].unique())
        )
        
        max_results = st.slider("ìµœëŒ€ ê²°ê³¼ ìˆ˜:", 5, 20, 10)
    
    if query_text and st.button("ğŸ” ê³ ê¸‰ ê²€ìƒ‰ ì‹¤í–‰", type="primary"):
        with st.spinner("ìœ ì‚¬ì‚¬ë¡€ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
            # í•„í„°ë§ ì ìš©
            filtered_df = df_meaningful.copy()
            
            if filter_country != 'ì „ì²´':
                filtered_df = filtered_df[filtered_df['ìˆ˜ì…êµ­'] == filter_country]
            if filter_accident_type != 'ì „ì²´':
                filtered_df = filtered_df[filtered_df['ì‚¬ê³ ìœ í˜•ëª…'] == filter_accident_type]
            if filter_decision != 'ì „ì²´':
                filtered_df = filtered_df[filtered_df['íŒì •êµ¬ë¶„'] == filter_decision]
            
            if len(filtered_df) == 0:
                st.warning("í•„í„° ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ìœ ì‚¬ë„ ê³„ì‚°
            candidate_texts = filtered_df['ì‚¬ê³ ì„¤ëª…'].tolist()
            results = similarity_model.compute_similarity(query_text, candidate_texts, filtered_df)
            
            if not results:
                st.warning("ìœ ì‚¬í•œ ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ê²°ê³¼ í‘œì‹œ
            st.write(f"**ğŸ¯ ìƒìœ„ {min(len(results), max_results)}ê°œ ìœ ì‚¬ì‚¬ë¡€:**")
            
            # ìœ ì‚¬ë„ ë¶„í¬ ì‹œê°í™”
            similarities = [result[0] for result in results[:max_results]]
            
            import plotly.express as px
            fig = px.bar(
                x=list(range(1, len(similarities) + 1)),
                y=similarities,
                title="ìœ ì‚¬ë„ ì ìˆ˜ ë¶„í¬",
                labels={'x': 'ìˆœìœ„', 'y': 'ìœ ì‚¬ë„ ì ìˆ˜'}
            )
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
            
            # ìƒì„¸ ê²°ê³¼
            for i, (similarity, case) in enumerate(results[:max_results]):
                with st.expander(f"#{i+1} ìœ ì‚¬ë„ {similarity:.4f} - {case['íŒì •êµ¬ë¶„']} ({case['ì‚¬ê³ ìœ í˜•ëª…']})"):
                    
                    # ìœ ì‚¬ë„ ì‹œê°ì  í‘œì‹œ
                    similarity_pct = similarity * 100
                    st.progress(similarity_pct / 100)
                    st.caption(f"ìœ ì‚¬ë„: {similarity_pct:.1f}%")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**ğŸ“‹ ê¸°ë³¸ì •ë³´**")
                        st.write(f"â€¢ ë³´ìƒíŒŒì¼ë²ˆí˜¸: `{case['ë³´ìƒíŒŒì¼ë²ˆí˜¸']}`")
                        st.write(f"â€¢ ì‚¬ê³ ë²ˆí˜¸: `{case['ì‚¬ê³ ë²ˆí˜¸']}`")
                        st.write(f"â€¢ ìˆ˜ì…êµ­: **{case['ìˆ˜ì…êµ­']}**")
                        st.write(f"â€¢ ë³´í—˜ì¢…ëª©: {case['ë³´í—˜ì¢…ëª©']}")
                        st.write(f"â€¢ ìƒí’ˆë¶„ë¥˜: {case['ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…']}")
                        
                        if pd.notna(case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']):
                            amount_str = f"{case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']:,.0f}ì›"
                            if case['ì›í™”ì‚¬ê³ ê¸ˆì•¡'] >= 100000000:
                                amount_str += f" ({case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']/100000000:.1f}ì–µì›)"
                            st.write(f"â€¢ ì‚¬ê³ ê¸ˆì•¡: **{amount_str}**")
                    
                    with col2:
                        st.write("**âš–ï¸ íŒì •ì •ë³´**")
                        
                        # íŒì •êµ¬ë¶„ì— ë”°ë¥¸ ìƒ‰ìƒ í‘œì‹œ
                        if case['íŒì •êµ¬ë¶„'] == 'ì§€ê¸‰':
                            st.success(f"íŒì •êµ¬ë¶„: {case['íŒì •êµ¬ë¶„']}")
                        elif case['íŒì •êµ¬ë¶„'] == 'ë©´ì±…':
                            st.error(f"íŒì •êµ¬ë¶„: {case['íŒì •êµ¬ë¶„']}")
                        else:
                            st.info(f"íŒì •êµ¬ë¶„: {case['íŒì •êµ¬ë¶„']}")
                        
                        st.write(f"â€¢ íŒì •ì‚¬ìœ : **{case['íŒì •ì‚¬ìœ ']}**")
                        st.write(f"â€¢ íŒì •íšŒì°¨: {case['íŒì •íšŒì°¨']}íšŒ")
                        st.write(f"â€¢ ì‚¬ê³ ì§„í–‰ìƒíƒœ: {case['ì‚¬ê³ ì§„í–‰ìƒíƒœ']}")
                        
                        if pd.notna(case['í–¥í›„ê²°ì œì „ë§']) and case['í–¥í›„ê²°ì œì „ë§'] != 'íŒë‹¨ë¶ˆê°€':
                            st.write(f"â€¢ í–¥í›„ê²°ì œì „ë§: {case['í–¥í›„ê²°ì œì „ë§']}")
                    
                    st.write("**ğŸ“ ì‚¬ê³ ì„¤ëª…**")
                    st.markdown(f"> {case['ì‚¬ê³ ì„¤ëª…']}")
                    
                    # í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŒ… (ê°„ë‹¨í•œ ë°©ì‹)
                    query_words = set(query_text.split())
                    case_words = set(case['ì‚¬ê³ ì„¤ëª…'].split())
                    common_words = query_words.intersection(case_words)
                    
                    if common_words:
                        st.write("**ğŸ”‘ ê³µí†µ í‚¤ì›Œë“œ:**")
                        st.write(" â€¢ ".join([f"`{word}`" for word in common_words if len(word) > 1]))

def create_similarity_analysis_dashboard(df):
    """ìœ ì‚¬ë„ ë¶„ì„ ëŒ€ì‹œë³´ë“œ"""
    st.subheader("ğŸ“Š ìœ ì‚¬ë„ ê²€ìƒ‰ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # ì‚¬ê³ ì„¤ëª… ê¸¸ì´ë³„ ë¶„í¬
        df_text = df[df['ì‚¬ê³ ì„¤ëª…'].notna()].copy()
        df_text['ì„¤ëª…_ê¸¸ì´'] = df_text['ì‚¬ê³ ì„¤ëª…'].str.len()
        
        length_bins = [0, 20, 50, 100, 200, 500, float('inf')]
        length_labels = ['20ì ë¯¸ë§Œ', '20-50ì', '50-100ì', '100-200ì', '200-500ì', '500ì ì´ìƒ']
        df_text['ê¸¸ì´_êµ¬ê°„'] = pd.cut(df_text['ì„¤ëª…_ê¸¸ì´'], bins=length_bins, labels=length_labels)
        
        length_dist = df_text['ê¸¸ì´_êµ¬ê°„'].value_counts()
        
        import plotly.express as px
        fig1 = px.bar(
            x=length_dist.index,
            y=length_dist.values,
            title="ì‚¬ê³ ì„¤ëª… ê¸¸ì´ë³„ ë¶„í¬",
            labels={'x': 'ê¸¸ì´ êµ¬ê°„', 'y': 'ê±´ìˆ˜'}
        )
        fig1.update_layout(height=400)
        st.plotly_chart(fig1, use_container_width=True)
    
    with col2:
        # íŒì •êµ¬ë¶„ë³„ í‰ê·  ì„¤ëª… ê¸¸ì´
        avg_length_by_decision = df_text.groupby('íŒì •êµ¬ë¶„')['ì„¤ëª…_ê¸¸ì´'].mean().sort_values(ascending=False)
        
        fig2 = px.bar(
            x=avg_length_by_decision.values,
            y=avg_length_by_decision.index,
            orientation='h',
            title="íŒì •êµ¬ë¶„ë³„ í‰ê·  ì„¤ëª… ê¸¸ì´",
            labels={'x': 'í‰ê·  ê¸¸ì´ (ì)', 'y': 'íŒì •êµ¬ë¶„'}
        )
        fig2.update_layout(height=400)
        st.plotly_chart(fig2, use_container_width=True)
    
    # í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„
    st.write("**ğŸ“ í…ìŠ¤íŠ¸ ë°ì´í„° í’ˆì§ˆ ë¶„ì„**")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        meaningful_count = len(df_text[
            (df_text['ì„¤ëª…_ê¸¸ì´'] > 10) &
            (~df_text['ì‚¬ê³ ì„¤ëª…'].str.contains('ì„¤ëª…ì—†ìŒ|ì²¨ë¶€íŒŒì¼ì°¸ê³ |í•´ë‹¹ì—†ìŒ', na=False, case=False))
        ])
        st.metric("ì˜ë¯¸ìˆëŠ” ì„¤ëª…", f"{meaningful_count:,}ê±´", f"{meaningful_count/len(df)*100:.1f}%")
    
    with col2:
        short_count = len(df_text[df_text['ì„¤ëª…_ê¸¸ì´'] <= 10])
        st.metric("ì§§ì€ ì„¤ëª…", f"{short_count:,}ê±´", f"{short_count/len(df)*100:.1f}%")
    
    with col3:
        long_count = len(df_text[df_text['ì„¤ëª…_ê¸¸ì´'] > 100])
        st.metric("ìƒì„¸í•œ ì„¤ëª…", f"{long_count:,}ê±´", f"{long_count/len(df)*100:.1f}%")
    
    with col4:
        avg_length = df_text['ì„¤ëª…_ê¸¸ì´'].mean()
        st.metric("í‰ê·  ì„¤ëª… ê¸¸ì´", f"{avg_length:.1f}ì")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    st.title("ğŸ¤– KoSimCSE ê¸°ë°˜ ê³ ê¸‰ ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰")
    
    # ë°ì´í„° ë¡œë“œ
    @st.cache_data
    def load_data():
        try:
            df = pd.read_csv('KoSimCSE/new/design.csv', encoding='cp949')
            
            # ì˜ë¯¸ìˆëŠ” ì‚¬ê³ ì„¤ëª…ë§Œ í•„í„°ë§
            df_meaningful = df[
                (df['ì‚¬ê³ ì„¤ëª…'].notna()) & 
                (df['ì‚¬ê³ ì„¤ëª…'].str.len() > 10) &
                (~df['ì‚¬ê³ ì„¤ëª…'].str.contains('ì„¤ëª…ì—†ìŒ|ì²¨ë¶€íŒŒì¼ì°¸ê³ |í•´ë‹¹ì—†ìŒ', na=False, case=False))
            ].copy()
            
            return df, df_meaningful
        except Exception as e:
            st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None, None
    
    df, df_meaningful = load_data()
    if df is None:
        return
    
    # íƒ­ êµ¬ì„±
    tab1, tab2 = st.tabs(["ğŸ” ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰", "ğŸ“Š ë¶„ì„ ëŒ€ì‹œë³´ë“œ"])
    
    with tab1:
        create_advanced_similarity_search(df, df_meaningful)
    
    with tab2:
        create_similarity_analysis_dashboard(df)

if __name__ == "__main__":
    main()