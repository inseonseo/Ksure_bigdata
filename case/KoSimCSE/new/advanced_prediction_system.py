import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import seaborn as sns
import matplotlib.pyplot as plt
from collections import Counter
import pickle
import warnings
warnings.filterwarnings('ignore')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë³´í—˜ì‚¬ê³  ì˜ˆì¸¡ ë° ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰ ì‹œìŠ¤í…œ",
    page_icon="ğŸ”®",
    layout="wide",
    initial_sidebar_state="expanded"
)

class InsurancePredictionSystem:
    def __init__(self):
        self.model = None
        self.text_vectorizer = None
        self.label_encoders = {}
        self.feature_importance = None
        self.optimal_weights = {
            'text_similarity': 0.4,
            'accident_type': 0.2,
            'country': 0.15,
            'amount_range': 0.15,
            'insurance_type': 0.1
        }
    
    def preprocess_features(self, df):
        """íŠ¹ì„± ì „ì²˜ë¦¬"""
        df_processed = df.copy()
        
        # ê¸ˆì•¡ êµ¬ê°„ ìƒì„±
        df_processed['ê¸ˆì•¡êµ¬ê°„'] = pd.cut(
            df_processed['ì›í™”ì‚¬ê³ ê¸ˆì•¡'].fillna(0),
            bins=[0, 10000000, 50000000, 100000000, 500000000, float('inf')],
            labels=['1ì²œë§Œì›ë¯¸ë§Œ', '1ì²œë§Œ-5ì²œë§Œì›', '5ì²œë§Œ-1ì–µì›', '1ì–µ-5ì–µì›', '5ì–µì›ì´ìƒ']
        )
        
        # ì‚¬ê³ ìœ í˜• ê·¸ë£¹í™” (ì‹ ìš©ìœ„í—˜ ê³„ì—´ í†µí•©)
        df_processed['ì‚¬ê³ ìœ í˜•ê·¸ë£¹'] = df_processed['ì‚¬ê³ ìœ í˜•ëª…'].apply(self._group_accident_type)
        
        # í…ìŠ¤íŠ¸ íŠ¹ì„± ì¶”ì¶œ
        df_processed['ì‚¬ê³ ì„¤ëª…_ê¸¸ì´'] = df_processed['ì‚¬ê³ ì„¤ëª…'].fillna('').str.len()
        df_processed['ì‚¬ê³ ì„¤ëª…_ìœ íš¨'] = (
            (df_processed['ì‚¬ê³ ì„¤ëª…'].notna()) & 
            (df_processed['ì‚¬ê³ ì„¤ëª…'].str.len() > 10) &
            (~df_processed['ì‚¬ê³ ì„¤ëª…'].str.contains('ì„¤ëª…ì—†ìŒ|ì²¨ë¶€íŒŒì¼ì°¸ê³ |í•´ë‹¹ì—†ìŒ', na=False, case=False))
        )
        
        return df_processed
    
    def _group_accident_type(self, accident_type):
        """ì‚¬ê³ ìœ í˜• ê·¸ë£¹í™”"""
        if pd.isna(accident_type):
            return 'ê¸°íƒ€'
        
        if 'ì‹ ìš©ìœ„í—˜' in accident_type:
            if 'ì§€ê¸‰ì§€ì²´' in accident_type:
                return 'ì‹ ìš©ìœ„í—˜-ì§€ê¸‰ì§€ì²´'
            elif 'íŒŒì‚°' in accident_type:
                return 'ì‹ ìš©ìœ„í—˜-íŒŒì‚°'
            elif 'ì§€ê¸‰ë¶ˆëŠ¥' in accident_type or 'ì§€ê¸‰ê±°ì ˆ' in accident_type:
                return 'ì‹ ìš©ìœ„í—˜-ì§€ê¸‰ë¶ˆëŠ¥/ê±°ì ˆ'
            else:
                return 'ì‹ ìš©ìœ„í—˜-ê¸°íƒ€'
        elif 'ë¹„ìƒìœ„í—˜' in accident_type:
            return 'ë¹„ìƒìœ„í—˜'
        elif 'ê²€ì—­ìœ„í—˜' in accident_type:
            return 'ê²€ì—­ìœ„í—˜'
        else:
            return 'ê¸°íƒ€ìœ„í—˜'
    
    def train_prediction_model(self, df):
        """ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ"""
        df_processed = self.preprocess_features(df)
        
        # í…ìŠ¤íŠ¸ ë²¡í„°í™” (ì˜ë¯¸ìˆëŠ” ì„¤ëª…ë§Œ)
        meaningful_texts = df_processed[df_processed['ì‚¬ê³ ì„¤ëª…_ìœ íš¨']]['ì‚¬ê³ ì„¤ëª…'].fillna('')
        if len(meaningful_texts) > 100:  # ìµœì†Œ 100ê°œ ì´ìƒì˜ ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ê°€ ìˆì„ ë•Œë§Œ
            self.text_vectorizer = TfidfVectorizer(
                max_features=200,
                ngram_range=(1, 2),
                min_df=2,
                stop_words=None
            )
            text_features = self.text_vectorizer.fit_transform(meaningful_texts)
            text_df = pd.DataFrame(
                text_features.toarray(), 
                columns=[f'text_feature_{i}' for i in range(text_features.shape[1])],
                index=meaningful_texts.index
            )
        else:
            text_df = pd.DataFrame()
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        categorical_features = ['ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©', 'ì‚¬ê³ ìœ í˜•ê·¸ë£¹', 'ê¸ˆì•¡êµ¬ê°„', 'ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…']
        
        for feature in categorical_features:
            le = LabelEncoder()
            df_processed[f'{feature}_encoded'] = le.fit_transform(df_processed[feature].fillna('Unknown'))
            self.label_encoders[feature] = le
        
        # íŠ¹ì„± ì„ íƒ
        feature_columns = [f'{feature}_encoded' for feature in categorical_features]
        feature_columns.extend(['ì‚¬ê³ ì„¤ëª…_ê¸¸ì´', 'ì›í™”ì‚¬ê³ ê¸ˆì•¡'])
        
        X = df_processed[feature_columns].fillna(0)
        
        # í…ìŠ¤íŠ¸ íŠ¹ì„± ì¶”ê°€ (ê°€ëŠ¥í•œ ê²½ìš°)
        if not text_df.empty:
            # ì¸ë±ìŠ¤ ë§ì¶”ê¸°
            X_with_text = X.join(text_df, how='left').fillna(0)
        else:
            X_with_text = X
        
        y = df_processed['íŒì •êµ¬ë¶„']
        
        # í•™ìŠµ/ê²€ì¦ ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X_with_text, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # ëª¨ë¸ í•™ìŠµ
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            class_weight='balanced'
        )
        
        self.model.fit(X_train, y_train)
        
        # íŠ¹ì„± ì¤‘ìš”ë„
        self.feature_importance = pd.DataFrame({
            'feature': X_with_text.columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        y_pred = self.model.predict(X_test)
        
        return {
            'train_score': self.model.score(X_train, y_train),
            'test_score': self.model.score(X_test, y_test),
            'classification_report': classification_report(y_test, y_pred, output_dict=True),
            'feature_importance': self.feature_importance
        }
    
    def predict_case(self, case_data):
        """ê°œë³„ ì‚¬ë¡€ ì˜ˆì¸¡"""
        if self.model is None:
            return None
        
        # íŠ¹ì„± ì „ì²˜ë¦¬
        processed_case = self.preprocess_features(pd.DataFrame([case_data]))
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        categorical_features = ['ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©', 'ì‚¬ê³ ìœ í˜•ê·¸ë£¹', 'ê¸ˆì•¡êµ¬ê°„', 'ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…']
        
        for feature in categorical_features:
            if feature in self.label_encoders:
                try:
                    processed_case[f'{feature}_encoded'] = self.label_encoders[feature].transform(
                        processed_case[feature].fillna('Unknown')
                    )
                except ValueError:
                    # ìƒˆë¡œìš´ ì¹´í…Œê³ ë¦¬ì¸ ê²½ìš° ê°€ì¥ ë¹ˆë²ˆí•œ ê°’ìœ¼ë¡œ ëŒ€ì²´
                    processed_case[f'{feature}_encoded'] = 0
        
        # íŠ¹ì„± ì„ íƒ
        feature_columns = [f'{feature}_encoded' for feature in categorical_features]
        feature_columns.extend(['ì‚¬ê³ ì„¤ëª…_ê¸¸ì´', 'ì›í™”ì‚¬ê³ ê¸ˆì•¡'])
        
        X = processed_case[feature_columns].fillna(0)
        
        # í…ìŠ¤íŠ¸ íŠ¹ì„± ì¶”ê°€ (ê°€ëŠ¥í•œ ê²½ìš°)
        if self.text_vectorizer and 'ì‚¬ê³ ì„¤ëª…' in case_data:
            try:
                text_features = self.text_vectorizer.transform([case_data['ì‚¬ê³ ì„¤ëª…']])
                text_df = pd.DataFrame(
                    text_features.toarray(), 
                    columns=[f'text_feature_{i}' for i in range(text_features.shape[1])]
                )
                X = pd.concat([X.reset_index(drop=True), text_df], axis=1)
            except:
                pass
        
        # ì˜ˆì¸¡
        prediction = self.model.predict(X)[0]
        prediction_proba = self.model.predict_proba(X)[0]
        
        # í´ë˜ìŠ¤ë³„ í™•ë¥ 
        classes = self.model.classes_
        probabilities = {cls: prob for cls, prob in zip(classes, prediction_proba)}
        
        return {
            'prediction': prediction,
            'probabilities': probabilities,
            'confidence': max(prediction_proba)
        }
    
    def calculate_similarity_score(self, query_case, candidate_case, df_all):
        """ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        weights = self.optimal_weights
        
        # 1. í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ (KoSimCSE ë˜ëŠ” TF-IDF ê¸°ë°˜)
        if 'text_similarity' in weights and 'ì‚¬ê³ ì„¤ëª…' in query_case and 'ì‚¬ê³ ì„¤ëª…' in candidate_case:
            # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ (ì‹¤ì œë¡œëŠ” KoSimCSE ì‚¬ìš©)
            query_words = set(str(query_case['ì‚¬ê³ ì„¤ëª…']).split())
            candidate_words = set(str(candidate_case['ì‚¬ê³ ì„¤ëª…']).split())
            
            if query_words and candidate_words:
                jaccard_sim = len(query_words.intersection(candidate_words)) / len(query_words.union(candidate_words))
                score += weights['text_similarity'] * jaccard_sim
        
        # 2. ì‚¬ê³ ìœ í˜• ìœ ì‚¬ë„
        if 'accident_type' in weights:
            if query_case.get('ì‚¬ê³ ìœ í˜•ëª…') == candidate_case.get('ì‚¬ê³ ìœ í˜•ëª…'):
                score += weights['accident_type']
            elif self._group_accident_type(query_case.get('ì‚¬ê³ ìœ í˜•ëª…')) == self._group_accident_type(candidate_case.get('ì‚¬ê³ ìœ í˜•ëª…')):
                score += weights['accident_type'] * 0.7
        
        # 3. ìˆ˜ì…êµ­ ì¼ì¹˜
        if 'country' in weights and query_case.get('ìˆ˜ì…êµ­') == candidate_case.get('ìˆ˜ì…êµ­'):
            score += weights['country']
        
        # 4. ê¸ˆì•¡ëŒ€ ìœ ì‚¬ë„
        if 'amount_range' in weights:
            query_amount = query_case.get('ì›í™”ì‚¬ê³ ê¸ˆì•¡', 0)
            candidate_amount = candidate_case.get('ì›í™”ì‚¬ê³ ê¸ˆì•¡', 0)
            
            if query_amount > 0 and candidate_amount > 0:
                amount_ratio = min(query_amount, candidate_amount) / max(query_amount, candidate_amount)
                score += weights['amount_range'] * amount_ratio
        
        # 5. ë³´í—˜ì¢…ëª© ì¼ì¹˜
        if 'insurance_type' in weights and query_case.get('ë³´í—˜ì¢…ëª©') == candidate_case.get('ë³´í—˜ì¢…ëª©'):
            score += weights['insurance_type']
        
        return score

def create_prediction_interface(prediction_system, df):
    """ì˜ˆì¸¡ ì¸í„°í˜ì´ìŠ¤"""
    st.subheader("ğŸ”® ì‚¬ê³  íŒì • ì˜ˆì¸¡")
    
    st.write("ìƒˆë¡œìš´ ì‚¬ê³  ì •ë³´ë¥¼ ì…ë ¥í•˜ì—¬ ì˜ˆìƒ íŒì •ì„ í™•ì¸í•´ë³´ì„¸ìš”.")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ğŸ“‹ ê¸°ë³¸ ì •ë³´**")
        
        input_country = st.selectbox(
            "ìˆ˜ì…êµ­:",
            options=df['ìˆ˜ì…êµ­'].value_counts().head(20).index
        )
        
        input_insurance = st.selectbox(
            "ë³´í—˜ì¢…ëª©:",
            options=df['ë³´í—˜ì¢…ëª©'].value_counts().head(15).index
        )
        
        input_accident_type = st.selectbox(
            "ì‚¬ê³ ìœ í˜•:",
            options=df['ì‚¬ê³ ìœ í˜•ëª…'].value_counts().head(15).index
        )
        
        input_product_group = st.selectbox(
            "ìƒí’ˆë¶„ë¥˜ê·¸ë£¹:",
            options=['ì„ íƒì•ˆí•¨'] + list(df['ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…'].value_counts().head(15).index)
        )
    
    with col2:
        st.write("**ğŸ’° ê¸ˆì•¡ ì •ë³´**")
        
        input_amount = st.number_input(
            "ì‚¬ê³ ê¸ˆì•¡ (ì›):",
            min_value=0,
            value=50000000,
            step=1000000,
            format="%d"
        )
        
        st.write("**ğŸ“ ì‚¬ê³  ì„¤ëª…**")
        input_description = st.text_area(
            "ì‚¬ê³ ì„¤ëª…:",
            placeholder="ì‚¬ê³ ì˜ ìƒì„¸í•œ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”...",
            height=100
        )
    
    if st.button("ğŸ¯ íŒì • ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
        # ì…ë ¥ ë°ì´í„° êµ¬ì„±
        case_data = {
            'ìˆ˜ì…êµ­': input_country,
            'ë³´í—˜ì¢…ëª©': input_insurance,
            'ì‚¬ê³ ìœ í˜•ëª…': input_accident_type,
            'ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…': input_product_group if input_product_group != 'ì„ íƒì•ˆí•¨' else None,
            'ì›í™”ì‚¬ê³ ê¸ˆì•¡': input_amount,
            'ì‚¬ê³ ì„¤ëª…': input_description
        }
        
        # ì˜ˆì¸¡ ì‹¤í–‰
        if prediction_system.model is not None:
            prediction_result = prediction_system.predict_case(case_data)
            
            if prediction_result:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼**")
                    
                    predicted_decision = prediction_result['prediction']
                    confidence = prediction_result['confidence']
                    
                    # ì˜ˆì¸¡ ê²°ê³¼ì— ë”°ë¥¸ ìƒ‰ìƒ í‘œì‹œ
                    if predicted_decision == 'ì§€ê¸‰':
                        st.success(f"ì˜ˆìƒ íŒì •: **{predicted_decision}**")
                    elif predicted_decision == 'ë©´ì±…':
                        st.error(f"ì˜ˆìƒ íŒì •: **{predicted_decision}**")
                    else:
                        st.info(f"ì˜ˆìƒ íŒì •: **{predicted_decision}**")
                    
                    st.write(f"ì‹ ë¢°ë„: **{confidence:.1%}**")
                    
                    # ì‹ ë¢°ë„ ì‹œê°ì  í‘œì‹œ
                    st.progress(confidence)
                
                with col2:
                    st.write("**ğŸ“Š íŒì •ë³„ í™•ë¥ **")
                    
                    probabilities = prediction_result['probabilities']
                    prob_df = pd.DataFrame(list(probabilities.items()), columns=['íŒì •êµ¬ë¶„', 'í™•ë¥ '])
                    prob_df = prob_df.sort_values('í™•ë¥ ', ascending=False)
                    
                    fig = px.bar(
                        prob_df,
                        x='í™•ë¥ ',
                        y='íŒì •êµ¬ë¶„',
                        orientation='h',
                        title="íŒì •êµ¬ë¶„ë³„ ì˜ˆì¸¡ í™•ë¥ "
                    )
                    fig.update_layout(height=300)
                    st.plotly_chart(fig, use_container_width=True)
                
                # ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰
                st.write("**ğŸ” ìœ ì‚¬í•œ ì‚¬ë¡€ë“¤**")
                
                # ìœ ì‚¬ë„ ê¸°ë°˜ ìƒìœ„ ì‚¬ë¡€ ê²€ìƒ‰
                similarities = []
                for idx, row in df.iterrows():
                    sim_score = prediction_system.calculate_similarity_score(case_data, row, df)
                    similarities.append((sim_score, row))
                
                # ìƒìœ„ 5ê°œ ìœ ì‚¬ì‚¬ë¡€
                similarities.sort(key=lambda x: x[0], reverse=True)
                top_similar = similarities[:5]
                
                for i, (sim_score, similar_case) in enumerate(top_similar):
                    with st.expander(f"#{i+1} ìœ ì‚¬ë„ {sim_score:.3f} - {similar_case['íŒì •êµ¬ë¶„']} ({similar_case['ì‚¬ê³ ìœ í˜•ëª…']})"):
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write("**ğŸ“‹ ì‚¬ë¡€ ì •ë³´**")
                            st.write(f"â€¢ ìˆ˜ì…êµ­: {similar_case['ìˆ˜ì…êµ­']}")
                            st.write(f"â€¢ ë³´í—˜ì¢…ëª©: {similar_case['ë³´í—˜ì¢…ëª©']}")
                            st.write(f"â€¢ ì‚¬ê³ ê¸ˆì•¡: {similar_case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']:,.0f}ì›" if pd.notna(similar_case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']) else "â€¢ ì‚¬ê³ ê¸ˆì•¡: ì •ë³´ì—†ìŒ")
                        
                        with col2:
                            st.write("**âš–ï¸ íŒì • ê²°ê³¼**")
                            st.write(f"â€¢ íŒì •êµ¬ë¶„: **{similar_case['íŒì •êµ¬ë¶„']}**")
                            st.write(f"â€¢ íŒì •ì‚¬ìœ : {similar_case['íŒì •ì‚¬ìœ ']}")
                            st.write(f"â€¢ íŒì •íšŒì°¨: {similar_case['íŒì •íšŒì°¨']}íšŒ")
                        
                        if pd.notna(similar_case['ì‚¬ê³ ì„¤ëª…']) and len(str(similar_case['ì‚¬ê³ ì„¤ëª…'])) > 10:
                            st.write("**ğŸ“ ì‚¬ê³ ì„¤ëª…**")
                            st.write(f"_{similar_case['ì‚¬ê³ ì„¤ëª…']}_")

def create_model_analysis_dashboard(prediction_system, model_results):
    """ëª¨ë¸ ë¶„ì„ ëŒ€ì‹œë³´ë“œ"""
    st.subheader("ğŸ“Š ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„")
    
    if model_results is None:
        st.warning("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("í•™ìŠµ ì •í™•ë„", f"{model_results['train_score']:.3f}")
    with col2:
        st.metric("ê²€ì¦ ì •í™•ë„", f"{model_results['test_score']:.3f}")
    with col3:
        overfitting = model_results['train_score'] - model_results['test_score']
        st.metric("ê³¼ì í•© ì •ë„", f"{overfitting:.3f}")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # íŠ¹ì„± ì¤‘ìš”ë„
        if prediction_system.feature_importance is not None:
            top_features = prediction_system.feature_importance.head(15)
            
            fig1 = px.bar(
                top_features,
                x='importance',
                y='feature',
                orientation='h',
                title="ìƒìœ„ 15ê°œ íŠ¹ì„± ì¤‘ìš”ë„"
            )
            fig1.update_layout(height=500)
            st.plotly_chart(fig1, use_container_width=True)
    
    with col2:
        # ë¶„ë¥˜ ì„±ëŠ¥ íˆíŠ¸ë§µ
        report = model_results['classification_report']
        
        # precision, recall, f1-score ì¶”ì¶œ
        metrics_data = []
        for class_name, metrics in report.items():
            if isinstance(metrics, dict) and class_name not in ['accuracy', 'macro avg', 'weighted avg']:
                metrics_data.append({
                    'Class': class_name,
                    'Precision': metrics['precision'],
                    'Recall': metrics['recall'],
                    'F1-Score': metrics['f1-score']
                })
        
        if metrics_data:
            metrics_df = pd.DataFrame(metrics_data)
            
            fig2 = px.bar(
                metrics_df.melt(id_vars='Class', var_name='Metric', value_name='Score'),
                x='Class',
                y='Score',
                color='Metric',
                barmode='group',
                title="í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ì§€í‘œ"
            )
            fig2.update_layout(height=500, xaxis_tickangle=-45)
            st.plotly_chart(fig2, use_container_width=True)
    
    # ê°€ì¤‘ì¹˜ ìµœì í™” ê²°ê³¼
    st.write("**âš–ï¸ í˜„ì¬ ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜**")
    
    weights_df = pd.DataFrame(list(prediction_system.optimal_weights.items()), 
                             columns=['íŠ¹ì„±', 'ê°€ì¤‘ì¹˜'])
    
    fig3 = px.pie(
        weights_df,
        values='ê°€ì¤‘ì¹˜',
        names='íŠ¹ì„±',
        title="ìœ ì‚¬ë„ ê³„ì‚° ê°€ì¤‘ì¹˜ ë¶„í¬"
    )
    st.plotly_chart(fig3, use_container_width=True)

@st.cache_data
def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    try:
        df = pd.read_csv('data/design.csv', encoding='cp949')
        
        # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
        date_columns = ['íŒì •ì¼', 'íŒì •ê²°ì¬ì¼', 'ì‚¬ê³ ì ‘ìˆ˜ì¼ì', 'ë³´í—˜ê¸ˆì²­êµ¬ì¼']
        for col in date_columns:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce')
        
        # ê¸ˆì•¡ ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜
        amount_columns = ['ì›í™”ì‚¬ê³ ê¸ˆì•¡', 'ì›í™”íŒì •ê¸ˆì•¡']
        for col in amount_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def main():
    st.title("ğŸ”® ë³´í—˜ì‚¬ê³  ì˜ˆì¸¡ ë° ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰ ì‹œìŠ¤í…œ")
    st.markdown("""
    ì´ ì‹œìŠ¤í…œì€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ìƒˆë¡œìš´ ì‚¬ê³ ì˜ íŒì •ì„ ì˜ˆì¸¡í•˜ê³ ,
    ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°ìœ¼ë¡œ ê´€ë ¨ ì‚¬ë¡€ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """)
    st.markdown("---")
    
    # ë°ì´í„° ë¡œë“œ
    df = load_data()
    if df is None:
        return
    
    # ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if 'prediction_system' not in st.session_state:
        st.session_state.prediction_system = InsurancePredictionSystem()
        st.session_state.model_results = None
    
    prediction_system = st.session_state.prediction_system
    
    # ì‚¬ì´ë“œë°” - ëª¨ë¸ ì„¤ì •
    st.sidebar.header("ğŸ”§ ëª¨ë¸ ì„¤ì •")
    
    if st.sidebar.button("ğŸ“š ëª¨ë¸ í•™ìŠµ ì‹¤í–‰"):
        with st.spinner("ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ì¤‘..."):
            model_results = prediction_system.train_prediction_model(df)
            st.session_state.model_results = model_results
        st.sidebar.success("ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    
    # ê°€ì¤‘ì¹˜ ì¡°ì •
    st.sidebar.write("**âš–ï¸ ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜ ì¡°ì •**")
    
    text_weight = st.sidebar.slider("í…ìŠ¤íŠ¸ ìœ ì‚¬ë„", 0.0, 1.0, prediction_system.optimal_weights['text_similarity'])
    accident_weight = st.sidebar.slider("ì‚¬ê³ ìœ í˜•", 0.0, 1.0, prediction_system.optimal_weights['accident_type'])
    country_weight = st.sidebar.slider("ìˆ˜ì…êµ­", 0.0, 1.0, prediction_system.optimal_weights['country'])
    amount_weight = st.sidebar.slider("ê¸ˆì•¡ëŒ€", 0.0, 1.0, prediction_system.optimal_weights['amount_range'])
    insurance_weight = st.sidebar.slider("ë³´í—˜ì¢…ëª©", 0.0, 1.0, prediction_system.optimal_weights['insurance_type'])
    
    # ê°€ì¤‘ì¹˜ ì •ê·œí™”
    total_weight = text_weight + accident_weight + country_weight + amount_weight + insurance_weight
    if total_weight > 0:
        prediction_system.optimal_weights = {
            'text_similarity': text_weight / total_weight,
            'accident_type': accident_weight / total_weight,
            'country': country_weight / total_weight,
            'amount_range': amount_weight / total_weight,
            'insurance_type': insurance_weight / total_weight
        }
    
    # íƒ­ êµ¬ì„±
    tab1, tab2 = st.tabs(["ğŸ”® íŒì • ì˜ˆì¸¡", "ğŸ“Š ëª¨ë¸ ë¶„ì„"])
    
    with tab1:
        create_prediction_interface(prediction_system, df)
    
    with tab2:
        create_model_analysis_dashboard(prediction_system, st.session_state.model_results)

if __name__ == "__main__":
    main()