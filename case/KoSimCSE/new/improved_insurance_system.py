import numpy as np
# NumPy 2.0 compatibility aliases for removed dtypes
if not hasattr(np, "unicode_"):
    np.unicode_ = np.str_
if not hasattr(np, "string_"):
    np.string_ = np.bytes_
try:
    np.bool
except AttributeError:
    np.bool = np.bool_
try:
    np.object
except AttributeError:
    np.object = np.object_
try:
    np.int
except AttributeError:
    np.int = int
try:
    np.float
except AttributeError:
    np.float = float

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import torch
from collections import Counter
from scipy import stats
import pickle
import warnings
import re
import time
warnings.filterwarnings('ignore')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title=" ì‚¬ê³ ë³„ íŒì •ì‹¬ì‚¬ ì‚¬ë¡€ ë¶„ì„",
    page_icon="ğŸ“‹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ê¹”ë”í•œ CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        background-color: #f8f9fa;
        padding: 2rem;
        border-radius: 10px;
        border-left: 5px solid #007bff;
        margin-bottom: 2rem;
    }
    
    .metric-box {
        background-color: white;
        padding: 1.5rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #007bff;
        text-align: center;
    }
    
    .confidence-box {
        background-color: #e3f2fd;
        padding: 1.5rem;
        border-radius: 10px;
        border: 2px solid #2196f3;
        margin: 1rem 0;
    }
    
    .success-box {
        background-color: #e8f5e8;
        border: 2px solid #4caf50;
    }
    
    .error-box {
        background-color: #ffebee;
        border: 2px solid #f44336;
    }
    
    .warning-box {
        background-color: #fff3e0;
        border: 2px solid #ff9800;
    }
</style>
""", unsafe_allow_html=True)

class CountryProcessor:
    """ê°œì„ ëœ êµ­ê°€ ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # ê°œë³„ ìœ ì§€ êµ­ê°€ (ìƒìœ„ 16ê°œ)
        self.individual_countries = [
            'ë¯¸êµ­', 'ì¤‘êµ­', 'ë¸Œë¼ì§ˆ', 'ì¼ë³¸', 'ë…ì¼', 'ì˜êµ­', 'ëŸ¬ì‹œì•„', 'ì¸ë„',
            'ë² íŠ¸ë‚¨', 'ì´íƒˆë¦¬ì•„', 'í™ì½©', 'ì•„ëì—ë¯¸ë¦¬íŠ¸ì—°í•©', 'íŠ€ë¥´í‚¤ì˜ˆ', 
            'ì¸ë„ë„¤ì‹œì•„', 'ìŠ¤í˜ì¸', 'ëŒ€ë§Œ'
        ]
        
        # ì§€ì—­ë³„ ë¶„ë¥˜
        self.regions = {
            'asia': {
                'ê°œë³„': ['ì¤‘êµ­', 'ì¼ë³¸', 'ì¸ë„', 'ë² íŠ¸ë‚¨', 'í™ì½©', 'ëŒ€ë§Œ', 'ì¸ë„ë„¤ì‹œì•„'],
                'ê¸°íƒ€': ['íƒœêµ­', 'ë§ë ˆì´ì‹œì•„', 'í•„ë¦¬í•€', 'ì‹±ê°€í¬ë¥´', 'ë¯¸ì–€ë§ˆ', 'ìº„ë³´ë””ì•„', 'ëª½ê³¨', 'ë¶€íƒ„']
            },
            'europe': {
                'ê°œë³„': ['ë…ì¼', 'ì˜êµ­', 'ì´íƒˆë¦¬ì•„', 'ìŠ¤í˜ì¸'],
                'ê¸°íƒ€': ['í”„ë‘ìŠ¤', 'ë„¤ëœë€ë“œ', 'ë²¨ê¸°ì—„', 'ìŠ¤ìœ„ìŠ¤', 'ì˜¤ìŠ¤íŠ¸ë¦¬ì•„', 'ê·¸ë¦¬ìŠ¤', 'ëª°íƒ€', 'í—ê°€ë¦¬', 'ì²´ì½”', 'Estonia']
            },
            'americas': {
                'ê°œë³„': ['ë¯¸êµ­', 'ë¸Œë¼ì§ˆ'],
                'ê¸°íƒ€': ['ë©•ì‹œì½”', 'ì½œë¡¬ë¹„ì•„', 'ì•„ë¥´í—¨í‹°ë‚˜', 'í˜ë£¨', 'ì¹ ë ˆ', 'ê³¼í…Œë§ë¼', 'ë³¼ë¦¬ë¹„ì•„', 'ì˜¨ë‘ë¼ìŠ¤', 'íŒŒë‚˜ë§ˆ', 'ìë©”ì´ì¹´']
            },
            'middle_east': {
                'ê°œë³„': ['ì•„ëì—ë¯¸ë¦¬íŠ¸ì—°í•©', 'íŠ€ë¥´í‚¤ì˜ˆ'],
                'ê¸°íƒ€': ['ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„', 'ì¹´íƒ€ë¥´', 'ì¿ ì›¨ì´íŠ¸', 'ë°”ë ˆì¸', 'ì´ìŠ¤ë¼ì—˜']
            },
            'africa': {
                'ê°œë³„': [],
                'ê¸°íƒ€': ['ê°€ë‚˜', 'ì¼€ëƒ', 'ì„¸ë„¤ê°ˆ', 'ì—í‹°ì˜¤í”¼ì•„', 'ìš°ê°„ë‹¤', 'ë¥´ì™„ë‹¤', 'ê°€ë´‰', 'ê°ë¹„ì•„', 'ë¼ì´ë² ë¦¬ì•„', 'ë§ˆë‹¤ê°€ìŠ¤ì¹´ë¥´', 'ë§ë¼ìœ„', 'ëª¨ë¡œì½”', 'ë² ëƒ‰', 'ì‹œì—ë¼ë¦¬ì˜¨', 'í† ê³ ']
            },
            'oceania': {
                'ê°œë³„': [],
                'ê¸°íƒ€': ['í˜¸ì£¼', 'ë‰´ì§ˆëœë“œ']
            },
            'other': {
                'ê°œë³„': ['ëŸ¬ì‹œì•„'],
                'ê¸°íƒ€': ['ë¼íŠ¸ë¹„ì•„', 'ëª°ë„ë°”', 'ë§ˆì¼€ë„ë‹ˆì•„', 'ë³´ìŠ¤ë‹ˆì•„í—¤ë¥´ì²´ê³ ë¹„ë‚˜', 'ì„¸ë¥´ë¹„ì•„', 'ìŠ¬ë¡œë°”í‚¤ì•„', 'ìš°ì¦ˆë² í‚¤ìŠ¤íƒ„', 'ì¡°ì§€ì•„']
            }
        }
    
    def get_country_region(self, country):
        """êµ­ê°€ì˜ ì§€ì—­ ë°˜í™˜"""
        for region, countries in self.regions.items():
            if country in countries['ê°œë³„'] or country in countries['ê¸°íƒ€']:
                return region
        return 'other'
    
    def is_individual_country(self, country):
        """ê°œë³„ ìœ ì§€ êµ­ê°€ì¸ì§€ í™•ì¸"""
        return country in self.individual_countries
    
    def is_minor_country(self, country):
        """ì†Œê·œëª¨ êµ­ê°€ì¸ì§€ í™•ì¸"""
        for region, countries in self.regions.items():
            if country in countries['ê¸°íƒ€']:
                return True
        return False
    
    def preprocess_country(self, country):
        """êµ­ê°€ ì „ì²˜ë¦¬"""
        if pd.isna(country):
            return 'ì •ë³´ì—†ìŒ'
        
        # 1. ê°œë³„ ìœ ì§€ êµ­ê°€
        if country in self.individual_countries:
            return country
        
        # 2. ì§€ì—­ë³„ ê·¸ë£¹í™”
        region = self.get_country_region(country)
        if region != 'other':
            return f'{region}_ê¸°íƒ€'
        
        # 3. ì™„ì „íˆ ì•Œ ìˆ˜ ì—†ëŠ” êµ­ê°€
        return 'ê¸°íƒ€êµ­ê°€'
    
    def calculate_country_similarity(self, country1, country2):
        """ê³„ì¸µì  êµ­ê°€ ìœ ì‚¬ë„ ê³„ì‚°"""
        if pd.isna(country1) or pd.isna(country2):
            return 0.0
        
        # ì™„ì „ ì¼ì¹˜
        if country1 == country2:
            return 1.0
        
        region1 = self.get_country_region(country1)
        region2 = self.get_country_region(country2)
        
        is_individual1 = self.is_individual_country(country1)
        is_individual2 = self.is_individual_country(country2)
        is_minor1 = self.is_minor_country(country1)
        is_minor2 = self.is_minor_country(country2)
        
        # ë‘˜ ë‹¤ ê°œë³„ êµ­ê°€ì¸ ê²½ìš°
        if is_individual1 and is_individual2:
            return 0.6 if region1 == region2 else 0.3
        
        # ë‘˜ ë‹¤ ì†Œê·œëª¨ êµ­ê°€ì¸ ê²½ìš°
        if is_minor1 and is_minor2:
            return 0.7 if region1 == region2 else 0.4
        
        # í•˜ë‚˜ëŠ” ê°œë³„, í•˜ë‚˜ëŠ” ì†Œê·œëª¨ì¸ ê²½ìš°
        if (is_individual1 and is_minor2) or (is_minor1 and is_individual2):
            return 0.5 if region1 == region2 else 0.2
        
        # ê¸°íƒ€ ê²½ìš°
        return 0.2

class HybridConfidenceCalculator:
    """í•˜ì´ë¸Œë¦¬ë“œ ì‹ ë¢°ë„ ê³„ì‚°ê¸°"""
    
    @staticmethod
    def calculate_weighted_confidence(decisions, similarity_scores):
        """ê°€ì¤‘ ì‹ ë¢°ë„ ê³„ì‚°"""
        if not decisions or not similarity_scores:
            return 0.0, 'ì •ë³´ì—†ìŒ'
        
        # ê°€ì¥ ë§ì€ íŒì •êµ¬ë¶„ ì°¾ê¸°
        decision_counts = Counter(decisions)
        most_common_decision = decision_counts.most_common(1)[0][0]
        
        # í•´ë‹¹ íŒì •ì˜ ê°€ì¤‘ ì ìˆ˜ í•©
        weighted_sum = sum(score for decision, score in zip(decisions, similarity_scores) 
                          if decision == most_common_decision)
        total_weight = sum(similarity_scores)
        
        if total_weight == 0:
            return 0.0, most_common_decision
        
        return weighted_sum / total_weight, most_common_decision
    
    @staticmethod
    def calculate_bayesian_confidence(positive_count, total_count, confidence_level=0.95):
        """ë² ì´ì§€ì•ˆ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°"""
        if total_count == 0:
            return 0.0, (0.0, 0.0)
        
        # ë² íƒ€ ë¶„í¬ íŒŒë¼ë¯¸í„° (ë¬´ì •ë³´ ì‚¬ì „ë¶„í¬)
        alpha = 1 + positive_count
        beta = 1 + total_count - positive_count
        
        # ë² ì´ì§€ì•ˆ ì¶”ì •ê°’
        posterior_mean = alpha / (alpha + beta)
        
        # ì‹ ë¢°êµ¬ê°„
        alpha_level = 1 - confidence_level
        lower = stats.beta.ppf(alpha_level/2, alpha, beta)
        upper = stats.beta.ppf(1 - alpha_level/2, alpha, beta)
        
        return posterior_mean, (lower, upper)
    
    @classmethod
    def hybrid_confidence(cls, decisions, similarity_scores):
        """í•˜ì´ë¸Œë¦¬ë“œ ì‹ ë¢°ë„ ê³„ì‚°"""
        if not decisions:
            return {
                'confidence': 0.0,
                'credible_interval': (0.0, 0.0),
                'predicted_decision': 'ì •ë³´ì—†ìŒ',
                'sample_size': 0,
                'avg_similarity': 0.0,
                'interpretation': 'ìœ ì‚¬ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤.',
                'grade': 'ì‹ ë¢°ë¶ˆê°€'
            }
        
        # 1. ê°€ì¤‘ ì‹ ë¢°ë„ ê³„ì‚°
        weighted_conf, predicted_decision = cls.calculate_weighted_confidence(decisions, similarity_scores)
        
        # 2. ë² ì´ì§€ì•ˆ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
        positive_count = sum(1 for d in decisions if d == predicted_decision)
        bayesian_mean, (lower, upper) = cls.calculate_bayesian_confidence(positive_count, len(decisions))
        
        # 3. í‘œë³¸ í¬ê¸° ë° í’ˆì§ˆ ë³´ì •
        sample_size = len(decisions)
        avg_similarity = np.mean(similarity_scores) if similarity_scores else 0.0
        
        # í‘œë³¸ í¬ê¸° ë³´ì • (ë” ë³´ìˆ˜ì ìœ¼ë¡œ)
        if sample_size >= 10:
            sample_factor = 1.0
        elif sample_size >= 5:
            sample_factor = 0.9
        else:
            sample_factor = 0.8
        
        # ìœ ì‚¬ë„ í’ˆì§ˆ ë³´ì •
        if avg_similarity >= 0.7:
            quality_factor = 1.1
        elif avg_similarity >= 0.5:
            quality_factor = 1.0
        else:
            quality_factor = 0.9
        
        # ìµœì¢… ì‹ ë¢°ë„ (ê°€ì¤‘ ë°©ì‹ + ë³´ì •)
        final_confidence = min(0.95, weighted_conf * sample_factor * quality_factor)
        
        # ì‹ ë¢°ë„ ë“±ê¸‰
        if final_confidence >= 0.8 and sample_size >= 5:
            grade = 'ë†’ìŒ'
        elif final_confidence >= 0.6 and sample_size >= 3:
            grade = 'ë³´í†µ'
        else:
            grade = 'ë‚®ìŒ'
        
        # í•´ì„ ë©”ì‹œì§€
        interpretation = f"{final_confidence:.1%} (95% êµ¬ê°„: {lower:.1%}-{upper:.1%})"
        
        return {
            'confidence': final_confidence,
            'credible_interval': (lower, upper),
            'predicted_decision': predicted_decision,
            'sample_size': sample_size,
            'avg_similarity': avg_similarity,
            'interpretation': interpretation,
            'grade': grade,
            'bayesian_mean': bayesian_mean,
            'weighted_confidence': weighted_conf
        }

class ImprovedInsuranceSystem:
    def __init__(self):
        self.model = None
        self.kosimcse_model = None
        self.kosimcse_tokenizer = None
        self.text_vectorizer = None
        self.label_encoders = {}
        self.feature_importance = None
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.country_processor = CountryProcessor()
        self.confidence_calculator = HybridConfidenceCalculator()
        
        # ìµœì í™”ëœ ê°€ì¤‘ì¹˜ (í™•ì¥ëœ ë³€ìˆ˜ í¬í•¨)
        self.optimal_weights = {
            # í•µì‹¬ ë³€ìˆ˜ (ê°œë³„ ê°€ì¤‘ì¹˜)
            'text_similarity': 0.35,      # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
            'accident_type': 0.20,        # ì‚¬ê³ ìœ í˜•
            'country_similarity': 0.12,   # êµ­ê°€ ìœ ì‚¬ë„
            
            # ìˆ«ìí˜• ë³€ìˆ˜ ê·¸ë£¹ (15%)
            'amount_similarity': 0.08,    # ê¸ˆì•¡ ìœ ì‚¬ë„
            'coverage_rate': 0.05,        # ë¶€ë³´ìœ¨
            'payment_terms': 0.02,        # ê²°ì œì¡°ê±´
            
            # ë²”ì£¼í˜• ë³€ìˆ˜ ê·¸ë£¹ (18%)
            'insurance_type': 0.05,       # ë³´í—˜ì¢…ëª©
            'product_category': 0.08,     # ìƒí’ˆë¶„ë¥˜
            'payment_method': 0.04,       # ê²°ì œë°©ë²•
            'future_outlook': 0.01        # í–¥í›„ì „ë§
        }
        
        # ìºì‹œ ê´€ë¦¬
        self.embeddings_cache = {}
        self.similarity_cache = {}
        
        # ëŸ°íƒ€ì„ ê°€ì¤‘ì¹˜ ì˜¤ë²„ë¼ì´ë“œ(ì„¸ì…˜ ì¤‘ ì¼ì‹œ ì ìš©)
        self.runtime_weight_overrides = None
    
    @st.cache_resource
    def load_kosimcse_model(_self):
        """KoSimCSE ëª¨ë¸ ë¡œë“œ"""
        try:
            # Lazy import to avoid hard dependency at module import time
            from transformers import AutoModel, AutoTokenizer
            model_name = "BM-K/KoSimCSE-roberta-multitask"
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = AutoModel.from_pretrained(model_name)
            model.eval()
            return model, tokenizer
        except Exception as e:
            st.error(f"AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None, None
    
    def initialize_ai_model(self):
        """AI ëª¨ë¸ ì´ˆê¸°í™”"""
        if self.kosimcse_model is None:
            with st.spinner("AI ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘..."):
                self.kosimcse_model, self.kosimcse_tokenizer = self.load_kosimcse_model()
        return self.kosimcse_model is not None
    
    def preprocess_text(self, text):
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        if pd.isna(text) or text == '':
            return ""
        
        text = str(text).strip()
        
        # ì˜ë¯¸ì—†ëŠ” í…ìŠ¤íŠ¸ í•„í„°ë§
        meaningless_patterns = [
            r'^ì„¤ëª…ì—†ìŒ$', r'^ì²¨ë¶€íŒŒì¼ì°¸ê³ $', r'^í•´ë‹¹ì—†ìŒ$', r'^-$',
            r'^ì—†ìŒ$', r'^ê¸°íƒ€$', r'^ë¯¸ìƒ$'
        ]
        
        for pattern in meaningless_patterns:
            if re.match(pattern, text, re.IGNORECASE):
                return ""
        
        return text
    
    def get_text_embeddings(self, texts, batch_size=4):
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        if not self.initialize_ai_model():
            return None
        
        processed_texts = [self.preprocess_text(text) for text in texts]
        valid_texts = [text for text in processed_texts if text]
        
        if not valid_texts:
            return None
        
        embeddings = []
        
        try:
            # Lazy import torch to avoid ImportError if not installed
            import torch
            for i in range(0, len(valid_texts), batch_size):
                batch_texts = valid_texts[i:i + batch_size]
                
                inputs = self.kosimcse_tokenizer(
                    batch_texts,
                    padding=True,
                    truncation=True,
                    max_length=256,
                    return_tensors="pt"
                )
                
                with torch.no_grad():
                    outputs = self.kosimcse_model(**inputs)
                    batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()
                    embeddings.extend(batch_embeddings)
            
            return np.array(embeddings)
            
        except Exception as e:
            st.error(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None
    
    def smart_candidate_filtering(self, query_case, candidates_df, max_candidates=150):
        """ìŠ¤ë§ˆíŠ¸ í›„ë³´ í•„í„°ë§"""
        query_country = query_case.get('ìˆ˜ì…êµ­', '')
        
        # 1. ì¿¼ë¦¬ êµ­ê°€ê°€ ê°œë³„ ìœ ì§€ êµ­ê°€ì¸ ê²½ìš°
        if self.country_processor.is_individual_country(query_country):
            # ê°™ì€ êµ­ê°€ ìš°ì„ 
            same_country = candidates_df[candidates_df['ìˆ˜ì…êµ­'] == query_country]
            if len(same_country) >= 20:
                return same_country.sample(n=min(max_candidates, len(same_country)), random_state=42)
            
            # ê°™ì€ ì§€ì—­ìœ¼ë¡œ í™•ì¥
            query_region = self.country_processor.get_country_region(query_country)
            same_region = candidates_df[candidates_df['ìˆ˜ì…êµ­'].apply(
                lambda x: self.country_processor.get_country_region(x) == query_region
            )]
            if len(same_region) >= 50:
                return same_region.sample(n=min(max_candidates, len(same_region)), random_state=42)
        
        # 2. ì¿¼ë¦¬ êµ­ê°€ê°€ ì†Œê·œëª¨ êµ­ê°€ì¸ ê²½ìš°
        elif self.country_processor.is_minor_country(query_country):
            query_region = self.country_processor.get_country_region(query_country)
            
            # ê°™ì€ ì§€ì—­ì˜ ì†Œê·œëª¨ êµ­ê°€ë“¤ ìš°ì„ 
            same_region_minor = candidates_df[candidates_df['ìˆ˜ì…êµ­'].apply(
                lambda x: (self.country_processor.get_country_region(x) == query_region and 
                          self.country_processor.is_minor_country(x))
            )]
            
            if len(same_region_minor) >= 10:
                return same_region_minor.sample(n=min(max_candidates//2, len(same_region_minor)), random_state=42)
            
            # ê°™ì€ ì§€ì—­ ì „ì²´ë¡œ í™•ì¥
            same_region_all = candidates_df[candidates_df['ìˆ˜ì…êµ­'].apply(
                lambda x: self.country_processor.get_country_region(x) == query_region
            )]
            
            if len(same_region_all) >= 20:
                return same_region_all.sample(n=min(max_candidates, len(same_region_all)), random_state=42)
        
        # 3. ì „ì²´ ê²€ìƒ‰ (ë¬´ì‘ìœ„ ìƒ˜í”Œë§)
        return candidates_df.sample(n=min(max_candidates, len(candidates_df)), random_state=42)
    
    def calculate_similarity_scores(self, query_case, candidates_df):
        """ê°œì„ ëœ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°"""
        
        # 0) ë°ì´í„° ëˆ„ì¶œ ë°©ì§€: ë™ì¼ ì¼€ì´ìŠ¤/ì¤‘ë³µ í…ìŠ¤íŠ¸ í›„ë³´ ì œê±°
        safe_candidates = candidates_df.copy()
        try:
            # ë™ì¼ ì‚¬ê³ ë²ˆí˜¸/ë³´ìƒíŒŒì¼ë²ˆí˜¸ ë°°ì œ
            for key in ['ì‚¬ê³ ë²ˆí˜¸', 'ë³´ìƒíŒŒì¼ë²ˆí˜¸']:
                if key in safe_candidates.columns and key in query_case:
                    safe_candidates = safe_candidates[safe_candidates[key] != query_case.get(key)]
            # ë™ì¼ í…ìŠ¤íŠ¸(ì „ì²˜ë¦¬ í›„) ì™„ì „ ì¼ì¹˜ + ì£¼ìš” ë©”íƒ€ ë™ì¼ì‹œ ë°°ì œ
            q_text_norm = self.preprocess_text(query_case.get('ì‚¬ê³ ì„¤ëª…', ''))
            if q_text_norm:
                def _norm_text(x):
                    return self.preprocess_text(x)
                txt_eq = safe_candidates['ì‚¬ê³ ì„¤ëª…'].apply(_norm_text) == q_text_norm
                meta_eq = True
                if 'ìˆ˜ì…êµ­' in safe_candidates.columns and 'ìˆ˜ì…êµ­' in query_case:
                    meta_eq = meta_eq & (safe_candidates['ìˆ˜ì…êµ­'] == query_case.get('ìˆ˜ì…êµ­'))
                if 'ë³´í—˜ì¢…ëª©' in safe_candidates.columns and 'ë³´í—˜ì¢…ëª©' in query_case:
                    meta_eq = meta_eq & (safe_candidates['ë³´í—˜ì¢…ëª©'] == query_case.get('ë³´í—˜ì¢…ëª©'))
                dup_mask = txt_eq & meta_eq
                if dup_mask.any():
                    safe_candidates = safe_candidates[~dup_mask]
        except Exception:
            pass

        # ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ìœ¼ë¡œ í›„ë³´ ìˆ˜ ì œí•œ
        filtered_candidates = self.smart_candidate_filtering(query_case, safe_candidates)
        
        # ë©´ì±… ì‚¬ë¡€ì™€ ë¹„ë©´ì±… ì‚¬ë¡€ ë¶„ë¦¬
        exemption_candidates = filtered_candidates[filtered_candidates['íŒì •êµ¬ë¶„'] == 'ë©´ì±…']
        non_exemption_candidates = filtered_candidates[filtered_candidates['íŒì •êµ¬ë¶„'] != 'ë©´ì±…']
        
        similarities = []
        
        # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°
        query_text = query_case.get('ì‚¬ê³ ì„¤ëª…', '')
        if query_text and len(query_text) > 10:
            candidate_texts = filtered_candidates['ì‚¬ê³ ì„¤ëª…'].tolist()
            
            # AI ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
            all_texts = [query_text] + candidate_texts
            embeddings = self.get_text_embeddings(all_texts)
            
            if embeddings is not None and len(embeddings) > 1:
                query_embedding = embeddings[0:1]
                candidate_embeddings = embeddings[1:]
                text_similarities = cosine_similarity(query_embedding, candidate_embeddings)[0]
                
                # ë©´ì±… í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„ ë³´ì • ì ìš©
                text_similarities = self._apply_exemption_keyword_boost(
                    query_text, candidate_texts, text_similarities, filtered_candidates
                )
            else:
                # í´ë°±: ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
                text_similarities = []
                query_words = set(query_text.lower().split())
                for candidate_text in candidate_texts:
                    if pd.notna(candidate_text):
                        candidate_words = set(str(candidate_text).lower().split())
                        if query_words and candidate_words:
                            jaccard_sim = len(query_words.intersection(candidate_words)) / len(query_words.union(candidate_words))
                            text_similarities.append(jaccard_sim)
                        else:
                            text_similarities.append(0.0)
                    else:
                        text_similarities.append(0.0)
                text_similarities = np.array(text_similarities)
                
                # ë©´ì±… í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„ ë³´ì • ì ìš© (í´ë°±ì—ë„)
                text_similarities = self._apply_exemption_keyword_boost(
                    query_text, candidate_texts, text_similarities, filtered_candidates
                )
        else:
            text_similarities = np.zeros(len(filtered_candidates))
        
        # í†µí•© ìœ ì‚¬ë„ ê³„ì‚°
        for i, (idx, candidate) in enumerate(filtered_candidates.iterrows()):
            score = 0.0
            # ëŸ°íƒ€ì„ ì˜¤ë²„ë¼ì´ë“œê°€ ìˆìœ¼ë©´ ìš°ì„  ì ìš©
            weights = self.runtime_weight_overrides if self.runtime_weight_overrides else self.optimal_weights
            
            # 1. í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
            if i < len(text_similarities):
                score += weights['text_similarity'] * text_similarities[i]
            
            # 2. ì‚¬ê³ ìœ í˜• ìœ ì‚¬ë„
            if query_case.get('ì‚¬ê³ ìœ í˜•ëª…') == candidate.get('ì‚¬ê³ ìœ í˜•ëª…'):
                score += weights['accident_type']
            elif self._group_accident_type(query_case.get('ì‚¬ê³ ìœ í˜•ëª…')) == self._group_accident_type(candidate.get('ì‚¬ê³ ìœ í˜•ëª…')):
                score += weights['accident_type'] * 0.7
            
            # 3. êµ­ê°€ ìœ ì‚¬ë„ (ê°œì„ ë¨)
            country_sim = self.country_processor.calculate_country_similarity(
                query_case.get('ìˆ˜ì…êµ­'), candidate.get('ìˆ˜ì…êµ­')
            )
            score += weights['country_similarity'] * country_sim
            
            # 4. ê¸ˆì•¡ëŒ€ ìœ ì‚¬ë„
            query_amount = query_case.get('ì›í™”ì‚¬ê³ ê¸ˆì•¡', 0)
            candidate_amount = candidate.get('ì›í™”ì‚¬ê³ ê¸ˆì•¡', 0)
            
            if query_amount > 0 and candidate_amount > 0:
                amount_ratio = min(query_amount, candidate_amount) / max(query_amount, candidate_amount)
                score += weights['amount_similarity'] * amount_ratio
            
            # 5. ë³´í—˜ì¢…ëª© ì¼ì¹˜
            if query_case.get('ë³´í—˜ì¢…ëª©') == candidate.get('ë³´í—˜ì¢…ëª©'):
                score += weights['insurance_type']
            
            # 6. ìƒí’ˆë¶„ë¥˜ ìœ ì‚¬ë„ (ê·¸ë£¹ëª… + ìƒì„¸ë¶„ë¥˜ëª…)
            if 'product_category' in weights:
                query_product = query_case.get('ìƒí’ˆë¶„ë¥˜ëª…', '')
                candidate_product = candidate.get('ìƒí’ˆë¶„ë¥˜ëª…', '')
                query_group = query_case.get('ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…', '')
                candidate_group = candidate.get('ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…', '')
                
                # ì™„ì „ ì¼ì¹˜ (ìƒì„¸ë¶„ë¥˜ëª…)
                if query_product == candidate_product:
                    score += weights['product_category']
                # ê·¸ë£¹ëª… ì¼ì¹˜
                elif query_group == candidate_group:
                    score += weights['product_category'] * 0.8
                # ê·¸ë£¹í™”ëœ ìƒí’ˆë¶„ë¥˜ ì¼ì¹˜
                elif self._group_product_category(query_product) == self._group_product_category(candidate_product):
                    score += weights['product_category'] * 0.6
            
            # 7. ë¶€ë³´ìœ¨ ìœ ì‚¬ë„
            if 'coverage_rate' in weights:
                query_coverage = query_case.get('ë¶€ë³´ìœ¨', 0)
                candidate_coverage = candidate.get('ë¶€ë³´ìœ¨', 0)
                
                coverage_sim = self._calculate_coverage_similarity(query_coverage, candidate_coverage)
                score += weights['coverage_rate'] * coverage_sim
            
            # 8. ê²°ì œë°©ë²• ìœ ì‚¬ë„
            if 'payment_method' in weights:
                query_payment = query_case.get('ê²°ì œë°©ë²•', '')
                candidate_payment = candidate.get('ê²°ì œë°©ë²•', '')
                
                if query_payment == candidate_payment:
                    score += weights['payment_method']
                elif self._group_payment_method(query_payment) == self._group_payment_method(candidate_payment):
                    score += weights['payment_method'] * 0.8
            
            # 9. ê²°ì œì¡°ê±´ ìœ ì‚¬ë„
            if 'payment_terms' in weights:
                query_terms = query_case.get('ê²°ì œì¡°ê±´', '')
                candidate_terms = candidate.get('ê²°ì œì¡°ê±´', '')
                
                terms_sim = self._calculate_payment_terms_similarity(query_terms, candidate_terms)
                score += weights['payment_terms'] * terms_sim
            
            # 10. í–¥í›„ê²°ì œì „ë§ ìœ ì‚¬ë„
            if 'future_outlook' in weights:
                query_outlook = query_case.get('í–¥í›„ê²°ì œì „ë§', '')
                candidate_outlook = candidate.get('í–¥í›„ê²°ì œì „ë§', '')
                
                outlook_sim = self._calculate_future_outlook_similarity(query_outlook, candidate_outlook)
                score += weights['future_outlook'] * outlook_sim
            
            similarities.append((
                score, 
                text_similarities[i] if i < len(text_similarities) else 0.0, 
                country_sim,
                candidate
            ))
        
        # ë©´ì±… ì‚¬ë¡€ì™€ ë¹„ë©´ì±… ì‚¬ë¡€ ë¶„ë¦¬
        exemption_similarities = [(score, text_sim, country_sim, candidate) 
                                for score, text_sim, country_sim, candidate in similarities 
                                if candidate['íŒì •êµ¬ë¶„'] == 'ë©´ì±…']
        
        non_exemption_similarities = [(score, text_sim, country_sim, candidate) 
                                    for score, text_sim, country_sim, candidate in similarities 
                                    if candidate['íŒì •êµ¬ë¶„'] != 'ë©´ì±…']
        
        # ê°ê° ì •ë ¬
        exemption_similarities.sort(key=lambda x: x[0], reverse=True)
        non_exemption_similarities.sort(key=lambda x: x[0], reverse=True)
        
        # ê°•ì œ ë©´ì±… í¬í•¨ ê²°ê³¼ êµ¬ì„±
        final_results = []
        
        # 1. ê°€ì¥ ìœ ì‚¬í•œ ë©´ì±… ì‚¬ë¡€ 1ê±´ (ìˆë‹¤ë©´ ë¬´ì¡°ê±´ í¬í•¨)
        if exemption_similarities:
            final_results.append(exemption_similarities[0])
            print(f"ğŸ›¡ï¸ ë©´ì±… ê²½ê³ : ê°€ì¥ ìœ ì‚¬í•œ ë©´ì±… ì‚¬ë¡€ í¬í•¨ (ìœ ì‚¬ë„: {exemption_similarities[0][0]:.3f})")
        
        # 2. ë‚˜ë¨¸ì§€ëŠ” ì „ì²´ì—ì„œ ìƒìœ„ ìˆœìœ¼ë¡œ (ë©´ì±… ì œì™¸í•˜ê³ )
        remaining_slots = max(0, len(similarities) - len(final_results))
        if remaining_slots > 0:
            final_results.extend(non_exemption_similarities[:remaining_slots])
        
        return final_results
    
    def _group_accident_type(self, accident_type):
        """ì‚¬ê³ ìœ í˜• ê·¸ë£¹í™”"""
        if pd.isna(accident_type):
            return 'ê¸°íƒ€'
        
        if 'ì‹ ìš©ìœ„í—˜' in accident_type:
            if 'ì§€ê¸‰ì§€ì²´' in accident_type:
                return 'ì‹ ìš©ìœ„í—˜-ì§€ê¸‰ì§€ì²´'
            elif 'íŒŒì‚°' in accident_type:
                return 'ì‹ ìš©ìœ„í—˜-íŒŒì‚°'
            elif 'ì§€ê¸‰ë¶ˆëŠ¥' in accident_type or 'ì§€ê¸‰ê±°ì ˆ' in accident_type:
                return 'ì‹ ìš©ìœ„í—˜-ì§€ê¸‰ë¶ˆëŠ¥/ê±°ì ˆ'
            else:
                return 'ì‹ ìš©ìœ„í—˜-ê¸°íƒ€'
        elif 'ë¹„ìƒìœ„í—˜' in accident_type:
            return 'ë¹„ìƒìœ„í—˜'
        elif 'ê²€ì—­ìœ„í—˜' in accident_type:
            return 'ê²€ì—­ìœ„í—˜'
        else:
            return 'ê¸°íƒ€ìœ„í—˜'
    
    def _group_product_category(self, product_name):
        """ìƒí’ˆë¶„ë¥˜ ê·¸ë£¹í™”"""
        if pd.isna(product_name):
            return 'ê¸°íƒ€'
        
        product_name = str(product_name).lower()
        
        # ì˜ë¥˜ ë° ì§ë¬¼ë¥˜
        if any(word in product_name for word in ['ì˜ë¥˜', 'ì§ë¬¼', 'ì„¬ìœ ', 'íŒ¨ì…˜', 'textile', 'clothing']):
            return 'ì˜ë¥˜_ì§ë¬¼ë¥˜'
        # ì „ìì œí’ˆ
        elif any(word in product_name for word in ['ì „ì', 'ë°˜ë„ì²´', 'ì»´í“¨í„°', 'electronics', 'semiconductor']):
            return 'ì „ìì œí’ˆ'
        # ë†ìˆ˜ì‚°ë¬¼
        elif any(word in product_name for word in ['ë†ì‚°ë¬¼', 'ìˆ˜ì‚°ë¬¼', 'ì‹í’ˆ', 'agriculture', 'food']):
            return 'ë†ìˆ˜ì‚°ë¬¼'
        # ìë™ì°¨ ë° ë¶€í’ˆ
        elif any(word in product_name for word in ['ìë™ì°¨', 'ë¶€í’ˆ', 'auto', 'parts']):
            return 'ìë™ì°¨_ë¶€í’ˆ'
        # í™”í•™ì œí’ˆ
        elif any(word in product_name for word in ['í™”í•™', 'í”Œë¼ìŠ¤í‹±', 'chemical', 'plastic']):
            return 'í™”í•™ì œí’ˆ'
        else:
            return 'ê¸°íƒ€ì œí’ˆ'
    
    def _group_payment_method(self, payment_method):
        """ê²°ì œë°©ë²• ê·¸ë£¹í™”"""
        if pd.isna(payment_method):
            return 'ê¸°íƒ€'
        
        payment_method = str(payment_method).upper()
        
        # ì‹ ìš©ë„ë³„ ê·¸ë£¹í™”
        if any(method in payment_method for method in ['L/C', 'LC', 'ì‹ ìš©ì¥']):
            return 'L/C'
        elif any(method in payment_method for method in ['D/P', 'DP', 'ë„ì°©ì§€ì§€ê¸‰']):
            return 'D/P'
        elif any(method in payment_method for method in ['D/A', 'DA', 'ë„ì°©ì§€ì¸ìˆ˜']):
            return 'D/A'
        elif any(method in payment_method for method in ['NET', 'OPEN', 'ë¬´ì‹ ìš©ì¥']):
            return 'NET'
        else:
            return 'ê¸°íƒ€ê²°ì œ'
    
    def _calculate_coverage_similarity(self, query_rate, candidate_rate):
        """ë¶€ë³´ìœ¨ ìœ ì‚¬ë„ ê³„ì‚°"""
        if pd.isna(query_rate) or pd.isna(candidate_rate):
            return 0.5  # ì¤‘ê°„ê°’
        
        # ë¹„ìœ¨ ì°¨ì´ ê³„ì‚°
        rate_diff = abs(query_rate - candidate_rate) / 100
        
        # ì°¨ì´ê°€ í´ìˆ˜ë¡ ë‚®ì€ ìœ ì‚¬ë„
        return max(0.1, 1.0 - rate_diff)
    
    def _calculate_payment_terms_similarity(self, query_terms, candidate_terms):
        """ê²°ì œì¡°ê±´ ìœ ì‚¬ë„ ê³„ì‚°"""
        if pd.isna(query_terms) or pd.isna(candidate_terms):
            return 0.5
        
        query_terms = str(query_terms).lower()
        candidate_terms = str(candidate_terms).lower()
        
        # ì™„ì „ ì¼ì¹˜
        if query_terms == candidate_terms:
            return 1.0
        
        # ì¡°ê±´ ìœ í˜•ë³„ ê·¸ë£¹í™”
        if 'days' in query_terms and 'days' in candidate_terms:
            return 0.8
        elif 'sight' in query_terms and 'sight' in candidate_terms:
            return 0.8
        elif 'invoice' in query_terms and 'invoice' in candidate_terms:
            return 0.7
        
        return 0.3
    
    def _calculate_future_outlook_similarity(self, query_outlook, candidate_outlook):
        """í–¥í›„ê²°ì œì „ë§ ìœ ì‚¬ë„ ê³„ì‚°"""
        if pd.isna(query_outlook) or pd.isna(candidate_outlook):
            return 0.5
        
        query_outlook = str(query_outlook).lower()
        candidate_outlook = str(candidate_outlook).lower()
        
        # ì™„ì „ ì¼ì¹˜
        if query_outlook == candidate_outlook:
            return 1.0
        
        # ê¸ì •ì  vs ë¶€ì •ì  ê·¸ë£¹í™”
        positive_terms = ['ì§€ê¸‰ì˜ˆì •', 'íšŒìˆ˜ì˜ˆì •', 'ê¸ì •ì ', 'positive']
        negative_terms = ['íšŒìˆ˜ë¶ˆê°€', 'ì§€ê¸‰ë¶ˆê°€', 'ë¶€ì •ì ', 'negative']
        unknown_terms = ['íŒë‹¨ë¶ˆê°€', 'ë¯¸ìƒ', 'unknown']
        
        query_group = None
        candidate_group = None
        
        if any(term in query_outlook for term in positive_terms):
            query_group = 'positive'
        elif any(term in query_outlook for term in negative_terms):
            query_group = 'negative'
        elif any(term in query_outlook for term in unknown_terms):
            query_group = 'unknown'
        
        if any(term in candidate_outlook for term in positive_terms):
            candidate_group = 'positive'
        elif any(term in candidate_outlook for term in negative_terms):
            candidate_group = 'negative'
        elif any(term in candidate_outlook for term in unknown_terms):
            candidate_group = 'unknown'
        
        if query_group == candidate_group:
            return 0.8
        elif query_group == 'unknown' or candidate_group == 'unknown':
            return 0.5
        else:
            return 0.2
    
    def _apply_exemption_keyword_boost(self, query_text, candidate_texts, similarities, candidates_df):
        """ë©´ì±… ê´€ë ¨ í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„ ë³´ì • (ê°œì„ ëœ ë²„ì „)"""
        
        # ë” êµ¬ì²´ì ì¸ ë©´ì±… ê´€ë ¨ í•µì‹¬ íŒ¨í„´ (ë§¥ë½ì„ ê³ ë ¤)
        exemption_patterns = {
            'ê³ ì˜ê³¼ì‹¤': [
                ('Rê¸‰.*ê¸°ë“±ë¡', 0.15),  # ì •ê·œì‹ íŒ¨í„´ê³¼ ê°€ì¤‘ì¹˜
                ('ì‹ ìš©ì¡°íšŒ.*ì†Œí™€', 0.12),
                ('ê³ ì˜.*ìœ„ë°˜', 0.10),
                ('ê³¼ì‹¤.*ë°œìƒ', 0.08)
            ],
            'ì—°ì†ìˆ˜ì¶œ': [
                ('ì´ì „.*ë¯¸ìˆ˜ê¸ˆ.*íšŒìˆ˜', 0.20),
                ('ì—°ì†.*ìˆ˜ì¶œ.*ìœ„ë°˜', 0.18),
                ('ê²½í•©ìˆ˜ì¶œì.*ì¡´ì¬', 0.10),
                ('ë™ì¼.*ìˆ˜ì…ì.*ê±°ë˜', 0.08)
            ],
            'ë³´ìƒí•œë„ì´ˆê³¼': [
                ('ë³´ìƒí•œë„.*ì´ˆê³¼', 0.25),
                ('í•œë„.*ì´ˆê³¼', 0.20),
                ('ì±…ì„í•œë„.*ë¶€ì¡±', 0.15)
            ],
            'ë³´í—˜ê´€ê³„ì„±ë¦½': [
                ('í—ˆìœ„.*ì„œë¥˜.*ì œì¶œ', 0.20),
                ('ë³´í—˜ê´€ê³„.*ì„±ë¦½.*ë¶ˆê°€', 0.18),
                ('ì‹ ì²­.*ì •ë³´.*í—ˆìœ„', 0.15)
            ],
            'ì£¼ì˜ì˜ë¬´í•´íƒœ': [
                ('íŒŒì‚°ì‹ ì²­.*ìƒíƒœ', 0.25),
                ('ì¬ë¬´ì•…í™”.*ì§•í›„.*ë¬´ì‹œ', 0.20),
                ('ì£¼ì˜ì˜ë¬´.*í•´íƒœ', 0.18),
                ('ì ì ˆí•œ.*ì¡°ì¹˜.*ë¶€ì¬', 0.12)
            ]
        }
        
        boosted_similarities = similarities.copy()
        
        for i, (candidate_text, candidate_row) in enumerate(zip(candidate_texts, candidates_df.itertuples())):
            # ì‹¤ì œ íŒì •êµ¬ë¶„ì´ ë©´ì±…ì¸ ê²½ìš°ë§Œ ì²˜ë¦¬
            if hasattr(candidate_row, 'íŒì •êµ¬ë¶„') and candidate_row.íŒì •êµ¬ë¶„ == 'ë©´ì±…':
                
                total_boost = 0.0  # ëˆ„ì  ë¶€ìŠ¤íŠ¸ ëŒ€ì‹  ì´í•©ìœ¼ë¡œ ê³„ì‚°
                matched_patterns = []
                
                # ê° íŒ¨í„´ë³„ë¡œ ë§¤ì¹­ í™•ì¸
                for pattern_type, pattern_list in exemption_patterns.items():
                    for pattern, weight in pattern_list:
                        # ì¿¼ë¦¬ì™€ í›„ë³´ ëª¨ë‘ì—ì„œ íŒ¨í„´ ê²€ìƒ‰
                        import re
                        query_match = re.search(pattern, query_text, re.IGNORECASE)
                        candidate_match = re.search(pattern, str(candidate_text), re.IGNORECASE)
                        
                        if query_match and candidate_match:
                            # íŒì •ì‚¬ìœ ë„ íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                            candidate_reason = getattr(candidate_row, 'íŒì •ì‚¬ìœ ', '')
                            if pattern_type in ['ê³ ì˜ê³¼ì‹¤'] and 'ê³ ì˜' in candidate_reason:
                                total_boost += weight
                                matched_patterns.append(f"{pattern_type}:{pattern}")
                            elif pattern_type in ['ì—°ì†ìˆ˜ì¶œ'] and 'ì—°ì†' in candidate_reason:
                                total_boost += weight
                                matched_patterns.append(f"{pattern_type}:{pattern}")
                            elif pattern_type in ['ë³´ìƒí•œë„ì´ˆê³¼'] and 'ì´ˆê³¼' in candidate_reason:
                                total_boost += weight
                                matched_patterns.append(f"{pattern_type}:{pattern}")
                            elif pattern_type in ['ë³´í—˜ê´€ê³„ì„±ë¦½'] and 'ì„±ë¦½' in candidate_reason:
                                total_boost += weight
                                matched_patterns.append(f"{pattern_type}:{pattern}")
                            elif pattern_type in ['ì£¼ì˜ì˜ë¬´í•´íƒœ'] and 'í•´íƒœ' in candidate_reason:
                                total_boost += weight
                                matched_patterns.append(f"{pattern_type}:{pattern}")
                
                # ìµœì¢… ë¶€ìŠ¤íŠ¸ ì ìš© (ìµœëŒ€ 10% ë¶€ìŠ¤íŠ¸ë¡œ ì œí•œ)
                if total_boost > 0:
                    final_boost = min(0.10, total_boost)  # ìµœëŒ€ 10% ë¶€ìŠ¤íŠ¸
                    boosted_similarities[i] = min(1.0, similarities[i] + final_boost)  # ê³±í•˜ê¸° ëŒ€ì‹  ë”í•˜ê¸°
                        
        return boosted_similarities
    
    def _analyze_judgment_reasons(self, decisions, reasons, similarity_scores):
        """íŒì •ì‚¬ìœ  ë¶„ì„"""
        
        # íŒì •êµ¬ë¶„ë³„ ì‚¬ìœ  ë¶„ì„
        decision_reasons = {}
        for decision, reason, sim_score in zip(decisions, reasons, similarity_scores):
            if decision not in decision_reasons:
                decision_reasons[decision] = []
            decision_reasons[decision].append({
                'reason': reason,
                'similarity': sim_score
            })
        
        # ì˜ˆìƒ íŒì •ì‚¬ìœ  ë„ì¶œ
        predicted_reasons = {}
        
        for decision, reason_list in decision_reasons.items():
            # ìœ ì‚¬ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì ìš©
            reason_weights = {}
            for item in reason_list:
                reason = item['reason']
                weight = item['similarity']
                
                if reason in reason_weights:
                    reason_weights[reason] += weight
                else:
                    reason_weights[reason] = weight
            
            # ê°€ì¤‘ì¹˜ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_reasons = sorted(reason_weights.items(), key=lambda x: x[1], reverse=True)
            predicted_reasons[decision] = sorted_reasons
        
        return {
            'decision_reasons': decision_reasons,
            'predicted_reasons': predicted_reasons,
            'top_reasons': self._get_top_reasons_by_decision(predicted_reasons)
        }
    
    def _get_top_reasons_by_decision(self, predicted_reasons):
        """íŒì •êµ¬ë¶„ë³„ ìƒìœ„ ì‚¬ìœ  ìš”ì•½"""
        top_reasons = {}
        
        for decision, reasons in predicted_reasons.items():
            if reasons:
                # ìƒìœ„ 3ê°œ ì‚¬ìœ 
                top_3 = reasons[:3]
                total_weight = sum([weight for _, weight in reasons])
                
                top_reasons[decision] = {
                    'reasons': [(reason, weight/total_weight) for reason, weight in top_3],
                    'total_cases': len(reasons)
                }
        
        return top_reasons

@st.cache_data
def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    try:
        df = pd.read_csv('data/design.csv', encoding='cp949')
        
        # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
        date_columns = ['íŒì •ì¼', 'íŒì •ê²°ì¬ì¼', 'ì‚¬ê³ ì ‘ìˆ˜ì¼ì', 'ë³´í—˜ê¸ˆì²­êµ¬ì¼']
        for col in date_columns:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce')
        
        # ê¸ˆì•¡ ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜
        amount_columns = ['ì›í™”ì‚¬ê³ ê¸ˆì•¡', 'ì›í™”íŒì •ê¸ˆì•¡', ]
        for col in amount_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def create_country_analysis_tab(df, country_processor):
    """êµ­ê°€ ë¶„ì„ íƒ­"""
    st.subheader("ğŸŒ êµ­ê°€ ì²˜ë¦¬ ë¶„ì„")
    
    # êµ­ê°€ ì „ì²˜ë¦¬ ì ìš©
    df_processed = df.copy()
    df_processed['ìˆ˜ì…êµ­_processed'] = df_processed['ìˆ˜ì…êµ­'].apply(country_processor.preprocess_country)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ğŸ“Š ì „ì²˜ë¦¬ ì „í›„ ë¹„êµ**")
        
        before_count = df['ìˆ˜ì…êµ­'].nunique()
        after_count = df_processed['ìˆ˜ì…êµ­_processed'].nunique()
        
        st.metric("ì „ì²˜ë¦¬ ì „ êµ­ê°€ ìˆ˜", f"{before_count}ê°œ")
        st.metric("ì „ì²˜ë¦¬ í›„ ì¹´í…Œê³ ë¦¬ ìˆ˜", f"{after_count}ê°œ", f"-{before_count-after_count}ê°œ")
        
        # ì „ì²˜ë¦¬ í›„ ë¶„í¬
        processed_counts = df_processed['ìˆ˜ì…êµ­_processed'].value_counts().head(15)
        fig1 = px.bar(
            x=processed_counts.values,
            y=processed_counts.index,
            orientation='h',
            title="ì „ì²˜ë¦¬ í›„ êµ­ê°€ ì¹´í…Œê³ ë¦¬ ë¶„í¬",
            color_discrete_sequence=['#007bff']
        )
        fig1.update_layout(height=500, showlegend=False)
        st.plotly_chart(fig1, use_container_width=True)
    
    with col2:
        st.write("**ğŸ” ì†Œê·œëª¨ êµ­ê°€ ìƒì„¸ ë‚´ì—­**")
        
        # ê¸°íƒ€ êµ­ê°€ì— í¬í•¨ëœ êµ­ê°€ë“¤ í‘œì‹œ
        minor_countries = []
        for region, countries in country_processor.regions.items():
            minor_countries.extend(countries['ê¸°íƒ€'])
        
        st.write("**ê¸°íƒ€êµ­ê°€ì— í¬í•¨ëœ 39ê°œêµ­:**")
        for i, country in enumerate(minor_countries, 1):
            if country in df['ìˆ˜ì…êµ­'].values:
                count = (df['ìˆ˜ì…êµ­'] == country).sum()
                st.write(f"{i:2d}. {country} ({count}ê±´)")
        
        # ì§€ì—­ë³„ ê·¸ë£¹í™” ê²°ê³¼
        st.write("**ì§€ì—­ë³„ ê·¸ë£¹í™” ê²°ê³¼:**")
        for region in country_processor.regions.keys():
            region_key = f"{region}_ê¸°íƒ€"
            if region_key in df_processed['ìˆ˜ì…êµ­_processed'].values:
                count = (df_processed['ìˆ˜ì…êµ­_processed'] == region_key).sum()
                st.write(f"â€¢ {region_key}: {count}ê±´")

def create_similarity_search_interface(system, df):
    """ê°œì„ ëœ ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤"""
    st.subheader("ğŸ” ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰")
    
    # AI ëª¨ë¸ ìƒíƒœ
    model_ready = system.initialize_ai_model()
    if model_ready:
        st.success("âœ… AI í…ìŠ¤íŠ¸ ë¶„ì„ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
    else:
        st.warning("âš ï¸ AI ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€ - ê¸°ë³¸ ê²€ìƒ‰ ëª¨ë“œ")
    
    
    # ê°€ì¤‘ì¹˜ ì¡°ì • (form ë°–ì— ë°°ì¹˜)
    with st.expander("ğŸ”§ ê°€ì¤‘ì¹˜ ì¡°ì • (ê³ ê¸‰ ì„¤ì •)", expanded=False):
        st.write("**í˜„ì¬ ê°€ì¤‘ì¹˜ ì„¤ì •:**")
        
        # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
        text_weight = st.slider(
            "í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜:",
            min_value=0.0,
            max_value=1.0,
            value=system.optimal_weights['text_similarity'],
            step=0.05,
            help="ì‚¬ê³ ì„¤ëª… í…ìŠ¤íŠ¸ì˜ ì¤‘ìš”ë„"
        )
        
        # ì‚¬ê³ ìœ í˜•
        accident_weight = st.slider(
            "ì‚¬ê³ ìœ í˜• ê°€ì¤‘ì¹˜:",
            min_value=0.0,
            max_value=1.0,
            value=system.optimal_weights['accident_type'],
            step=0.05,
            help="ì‚¬ê³ ìœ í˜•ì˜ ì¤‘ìš”ë„"
        )
        
        # êµ­ê°€
        country_weight = st.slider(
            "êµ­ê°€ ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜:",
            min_value=0.0,
            max_value=1.0,
            value=system.optimal_weights['country_similarity'],
            step=0.05,
            help="ìˆ˜ì…êµ­ì˜ ì¤‘ìš”ë„"
        )
        
        # ê¸ˆì•¡
        amount_weight = st.slider(
            "ê¸ˆì•¡ ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜:",
            min_value=0.0,
            max_value=1.0,
            value=system.optimal_weights['amount_similarity'],
            step=0.05,
            help="ì‚¬ê³ ê¸ˆì•¡ì˜ ì¤‘ìš”ë„"
        )
        
        # ë³´í—˜ì¢…ëª©
        insurance_weight = st.slider(
            "ë³´í—˜ì¢…ëª© ê°€ì¤‘ì¹˜:",
            min_value=0.0,
            max_value=1.0,
            value=system.optimal_weights['insurance_type'],
            step=0.05,
            help="ë³´í—˜ì¢…ëª©ì˜ ì¤‘ìš”ë„"
        )
        
        # ì„ íƒ ë¹„í™œì„± ì²´í¬ë°•ìŠ¤: íŠ¹ì • í”¼ì²˜ ì˜í–¥ ì œì™¸
        st.write("**í”¼ì²˜ ì‚¬ìš© ì—¬ë¶€(ì„ íƒ ì•ˆí•¨ ê°€ëŠ¥):**")
        use_text = st.checkbox("í…ìŠ¤íŠ¸ ì‚¬ìš©", value=True)
        use_accident = st.checkbox("ì‚¬ê³ ìœ í˜• ì‚¬ìš©", value=True)
        use_country = st.checkbox("êµ­ê°€ ì‚¬ìš©", value=True)
        use_amount = st.checkbox("ê¸ˆì•¡ ì‚¬ìš©", value=True)
        use_insurance = st.checkbox("ë³´í—˜ì¢…ëª© ì‚¬ìš©", value=True)

        # ì‚¬ìš© ì•ˆí•¨ì´ë©´ í•´ë‹¹ ê°€ì¤‘ì¹˜ë¥¼ 0ìœ¼ë¡œ ê°„ì£¼
        text_weight = text_weight if use_text else 0.0
        accident_weight = accident_weight if use_accident else 0.0
        country_weight = country_weight if use_country else 0.0
        amount_weight = amount_weight if use_amount else 0.0
        insurance_weight = insurance_weight if use_insurance else 0.0

        # ê°€ì¤‘ì¹˜ í•©ê³„ í™•ì¸(ì •ê·œí™”ëŠ” í•˜ì§€ ì•ŠìŒ: ì ˆëŒ€ ê°€ì¤‘ìœ¼ë¡œ ì²˜ë¦¬)
        total_weight = text_weight + accident_weight + country_weight + amount_weight + insurance_weight
        st.info(f"ê°€ì¤‘ì¹˜ í•©ê³„: {total_weight:.2f} (ì ˆëŒ€ ê°€ì¤‘)")
        
        # ê°€ì¤‘ì¹˜ ì ìš© ë²„íŠ¼
        if st.button("ê°€ì¤‘ì¹˜ ì ìš©"):
            # ëŸ°íƒ€ì„ ì˜¤ë²„ë¼ì´ë“œ ë°˜ì˜(ì„¸ì…˜ ë™ì•ˆë§Œ ì ìš©)
            system.runtime_weight_overrides = {
                'text_similarity': text_weight,
                'accident_type': accident_weight,
                'country_similarity': country_weight,
                'amount_similarity': amount_weight,
                'insurance_type': insurance_weight,
                # ë‚˜ë¨¸ì§€ í•­ëª©ì€ ì›ë˜ ìµœì ê°’ ìœ ì§€(ì˜¤ë²„ë¼ì´ë“œì—ì„œ ì œê³µ ì•ˆ í•¨)
                'product_category': system.optimal_weights.get('product_category', 0.0),
                'coverage_rate': system.optimal_weights.get('coverage_rate', 0.0),
                'payment_method': system.optimal_weights.get('payment_method', 0.0),
                'payment_terms': system.optimal_weights.get('payment_terms', 0.0),
                'future_outlook': system.optimal_weights.get('future_outlook', 0.0),
            }
            st.success("ê°€ì¤‘ì¹˜(ì‚¬ìš© ì•ˆí•¨ í¬í•¨)ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ê²€ìƒ‰ í¼
    with st.form("improved_search_form"):
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.write("**ğŸ“‹ ì‚¬ê³  ì •ë³´ ì…ë ¥**")
            
            input_country = st.selectbox(
                "ìˆ˜ì…êµ­:",
                options=df['ìˆ˜ì…êµ­'].value_counts().head(30).index,
                help="ì‚¬ê³ ê°€ ë°œìƒí•œ ìˆ˜ì…êµ­ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            input_insurance = st.selectbox(
                "ë³´í—˜ì¢…ëª©:",
                options=df['ë³´í—˜ì¢…ëª©'].value_counts().head(10).index
            )
            
            input_accident_type = st.selectbox(
                "ì‚¬ê³ ìœ í˜•:",
                options=df['ì‚¬ê³ ìœ í˜•ëª…'].value_counts().head(10).index
            )
            
            input_amount = st.number_input(
                "ì‚¬ê³ ê¸ˆì•¡ (ì›):",
                min_value=0,
                value=50000000,
                step=1000000,
                format="%d"
            )
            
            input_coverage = st.slider(
                "ë¶€ë³´ìœ¨ (%):",
                min_value=0,
                max_value=100,
                value=95,
                step=5,
                help="ë³´í—˜ ê°€ì… ë¹„ìœ¨ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            input_description = st.text_area(
                "ì‚¬ê³ ì„¤ëª…:",
                placeholder="ì‚¬ê³ ì˜ êµ¬ì²´ì ì¸ ìƒí™©ì„ ì…ë ¥í•˜ì„¸ìš”...",
                height=120
            )
            
            # ì¶”ê°€ ì…ë ¥ í•„ë“œë“¤
            # ìƒí’ˆë¶„ë¥˜ ì„ íƒ
            st.write("**ğŸ“¦ ìƒí’ˆë¶„ë¥˜ ì„ íƒ**")
            
            # ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª… ì˜µì…˜ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ - ìƒìœ„ 10ê°œ)
            product_group_options = [
                'ì˜ë¥˜ ë° ì§ë¬¼ë¥˜', 'ë¬´ê¸° ë° ìœ ê¸°í™”í•™ì œí’ˆ', 'ì „ê¸° ë° ì „ìì œí’ˆ', 'ê¸°ê³„ë¥˜',
                'ê¸ˆì†, ë¹„ê¸ˆì†ë¥˜', 'ê³ ë¬´, ê°€ì£½', 'ìš´ì†¡ì¥ë¹„ ë° ë¶€í’ˆ', 'ëª©ì¬ì™€ í„í”„, ì§€ë¬¼ë¥˜',
                'ë†ìˆ˜ì‚°ë¬¼, ì‹ë£Œí’ˆ', 'ì •ë°€ê¸°ê¸°, ì‹œê³„, ì•…ê¸°, ë¬´ê¸°ë¥˜', 'ê¸°íƒ€'
            ]
            input_product_group = st.selectbox(
                "ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…:",
                options=product_group_options,
                help="ìƒí’ˆì˜ ëŒ€ë¶„ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )
            
            # ìƒí’ˆë¶„ë¥˜ëª… ì˜µì…˜ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ - ìƒìœ„ 20ê°œ)
            product_options = [
                'ê°•ë ¥ì‚¬(í´ë¦¬ì—ìŠ¤í…Œë¥´ì˜ ê²ƒ)', 'ì™¸ë¶€í‘œë©´ì´ í”Œë¼ìŠ¤í‹±ì‰¬íŠ¸ ë˜ëŠ” ë°©ì§ìš© ì„¬ìœ ì œì˜ ê²ƒ', 'ì¸ì¡°ì„¬ìœ ì œì˜ ê²ƒ',
                'ì¸ì‡„íšŒë¡œ', '4. í´ë¦¬ì¹´ë³´ë„¤ì´íŠ¸', 'ê´‘ì „ì§€(íƒœì–‘ì „ì§€, í¬í† ë‹¤ì´ì˜¤ë“œ, í¬í† ì»¤í”Œ ë° í¬í† ë¦´ë ˆì´ë¥¼ í¬í•¨í•œë‹¤)',
                'ì‹ ì°¨', 'ì¤‘ê³ ì°¨', 'ì˜ë¥˜ ë° ì§ë¬¼ë¥˜', 'ì „ìì œí’ˆ', 'ë†ìˆ˜ì‚°ë¬¼', 'ìë™ì°¨ë¶€í’ˆ', 'í™”í•™ì œí’ˆ',
                'ê¸°íƒ€ì œí’ˆ', 'ê¸°íƒ€'
            ]
            input_product = st.selectbox(
                "ìƒí’ˆë¶„ë¥˜ëª… (ìƒì„¸):",
                options=product_options,
                help="ìˆ˜ì¶œ ìƒí’ˆì˜ ìƒì„¸ ë¶„ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )
            
            # ê²°ì œë°©ë²• ì˜µì…˜ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
            payment_method_options = [
                'O/A(T/T í¬í•¨)', 'D/A', 'NET', 'CAD', 'L/C Usance', 'COD', 'D/P', 'L/C',
                'ì‹ ìš©ì¹´ë“œ', 'ê¸°ì„±ê³ ë°©ì‹', 'ì‹ ìš©ì¥ ë¬¸ë©´ìƒ Tenor', 'ì„ ê¸‰ê¸ˆì§€ê¸‰ì¼', 'ê¸°íƒ€'
            ]
            input_payment_method = st.selectbox(
                "ê²°ì œë°©ë²•:",
                options=payment_method_options,
                help="ê±°ë˜ ê²°ì œ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            # ê²°ì œì¡°ê±´ ì˜µì…˜ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
            payment_terms_options = [
                'Days From B/L Date', 'Days After B/L Date', 'Days After Invoice Date',
                'Days From Invoice Date', 'Days After Sight', 'ì›”ë§ ë§ˆê°í›„', 'Days After Arrival',
                'After Delivery Date(Netê±°ë˜ë¡œ ìˆ˜ì…ì§€ì¸ë„ì¼ ê¸°ì¤€ ë³´í—˜ê¸°ì‚°)', 'Days From Nego Date',
                'After Finding Docs', 'At Sight', 'Days After Nego Date', 'Days From Arrival',
                'After Delivery Date(êµ­ë‚´ìˆ˜ì¶œì¼ ê¸°ì¤€ ë³´í—˜ê¸°ì‚°)', 'At', 'On Arrival Of Goods',
                'ë§¤ì›” 15ì¼ì ë§ˆê°í›„', 'ê¸°íƒ€'
            ]
            input_payment_terms = st.selectbox(
                "ê²°ì œì¡°ê±´:",
                options=payment_terms_options,
                help="ê²°ì œ ì¡°ê±´ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            # í–¥í›„ê²°ì œì „ë§ ì˜µì…˜ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
            future_outlook_options = [
                'íŒë‹¨ë¶ˆê°€', 'ê²°ì œë¶ˆëŠ¥', 'ê¸°íƒ€', 'ì „ë§¤ê°€ëŠ¥', 'ì¼ë¶€ê²°ì œê°€ëŠ¥', 'ê²°ì œì§„í–‰ì¤‘'
            ]
            input_future_outlook = st.selectbox(
                "í–¥í›„ê²°ì œì „ë§:",
                options=future_outlook_options,
                help="í–¥í›„ ê²°ì œ ì „ë§ì„ ì„ íƒí•˜ì„¸ìš”"
            )
        
        with col2:
            st.write("**ğŸ”§ ê²€ìƒ‰ ì„¤ì •**")
            
            max_results = st.slider("ìµœëŒ€ ê²°ê³¼ ìˆ˜:", 3, 10, 5)
            
            st.write("**ğŸ“Š êµ­ê°€ ì²˜ë¦¬ ì •ë³´**")
            
            # ì…ë ¥ êµ­ê°€ì˜ ì²˜ë¦¬ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
            processed_country = system.country_processor.preprocess_country(input_country)
            is_individual = system.country_processor.is_individual_country(input_country)
            is_minor = system.country_processor.is_minor_country(input_country)
            region = system.country_processor.get_country_region(input_country)
            
            st.write(f"â€¢ ì…ë ¥êµ­ê°€: **{input_country}**")
            st.write(f"â€¢ ì²˜ë¦¬ê²°ê³¼: **{processed_country}**")
            st.write(f"â€¢ ì§€ì—­: **{region}**")
            st.write(f"â€¢ ìœ í˜•: **{'ê°œë³„êµ­ê°€' if is_individual else 'ì†Œê·œëª¨êµ­ê°€' if is_minor else 'ê¸°íƒ€'}**")
            
            # ê²€ìƒ‰ í•„í„° ì„¤ì •
            st.write("**ğŸ” ê²€ìƒ‰ í•„í„° ì„¤ì •**")
            filter_col1, filter_col2, filter_col3 = st.columns(3)
            
            with filter_col1:
                use_country_filter = st.checkbox("ìˆ˜ì…êµ­ í•„í„° ì ìš©", value=False, help="ì„ íƒí•œ ìˆ˜ì…êµ­ê³¼ ë™ì¼í•œ ì‚¬ë¡€ë§Œ ê²€ìƒ‰")
            with filter_col2:
                use_insurance_filter = st.checkbox("ë³´í—˜ì¢…ëª© í•„í„° ì ìš©", value=False, help="ì„ íƒí•œ ë³´í—˜ì¢…ëª©ê³¼ ë™ì¼í•œ ì‚¬ë¡€ë§Œ ê²€ìƒ‰")
            with filter_col3:
                use_accident_filter = st.checkbox("ì‚¬ê³ ìœ í˜• í•„í„° ì ìš©", value=False, help="ì„ íƒí•œ ì‚¬ê³ ìœ í˜•ê³¼ ë™ì¼í•œ ì‚¬ë¡€ë§Œ ê²€ìƒ‰")
            
        

            
            st.write("**âš–ï¸ ê¸°ë³¸ ê°€ì¤‘ì¹˜**")
            st.write("â€¢ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„: 35%")
            st.write("â€¢ ì‚¬ê³ ìœ í˜•: 20%")
            st.write("â€¢ êµ­ê°€ ìœ ì‚¬ë„: 12% â­")
            st.write("â€¢ ê¸ˆì•¡ìœ ì‚¬ë„: 8%")
            st.write("â€¢ ë³´í—˜ì¢…ëª©: 5%")
            st.write("â€¢ ìƒí’ˆë¶„ë¥˜: 8%")
            st.write("â€¢ ë¶€ë³´ìœ¨: 5%")
            st.write("â€¢ ê²°ì œë°©ë²•: 4%")
            st.write("â€¢ ê²°ì œì¡°ê±´: 2%")
            st.write("â€¢ í–¥í›„ì „ë§: 1%")

            
        submitted = st.form_submit_button("ğŸ” ê²€ìƒ‰ ì‹¤í–‰", type="primary")
    
    if submitted:
        start_time = time.time()
        
        # ì…ë ¥ ë°ì´í„° êµ¬ì„± (í™•ì¥ëœ ë³€ìˆ˜ í¬í•¨)
        case_data = {
            'ìˆ˜ì…êµ­': input_country,
            'ë³´í—˜ì¢…ëª©': input_insurance,
            'ì‚¬ê³ ìœ í˜•ëª…': input_accident_type,
            'ì›í™”ì‚¬ê³ ê¸ˆì•¡': input_amount,
            'ì‚¬ê³ ì„¤ëª…': input_description,
            'ë¶€ë³´ìœ¨': input_coverage,
            'ìƒí’ˆë¶„ë¥˜ëª…': input_product,
            'ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…': input_product_group,
            'ê²°ì œë°©ë²•': input_payment_method,
            'ê²°ì œì¡°ê±´': input_payment_terms,
            'í–¥í›„ê²°ì œì „ë§': input_future_outlook
        }
        
        with st.spinner(" ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
            # ì˜ë¯¸ìˆëŠ” ì„¤ëª…ì´ ìˆëŠ” ì‚¬ë¡€ ìš°ì„ 
            search_df = df.copy()
            if input_description:
                meaningful_df = search_df[
                    (search_df['ì‚¬ê³ ì„¤ëª…'].notna()) & 
                    (search_df['ì‚¬ê³ ì„¤ëª…'].str.len() > 10) &
                    (~search_df['ì‚¬ê³ ì„¤ëª…'].str.contains('ì„¤ëª…ì—†ìŒ|ì²¨ë¶€íŒŒì¼ì°¸ê³ |í•´ë‹¹ì—†ìŒ', na=False, case=False))
                ]
                if len(meaningful_df) > 50:
                    search_df = meaningful_df
            
            # í•„í„° ì ìš©
            if use_country_filter:
                search_df = search_df[search_df['ìˆ˜ì…êµ­'] == input_country]
                st.info(f"ğŸ” ìˆ˜ì…êµ­ í•„í„° ì ìš©: {input_country} ({len(search_df)}ê±´)")
            
            if use_insurance_filter:
                search_df = search_df[search_df['ë³´í—˜ì¢…ëª©'] == input_insurance]
                st.info(f"ğŸ” ë³´í—˜ì¢…ëª© í•„í„° ì ìš©: {input_insurance} ({len(search_df)}ê±´)")
            
            if use_accident_filter:
                search_df = search_df[search_df['ì‚¬ê³ ìœ í˜•ëª…'] == input_accident_type]
                st.info(f"ğŸ” ì‚¬ê³ ìœ í˜• í•„í„° ì ìš©: {input_accident_type} ({len(search_df)}ê±´)")
            
            if len(search_df) == 0:
                st.error("âŒ í•„í„° ì¡°ê±´ì— ë§ëŠ” ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.")
                return
            
            # ê°œì„ ëœ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = system.calculate_similarity_scores(case_data, search_df)
            # ìƒìœ„ 5ê±´ë§Œ, ìœ ì‚¬ë„ 0.30 ë¯¸ë§Œ ì œì™¸
            min_score = 0.30
            top_similar = [r for r in similarities if r[0] >= min_score][:5]
            
            search_time = time.time() - start_time
        
        # í•˜ì´ë¸Œë¦¬ë“œ ì‹ ë¢°ë„ ê³„ì‚°
        if top_similar:
            decisions = [case[3]['íŒì •êµ¬ë¶„'] for case in top_similar]
            reasons = [case[3]['íŒì •ì‚¬ìœ '] for case in top_similar]
            similarity_scores = [case[0] for case in top_similar]
            
            confidence_result = system.confidence_calculator.hybrid_confidence(decisions, similarity_scores)
            
            # íŒì •ì‚¬ìœ  ë¶„ì„
            reason_analysis = system._analyze_judgment_reasons(decisions, reasons, similarity_scores)
            
            # ì‹ ë¢°ë„ ê²°ê³¼ í‘œì‹œ
            pred_decision = confidence_result['predicted_decision']
            confidence = confidence_result['confidence']
            grade = confidence_result['grade']
            
            if pred_decision == 'ì§€ê¸‰':
                box_class = "confidence-box success-box"
            elif pred_decision == 'ë©´ì±…':
                box_class = "confidence-box error-box"
            else:
                box_class = "confidence-box warning-box"
            
            st.markdown(f"""
            <div class="{box_class}">
              <!--  <h2>ğŸ¯ ì˜ˆìƒ íŒì •: {pred_decision}</h2>
                <h3>í•˜ì´ë¸Œë¦¬ë“œ ì‹ ë¢°ë„: {confidence:.1%} ({grade})</h3>-->
                <p>{confidence_result['interpretation']}</p>
                <small>ê²€ìƒ‰ ì‹œê°„: {search_time:.1f}ì´ˆ | ìœ ì‚¬ì‚¬ë¡€: {confidence_result['sample_size']}ê°œ | í‰ê·  ìœ ì‚¬ë„: {confidence_result['avg_similarity']:.1%}</small>
            </div>
            """, unsafe_allow_html=True)
            
            # ì‹ ë¢°ë„ ìƒì„¸ ë¶„ì„
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.write("**ğŸ“Š ê°€ì¤‘ vs ë² ì´ì§€ì•ˆ ë¹„êµ**")
                st.metric("ê°€ì¤‘ ì‹ ë¢°ë„", f"{confidence_result['weighted_confidence']:.1%}")
                st.metric("ë² ì´ì§€ì•ˆ ì¶”ì •", f"{confidence_result['bayesian_mean']:.1%}")
                
            with col2:
                # íŒì •êµ¬ë¶„ ë¶„í¬
                decision_counts = Counter(decisions)
                decision_df = pd.DataFrame(list(decision_counts.items()), columns=['íŒì •êµ¬ë¶„', 'ê±´ìˆ˜'])
                fig_pred = px.pie(
                    decision_df,
                    values='ê±´ìˆ˜',
                    names='íŒì •êµ¬ë¶„',
                    title="ìœ ì‚¬ì‚¬ë¡€ íŒì •êµ¬ë¶„ ë¶„í¬",
                    color_discrete_sequence=['#28a745', '#dc3545', '#ffc107']
                )
                st.plotly_chart(fig_pred, use_container_width=True)
            
            with col3:
                # ì‹ ë¢°êµ¬ê°„ ì‹œê°í™”
                lower, upper = confidence_result['credible_interval']
                
                fig_interval = go.Figure()
                fig_interval.add_trace(go.Scatter(
                    x=[confidence_result['bayesian_mean']],
                    y=['ë² ì´ì§€ì•ˆ ì¶”ì •'],
                    mode='markers',
                    marker=dict(size=15, color='blue'),
                    name='ì¶”ì •ê°’'
                ))
                fig_interval.add_shape(
                    type="line",
                    x0=lower, x1=upper,
                    y0=0, y1=0,
                    line=dict(color="red", width=4),
                )
                fig_interval.update_layout(
                    title="95% ì‹ ë¢°êµ¬ê°„",
                    xaxis_title="í™•ë¥ ",
                    yaxis=dict(showticklabels=False),
                    height=200
                )
                st.plotly_chart(fig_interval, use_container_width=True)
            
            # íŒì •ì‚¬ìœ  ë¶„ì„ ì¶”ê°€
            st.subheader("ğŸ¯ íŒì •ì‚¬ìœ  ë¶„ì„")
            
            top_reasons = reason_analysis['top_reasons']
            
            if pred_decision in top_reasons:
                decision_info = top_reasons[pred_decision]
                st.write(f"**{pred_decision} íŒì •ì˜ ì£¼ìš” ì‚¬ìœ  (ìƒìœ„ 3ê°œ):**")
                
                for i, (reason, prob) in enumerate(decision_info['reasons']):
                    emoji = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰"
                    st.write(f"{emoji} **{reason}** ")
                    # ({prob:.1%}) ì´ê±´ ì¼ë‹¨ ì œì™¸
            else:
                st.info("í•´ë‹¹ íŒì •êµ¬ë¶„ì˜ ì‚¬ìœ  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            
            # ëª¨ë“  íŒì •êµ¬ë¶„ë³„ ì‚¬ìœ  ìš”ì•½
            if len(top_reasons) > 1:
                st.write("**ğŸ“Š íŒì •êµ¬ë¶„ë³„ ì£¼ìš” ì‚¬ìœ  ë¹„êµ**")
                
                reason_comparison = []
                for decision, info in top_reasons.items():
                    for reason, prob in info['reasons'][:2]:  # ìƒìœ„ 2ê°œë§Œ
                        reason_comparison.append({
                            'íŒì •êµ¬ë¶„': decision,
                            'íŒì •ì‚¬ìœ ': reason,
                            'ê°€ì¤‘í™•ë¥ ': prob,
                            'ì‚¬ë¡€ìˆ˜': info['total_cases']
                        })
                
                if reason_comparison:
                    reason_df = pd.DataFrame(reason_comparison)
                    
                    # íŒì •ì‚¬ìœ ë³„ ë§‰ëŒ€ ì°¨íŠ¸
                    fig_reasons = px.bar(
                        reason_df,
                        x='íŒì •ì‚¬ìœ ',
                        y='ê°€ì¤‘í™•ë¥ ',
                        color='íŒì •êµ¬ë¶„',
                        title="íŒì •êµ¬ë¶„ë³„ ì£¼ìš” ì‚¬ìœ ",
                        color_discrete_sequence=['#28a745', '#dc3545', '#ffc107']
                    )
                    fig_reasons.update_layout(
                        xaxis_title="íŒì •ì‚¬ìœ ",
                        xaxis_tickangle=45,
                        yaxis_title="ê°€ì¤‘í™•ë¥ ",
                        yaxis_tickformat='.1%'
                    )
                    st.plotly_chart(fig_reasons, use_container_width=True)
            
            # ìƒì„¸ ê²°ê³¼
            st.subheader("ğŸ“‹ ìœ ì‚¬ì‚¬ë¡€ ìƒì„¸ ë¶„ì„")
            
            # ë©´ì±… ì‚¬ë¡€ í¬í•¨ ì—¬ë¶€ í™•ì¸ ë° ê²½ê³  í‘œì‹œ
            exemption_cases = [case for _, _, _, case in top_similar if case['íŒì •êµ¬ë¶„'] == 'ë©´ì±…']
            if exemption_cases:
                st.warning(f"ğŸ›¡ï¸ **ë©´ì±… ê²½ê³ **: {len(exemption_cases)}ê±´ì˜ ë©´ì±… ì‚¬ë¡€ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”!")
                
                # ë©´ì±… ìœ ì‚¬ë„ ê¸°ë°˜ ë¶„ì„
                st.subheader("ğŸ›¡ï¸ ë©´ì±… ìœ ì‚¬ë„ ë¶„ì„")
                exemption_scores = [(score, case) for score, _, _, case in top_similar if case['íŒì •êµ¬ë¶„'] == 'ë©´ì±…']
                
                if exemption_scores:
                    avg_exemption_score = sum(score for score, _ in exemption_scores) / len(exemption_scores)
                    max_exemption_score = max(score for score, _ in exemption_scores)
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ë©´ì±… ì‚¬ë¡€ ìˆ˜", len(exemption_scores))
                    with col2:
                        st.metric("í‰ê·  ë©´ì±… ìœ ì‚¬ë„", f"{avg_exemption_score:.3f}")
                    with col3:
                        st.metric("ìµœê³  ë©´ì±… ìœ ì‚¬ë„", f"{max_exemption_score:.3f}")
                    
                    # ë©´ì±… ìœ„í—˜ë„ í‰ê°€
                    if max_exemption_score > 0.8:
                        st.error("ğŸš¨ **ë†’ì€ ë©´ì±… ìœ„í—˜**: ë§¤ìš° ìœ ì‚¬í•œ ë©´ì±… ì‚¬ë¡€ê°€ ì¡´ì¬í•©ë‹ˆë‹¤!")
                    elif max_exemption_score > 0.6:
                        st.warning("âš ï¸ **ì¤‘ê°„ ë©´ì±… ìœ„í—˜**: ìœ ì‚¬í•œ ë©´ì±… ì‚¬ë¡€ê°€ ìˆìŠµë‹ˆë‹¤.")
                    else:
                        st.info("â„¹ï¸ **ë‚®ì€ ë©´ì±… ìœ„í—˜**: ë©´ì±… ì‚¬ë¡€ì™€ì˜ ìœ ì‚¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.")
            
            for i, (total_score, text_sim, country_sim, similar_case) in enumerate(top_similar):
                # ë©´ì±… ì‚¬ë¡€ëŠ” íŠ¹ë³„ í‘œì‹œ
                if similar_case['íŒì •êµ¬ë¶„'] == 'ë©´ì±…':
                    expander_title = f"ğŸ›¡ï¸ #{i+1} ì¢…í•©ìœ ì‚¬ë„ {total_score*100:.1f}% - âš ï¸ **{similar_case['íŒì •êµ¬ë¶„']}** ({similar_case['ì‚¬ê³ ìœ í˜•ëª…']}) âš ï¸"
                    expanded = True  # ë©´ì±…ì€ ê¸°ë³¸ í¼ì³ì§
                else:
                    expander_title = f"#{i+1} ì¢…í•©ìœ ì‚¬ë„ {total_score*100:.1f}% - {similar_case['íŒì •êµ¬ë¶„']} ({similar_case['ì‚¬ê³ ìœ í˜•ëª…']})"
                    expanded = False
                
                with st.expander(expander_title, expanded=expanded):
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**ğŸ“‹ ì‚¬ë¡€ ì •ë³´**")
                        st.write(f"â€¢ ë³´ìƒíŒŒì¼ë²ˆí˜¸: `{similar_case['ë³´ìƒíŒŒì¼ë²ˆí˜¸']}`")
                        st.write(f"â€¢ ì‚¬ê³ ë²ˆí˜¸: `{similar_case['ì‚¬ê³ ë²ˆí˜¸']}`")
                        st.write(f"â€¢ ìˆ˜ì…êµ­: **{similar_case['ìˆ˜ì…êµ­']}**")
                        st.write(f"â€¢ ë³´í—˜ì¢…ëª©: {similar_case['ë³´í—˜ì¢…ëª©']}")
                        
                        if pd.notna(similar_case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']):
                            amount_str = f"{similar_case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']:,.0f}ì›"
                            if similar_case['ì›í™”ì‚¬ê³ ê¸ˆì•¡'] >= 100000000:
                                amount_str += f" ({similar_case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']/100000000:.1f}ì–µì›)"
                            st.write(f"â€¢ ì‚¬ê³ ê¸ˆì•¡: **{amount_str}**")
                    
                    with col2:
                        st.write("**âš–ï¸ íŒì • ì •ë³´**")
                        
                        if similar_case['íŒì •êµ¬ë¶„'] == 'ì§€ê¸‰':
                            st.success(f"íŒì •êµ¬ë¶„: {similar_case['íŒì •êµ¬ë¶„']}")
                        elif similar_case['íŒì •êµ¬ë¶„'] == 'ë©´ì±…':
                            st.error(f"íŒì •êµ¬ë¶„: {similar_case['íŒì •êµ¬ë¶„']}")
                        else:
                            st.warning(f"íŒì •êµ¬ë¶„: {similar_case['íŒì •êµ¬ë¶„']}")
                        
                        st.write(f"â€¢ íŒì •ì‚¬ìœ : **{similar_case['íŒì •ì‚¬ìœ ']}**")
                        st.write(f"â€¢ íŒì •íšŒì°¨: {similar_case['íŒì •íšŒì°¨']}íšŒ")
                        st.write(f"â€¢ ì‚¬ê³ ì§„í–‰ìƒíƒœ: {similar_case['ì‚¬ê³ ì§„í–‰ìƒíƒœ']}")
                    
                    # ìœ ì‚¬ë„ ìƒì„¸ ë¶„ì„
                    st.write("**ğŸ“Š ìœ ì‚¬ë„ ì„¸ë¶€ ë¶„ì„**")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("í…ìŠ¤íŠ¸ ìœ ì‚¬ë„", f"{text_sim*100:.1f}%")
                    with col2:
                        st.metric("êµ­ê°€ ìœ ì‚¬ë„", f"{country_sim*100:.1f}%")
                    with col3:
                        st.metric("ì¢…í•© ìœ ì‚¬ë„", f"{total_score*100:.1f}%")
                    
                    # ì§„í–‰ë°”
                    total_pct = min(total_score * 100, 100)
                    st.progress(float(total_pct) / 100)
                    
                    if pd.notna(similar_case['ì‚¬ê³ ì„¤ëª…']) and len(str(similar_case['ì‚¬ê³ ì„¤ëª…'])) > 10:
                        st.write("**ğŸ“ ì‚¬ê³ ì„¤ëª…**")
                        st.markdown(f"> {similar_case['ì‚¬ê³ ì„¤ëª…']}")

                    # ì „ë¬¸ê°€ìš© í•µì‹¬ ë³€ìˆ˜ ìš”ì•½
                    st.write("**ğŸ” í•µì‹¬ ë³€ìˆ˜**")
                    st.write(f"- ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…: {similar_case.get('ìƒí’ˆë¶„ë¥˜ê·¸ë£¹ëª…','-')}")
                    st.write(f"- ê²°ì œë°©ë²•/ì¡°ê±´: {similar_case.get('ê²°ì œë°©ë²•','-')} / {similar_case.get('ê²°ì œì¡°ê±´','-')}")
                    st.write(f"- ë¶€ë³´ìœ¨: {similar_case.get('ë¶€ë³´ìœ¨','-')}")
                    st.write(f"- í–¥í›„ì „ë§: {similar_case.get('í–¥í›„ê²°ì œì „ë§','-')}")
        else:
            st.warning("ì¡°ê±´ì— ë§ëŠ” ìœ ì‚¬ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def create_exemption_reason_tab(df):
    """ë©´ì±…ì‚¬ìœ ë³„ ì‚¬ë¡€ì¡°íšŒ íƒ­"""
    
    st.markdown("""
    <div class="main-header">
        <h2>ğŸ›¡ï¸ ë©´ì±…ì‚¬ìœ ë³„ ì‚¬ë¡€ì¡°íšŒ</h2>
        <p>íŠ¹ì • ë©´ì±…ì‚¬ìœ ë¡œ ì‹¤ì œ ë©´ì±…ëœ ì‚¬ë¡€ë“¤ì„ íƒìƒ‰í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ë©´ì±… ì‚¬ë¡€ë§Œ í•„í„°ë§
    exemption_df = df[df['íŒì •êµ¬ë¶„'] == 'ë©´ì±…'].copy()
    
    if len(exemption_df) == 0:
        st.warning("ë©´ì±… ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë©´ì±…ì‚¬ìœ  í†µê³„
    st.subheader("ğŸ“Š ë©´ì±…ì‚¬ìœ  í†µê³„")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ì´ ë©´ì±… ì‚¬ë¡€", len(exemption_df))
    
    with col2:
        unique_reasons = exemption_df['íŒì •ì‚¬ìœ '].nunique()
        st.metric("ë©´ì±…ì‚¬ìœ  ì¢…ë¥˜", unique_reasons)
    
    with col3:
        avg_amount = exemption_df['ì›í™”ì‚¬ê³ ê¸ˆì•¡'].mean()
        if pd.notna(avg_amount):
            st.metric("í‰ê·  ì‚¬ê³ ê¸ˆì•¡", f"{avg_amount:,.0f}ì›")
        else:
            st.metric("í‰ê·  ì‚¬ê³ ê¸ˆì•¡", "N/A")
    
    # ë©´ì±…ì‚¬ìœ ë³„ ë¶„í¬ ì‹œê°í™”
    st.subheader("ğŸ“ˆ ë©´ì±…ì‚¬ìœ ë³„ ë¶„í¬")
    
    reason_counts = exemption_df['íŒì •ì‚¬ìœ '].value_counts().head(15)
    
    fig = px.bar(
        x=reason_counts.values,
        y=reason_counts.index,
        orientation='h',
        title="ìƒìœ„ 15ê°œ ë©´ì±…ì‚¬ìœ ë³„ ì‚¬ë¡€ ìˆ˜",
        labels={'x': 'ì‚¬ë¡€ ìˆ˜', 'y': 'ë©´ì±…ì‚¬ìœ '},
        color=reason_counts.values,
        color_continuous_scale='Reds'
    )
    
    fig.update_layout(
        height=500,
        showlegend=False,
        xaxis_title="ì‚¬ë¡€ ìˆ˜",
        yaxis_title="ë©´ì±…ì‚¬ìœ "
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # ë©´ì±…ì‚¬ìœ  ì„ íƒ ë° ì‚¬ë¡€ ì¡°íšŒ
    st.subheader("ğŸ” ë©´ì±…ì‚¬ìœ ë³„ ì‚¬ë¡€ ì¡°íšŒ")
    
    # ë©´ì±…ì‚¬ìœ  ëª©ë¡ (ì‚¬ë¡€ ìˆ˜ì™€ í•¨ê»˜ í‘œì‹œ)
    reason_options = []
    for reason, count in reason_counts.items():
        reason_options.append(f"{reason} ({count}ê±´)")
    
    selected_reason_full = st.selectbox(
        "ë©´ì±…ì‚¬ìœ ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        options=reason_options,
        help="ì‚¬ë¡€ ìˆ˜ê°€ ë§ì€ ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
    )
    
    if selected_reason_full:
        # ì„ íƒëœ ë©´ì±…ì‚¬ìœ ì—ì„œ ì‚¬ë¡€ ìˆ˜ ì œê±°
        selected_reason = selected_reason_full.split(" (")[0]
        
        # í•´ë‹¹ ë©´ì±…ì‚¬ìœ ì˜ ì‚¬ë¡€ë“¤ í•„í„°ë§
        filtered_cases = exemption_df[exemption_df['íŒì •ì‚¬ìœ '] == selected_reason].copy()
        
        if len(filtered_cases) > 0:
            st.success(f"âœ… **{selected_reason}** ë©´ì±…ì‚¬ìœ ë¡œ ì´ **{len(filtered_cases)}ê±´**ì˜ ì‚¬ë¡€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

            # ê¸°ë³¸: ë©´ì±…ì‚¬ìœ ë§Œìœ¼ë¡œ í•„í„°ë§ëœ ê²°ê³¼ë¥¼ ì‚¬ìš©
            display_cases = filtered_cases.copy()

            # ì„ íƒ: ê³ ê¸‰ í•„í„° (ê¸°ë³¸ ë¹„í™œì„±í™”)
            with st.expander("âš™ï¸ ê³ ê¸‰ í•„í„° (ì„ íƒ)", expanded=False):
                use_advanced_filters = st.checkbox("ê³ ê¸‰ í•„í„° ì‚¬ìš©", value=False)
                if use_advanced_filters:
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        countries = ['ì „ì²´'] + sorted(display_cases['ìˆ˜ì…êµ­'].dropna().unique().tolist())
                        selected_country = st.selectbox("ìˆ˜ì…êµ­ í•„í„°:", countries)
                    with col2:
                        insurance_types = ['ì „ì²´'] + sorted(display_cases['ë³´í—˜ì¢…ëª©'].dropna().unique().tolist())
                        selected_insurance = st.selectbox("ë³´í—˜ì¢…ëª© í•„í„°:", insurance_types)
                    with col3:
                        accident_types = ['ì „ì²´'] + sorted(display_cases['ì‚¬ê³ ìœ í˜•ëª…'].dropna().unique().tolist())
                        selected_accident = st.selectbox("ì‚¬ê³ ìœ í˜• í•„í„°:", accident_types)

                    if selected_country != 'ì „ì²´':
                        display_cases = display_cases[display_cases['ìˆ˜ì…êµ­'] == selected_country]
                        st.info(f"ğŸ” ìˆ˜ì…êµ­ í•„í„°: {selected_country} ({len(display_cases)}ê±´)")
                    if selected_insurance != 'ì „ì²´':
                        display_cases = display_cases[display_cases['ë³´í—˜ì¢…ëª©'] == selected_insurance]
                        st.info(f"ğŸ” ë³´í—˜ì¢…ëª© í•„í„°: {selected_insurance} ({len(display_cases)}ê±´)")
                    if selected_accident != 'ì „ì²´':
                        display_cases = display_cases[display_cases['ì‚¬ê³ ìœ í˜•ëª…'] == selected_accident]
                        st.info(f"ğŸ” ì‚¬ê³ ìœ í˜• í•„í„°: {selected_accident} ({len(display_cases)}ê±´)")

            # í‚¤ì›Œë“œ ê²€ìƒ‰(ì‚¬ê³ ì„¤ëª… ë‚´ í¬í•¨ ê²€ìƒ‰)
            keyword = st.text_input("í‚¤ì›Œë“œ ê²€ìƒ‰(ì‚¬ê³ ì„¤ëª…):", value="", help="ì‚¬ê³ ì„¤ëª…ì— í¬í•¨ë˜ëŠ” í‚¤ì›Œë“œë¡œ ê°„ë‹¨ ê²€ìƒ‰")
            if keyword:
                mask = display_cases['ì‚¬ê³ ì„¤ëª…'].astype(str).str.contains(keyword, case=False, na=False)
                display_cases = display_cases[mask]
                st.info(f"ğŸ” í‚¤ì›Œë“œ '{keyword}' ê²°ê³¼: {len(display_cases)}ê±´")
            
            if len(display_cases) > 0:
                # ì •ë ¬ ì˜µì…˜
                sort_options = {
                    'ì‚¬ê³ ê¸ˆì•¡ (ë†’ì€ìˆœ)': 'ì›í™”ì‚¬ê³ ê¸ˆì•¡',
                    'ì‚¬ê³ ê¸ˆì•¡ (ë‚®ì€ìˆœ)': 'ì›í™”ì‚¬ê³ ê¸ˆì•¡',
                    'íŒì •íšŒì°¨ (ë†’ì€ìˆœ)': 'íŒì •íšŒì°¨',
                    'íŒì •íšŒì°¨ (ë‚®ì€ìˆœ)': 'íŒì •íšŒì°¨',
                    'ì‚¬ê³ ì ‘ìˆ˜ì¼ì (ìµœì‹ ìˆœ)': 'ì‚¬ê³ ì ‘ìˆ˜ì¼ì',
                    'ì‚¬ê³ ì ‘ìˆ˜ì¼ì (ì˜¤ë˜ëœìˆœ)': 'ì‚¬ê³ ì ‘ìˆ˜ì¼ì'
                }
                
                selected_sort = st.selectbox("ì •ë ¬ ê¸°ì¤€:", list(sort_options.keys()))
                
                # ì •ë ¬ ì ìš©
                if 'ë†’ì€ìˆœ' in selected_sort or 'ìµœì‹ ìˆœ' in selected_sort:
                    ascending = False
                else:
                    ascending = True
                
                display_cases = display_cases.sort_values(
                    by=sort_options[selected_sort], 
                    ascending=ascending,
                    na_position='last'
                )
                
                # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ
                st.write("**ğŸ“‹ ì‚¬ë¡€ ëª©ë¡**")
                
                # í‘œì‹œí•  ë°ì´í„° ì¤€ë¹„
                display_data = display_cases[[
                    'ë³´ìƒíŒŒì¼ë²ˆí˜¸', 'ì‚¬ê³ ë²ˆí˜¸', 'íŒì •íšŒì°¨', 'ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©', 
                    'ì‚¬ê³ ìœ í˜•ëª…', 'ì›í™”ì‚¬ê³ ê¸ˆì•¡', 'ì‚¬ê³ ì„¤ëª…', 'ì‚¬ê³ ì§„í–‰ìƒíƒœ'
                ]].copy()
                
                # ê¸ˆì•¡ í¬ë§·íŒ…
                display_data['ì‚¬ê³ ê¸ˆì•¡'] = display_data['ì›í™”ì‚¬ê³ ê¸ˆì•¡'].apply(
                    lambda x: f"{x:,.0f}ì›" if pd.notna(x) else "N/A"
                )
                
                # ì‚¬ê³ ì„¤ëª… ìš”ì•½ (50ì ì œí•œ)
                display_data['ì‚¬ê³ ì„¤ëª…_ìš”ì•½'] = display_data['ì‚¬ê³ ì„¤ëª…'].apply(
                    lambda x: str(x)[:50] + "..." if pd.notna(x) and len(str(x)) > 50 else str(x) if pd.notna(x) else "N/A"
                )
                
                # ìµœì¢… í‘œì‹œ ì»¬ëŸ¼
                final_columns = [
                    'ë³´ìƒíŒŒì¼ë²ˆí˜¸', 'ì‚¬ê³ ë²ˆí˜¸', 'íŒì •íšŒì°¨', 'ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©',
                    'ì‚¬ê³ ìœ í˜•ëª…', 'ì‚¬ê³ ê¸ˆì•¡', 'ì‚¬ê³ ì„¤ëª…_ìš”ì•½', 'ì‚¬ê³ ì§„í–‰ìƒíƒœ'
                ]
                
                # ì»¬ëŸ¼ëª… í•œê¸€í™”
                column_mapping = {
                    'ë³´ìƒíŒŒì¼ë²ˆí˜¸': 'ë³´ìƒíŒŒì¼ë²ˆí˜¸',
                    'ì‚¬ê³ ë²ˆí˜¸': 'ì‚¬ê³ ë²ˆí˜¸', 
                    'íŒì •íšŒì°¨': 'íŒì •íšŒì°¨',
                    'ìˆ˜ì…êµ­': 'ìˆ˜ì…êµ­',
                    'ë³´í—˜ì¢…ëª©': 'ë³´í—˜ì¢…ëª©',
                    'ì‚¬ê³ ìœ í˜•ëª…': 'ì‚¬ê³ ìœ í˜•',
                    'ì‚¬ê³ ê¸ˆì•¡': 'ì‚¬ê³ ê¸ˆì•¡',
                    'ì‚¬ê³ ì„¤ëª…_ìš”ì•½': 'ì‚¬ê³ ì„¤ëª…',
                    'ì‚¬ê³ ì§„í–‰ìƒíƒœ': 'ì§„í–‰ìƒíƒœ'
                }
                
                display_data = display_data[final_columns].rename(columns=column_mapping)
                
                # í˜ì´ì§€ë„¤ì´ì…˜
                items_per_page = 20
                total_items = len(display_data)
                total_pages = (total_items + items_per_page - 1) // items_per_page
                
                if total_pages > 1:
                    current_page = st.selectbox(
                        f"í˜ì´ì§€ ì„ íƒ (ì´ {total_pages}í˜ì´ì§€):",
                        range(1, total_pages + 1)
                    ) - 1
                else:
                    current_page = 0
                
                start_idx = current_page * items_per_page
                end_idx = min(start_idx + items_per_page, total_items)
                
                # í˜„ì¬ í˜ì´ì§€ ë°ì´í„° í‘œì‹œ
                current_data = display_data.iloc[start_idx:end_idx]
                
                st.dataframe(
                    current_data,
                    use_container_width=True,
                    hide_index=True
                )
                
                # í˜ì´ì§€ ì •ë³´
                if total_pages > 1:
                    st.write(f"ğŸ“„ {start_idx + 1}~{end_idx} / {total_items}ê±´ (í˜ì´ì§€ {current_page + 1}/{total_pages})")
                
                # ìœ ì‚¬ë„ ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€
                st.markdown("---")
                st.subheader("ğŸ” ìœ ì‚¬ë„ ê²€ìƒ‰ ê¸°ëŠ¥")
                
                # ìœ ì‚¬ë„ ê²€ìƒ‰ ë°©ì‹ ì„ íƒ(ê¸°ë³¸: ë©´ì±…ì‚¬ìœ ë§Œ í•„í„°ëœ í’€ì—ì„œ ê²€ìƒ‰)
                search_method = st.radio(
                    "ê²€ìƒ‰ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”:",
                    [
                        "ë°©ì‹ A: í•´ë‹¹ ë©´ì±…ì‚¬ìœ  ì‚¬ë¡€ë“¤(í˜„ì¬ í‘œì‹œëœ ëª©ë¡)ì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰",
                        "ë°©ì‹ B: ì „ì²´ ë°ì´í„°ì—ì„œ í•´ë‹¹ ë©´ì±…ì‚¬ìœ ì™€ ìœ ì‚¬í•œ ì‚¬ë¡€ ê²€ìƒ‰", 
                        "ë°©ì‹ C: ë³µí•© ì¡°ê±´ìœ¼ë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰"
                    ],
                    help="A ê¶Œì¥: ê³¼ë„í•œ ì„ í•„í„°ë¡œ 0ê±´ ë°©ì§€"
                )
                
                # ê²€ìƒ‰ì–´ ì…ë ¥
                search_text = st.text_area(
                    "ê²€ìƒ‰í•  ì‚¬ê³ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”:",
                    placeholder="ì˜ˆ: ìˆ˜ì¶œ ì§€ì—°, ì§€ê¸‰ ê±°ì ˆ, ê³„ì•½ ìœ„ë°˜ ë“±",
                    height=100,
                    help="ì‚¬ê³ ì˜ ì£¼ìš” ë‚´ìš©ì„ ììœ ë¡­ê²Œ ì…ë ¥í•˜ì„¸ìš”"
                )
                
                # ì¶”ê°€ ì¡°ê±´ (ë°©ì‹ Cìš©)
                additional_conditions = {}
                if "ë°©ì‹ C" in search_method:
                    st.write("**ì¶”ê°€ ê²€ìƒ‰ ì¡°ê±´:**")
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        additional_conditions['country'] = st.selectbox(
                            "ìˆ˜ì…êµ­ (ì„ íƒì‚¬í•­):",
                            ['ì „ì²´'] + sorted(df['ìˆ˜ì…êµ­'].unique().tolist())
                        )
                        additional_conditions['insurance'] = st.selectbox(
                            "ë³´í—˜ì¢…ëª© (ì„ íƒì‚¬í•­):",
                            ['ì „ì²´'] + sorted(df['ë³´í—˜ì¢…ëª©'].unique().tolist())
                        )
                    
                    with col2:
                        additional_conditions['accident_type'] = st.selectbox(
                            "ì‚¬ê³ ìœ í˜• (ì„ íƒì‚¬í•­):",
                            ['ì „ì²´'] + sorted(df['ì‚¬ê³ ìœ í˜•ëª…'].unique().tolist())
                        )
                        additional_conditions['amount_range'] = st.selectbox(
                            "ì‚¬ê³ ê¸ˆì•¡ ë²”ìœ„ (ì„ íƒì‚¬í•­):",
                            ['ì „ì²´', '1000ë§Œì› ì´í•˜', '1000ë§Œì›-5000ë§Œì›', '5000ë§Œì›-1ì–µì›', '1ì–µì› ì´ìƒ']
                        )
                
                # ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤í–‰
                if st.button("ğŸ” ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤í–‰", type="primary"):
                    if search_text.strip():
                        # ì‹œìŠ¤í…œ ì´ˆê¸°í™” í™•ì¸
                        if 'improved_system' not in st.session_state:
                            st.session_state.improved_system = ImprovedInsuranceSystem()
                        system = st.session_state.improved_system
                        
                        # ê²€ìƒ‰ ë°©ì‹ì— ë”°ë¥¸ í›„ë³´ ë°ì´í„° ì„ íƒ
                        if "ë°©ì‹ A" in search_method:
                            # í˜„ì¬ í‘œì‹œ ëª©ë¡(ë©´ì±…ì‚¬ìœ  + ì„ íƒì  ê³ ê¸‰í•„í„° + í‚¤ì›Œë“œ)ì—ì„œ ê²€ìƒ‰
                            candidates_df = display_cases.copy()
                            st.info(f"ğŸ” ë°©ì‹ A: í˜„ì¬ í‘œì‹œ {len(candidates_df)}ê±´ì—ì„œ ê²€ìƒ‰")
                            
                        elif "ë°©ì‹ B" in search_method:
                            # ì „ì²´ ë°ì´í„°ì—ì„œ í•´ë‹¹ ë©´ì±…ì‚¬ìœ ì™€ ìœ ì‚¬í•œ ì‚¬ë¡€ ê²€ìƒ‰
                            candidates_df = df.copy()
                            st.info(f"ğŸ” ë°©ì‹ B: ì „ì²´ ë°ì´í„° {len(candidates_df)}ê±´ì—ì„œ '{selected_reason}' ê´€ë ¨ ì‚¬ë¡€ ê²€ìƒ‰")
                            
                        else:  # ë°©ì‹ C
                            # ë³µí•© ì¡°ê±´ ì ìš©
                            candidates_df = df.copy()
                            
                            # ì¶”ê°€ ì¡°ê±´ í•„í„°ë§
                            if additional_conditions['country'] != 'ì „ì²´':
                                candidates_df = candidates_df[candidates_df['ìˆ˜ì…êµ­'] == additional_conditions['country']]
                            
                            if additional_conditions['insurance'] != 'ì „ì²´':
                                candidates_df = candidates_df[candidates_df['ë³´í—˜ì¢…ëª©'] == additional_conditions['insurance']]
                            
                            if additional_conditions['accident_type'] != 'ì „ì²´':
                                candidates_df = candidates_df[candidates_df['ì‚¬ê³ ìœ í˜•ëª…'] == additional_conditions['accident_type']]
                            
                            if additional_conditions['amount_range'] != 'ì „ì²´':
                                if additional_conditions['amount_range'] == '1000ë§Œì› ì´í•˜':
                                    candidates_df = candidates_df[candidates_df['ì›í™”ì‚¬ê³ ê¸ˆì•¡'] <= 10000000]
                                elif additional_conditions['amount_range'] == '1000ë§Œì›-5000ë§Œì›':
                                    candidates_df = candidates_df[(candidates_df['ì›í™”ì‚¬ê³ ê¸ˆì•¡'] > 10000000) & (candidates_df['ì›í™”ì‚¬ê³ ê¸ˆì•¡'] <= 50000000)]
                                elif additional_conditions['amount_range'] == '5000ë§Œì›-1ì–µì›':
                                    candidates_df = candidates_df[(candidates_df['ì›í™”ì‚¬ê³ ê¸ˆì•¡'] > 50000000) & (candidates_df['ì›í™”ì‚¬ê³ ê¸ˆì•¡'] <= 100000000)]
                                elif additional_conditions['amount_range'] == '1ì–µì› ì´ìƒ':
                                    candidates_df = candidates_df[candidates_df['ì›í™”ì‚¬ê³ ê¸ˆì•¡'] > 100000000]
                            
                            st.info(f"ğŸ” ë°©ì‹ C: ë³µí•© ì¡°ê±´ ì ìš© í›„ {len(candidates_df)}ê±´ì—ì„œ ê²€ìƒ‰")
                        
                        # ì¿¼ë¦¬ ì¼€ì´ìŠ¤ ìƒì„±
                        query_case = {
                            'ì‚¬ê³ ì„¤ëª…': search_text,
                            'íŒì •ì‚¬ìœ ': selected_reason,
                            'ìˆ˜ì…êµ­': additional_conditions.get('country', 'ì „ì²´'),
                            'ë³´í—˜ì¢…ëª©': additional_conditions.get('insurance', 'ì „ì²´'),
                            'ì‚¬ê³ ìœ í˜•ëª…': additional_conditions.get('accident_type', 'ì „ì²´')
                        }
                        
                        # ìœ ì‚¬ë„ ê³„ì‚°
                        with st.spinner("ìœ ì‚¬ë„ ê³„ì‚° ì¤‘..."):
                            try:
                                similarities = system.calculate_similarity_scores(query_case, candidates_df)

                                # ìƒìœ„ 5ê±´ë§Œ, 0.30 ë¯¸ë§Œ ì œì™¸
                                min_score = 0.30
                                top_items = [r for r in similarities if r[0] >= min_score][:5] if similarities else []

                                if top_items:
                                    # ê²°ê³¼ í‘œì‹œ
                                    st.success(f"âœ… ìœ ì‚¬ë„ ê²€ìƒ‰ ì™„ë£Œ! ìƒìœ„ {len(top_items)}ê°œ ê²°ê³¼ (ì„ê³„ì¹˜ {min_score:.2f} ì ìš©)")

                                    # ê²°ê³¼ í…Œì´ë¸” ìƒì„±
                                    results_data = []
                                    for i, (score, text_sim, country_sim, case) in enumerate(top_items, 1):
                                        results_data.append({
                                            'ìˆœìœ„': i,
                                            'ìœ ì‚¬ë„(%)': f"{score*100:.1f}%",
                                            'íŒì •êµ¬ë¶„': case['íŒì •êµ¬ë¶„'],
                                            'íŒì •ì‚¬ìœ ': case['íŒì •ì‚¬ìœ '],
                                            'ìˆ˜ì…êµ­': case['ìˆ˜ì…êµ­'],
                                            'ë³´í—˜ì¢…ëª©': case['ë³´í—˜ì¢…ëª©'],
                                            'ì‚¬ê³ ìœ í˜•': case['ì‚¬ê³ ìœ í˜•ëª…'],
                                            'ì‚¬ê³ ê¸ˆì•¡': f"{case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']:,.0f}ì›" if pd.notna(case['ì›í™”ì‚¬ê³ ê¸ˆì•¡']) else "N/A",
                                            'ì‚¬ê³ ì„¤ëª…': str(case['ì‚¬ê³ ì„¤ëª…'])[:100] + "..." if len(str(case['ì‚¬ê³ ì„¤ëª…'])) > 100 else str(case['ì‚¬ê³ ì„¤ëª…'])
                                        })
                                    
                                    # ê²°ê³¼ í…Œì´ë¸” í‘œì‹œ
                                    results_df = pd.DataFrame(results_data)
                                    st.dataframe(
                                        results_df,
                                        use_container_width=True,
                                        hide_index=True
                                    )
                                    
                                    # ê²€ìƒ‰ ë°©ì‹ë³„ í†µê³„
                                    st.subheader("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„")
                                    
                                    col1, col2, col3 = st.columns(3)
                                    
                                    with col1:
                                        exemption_count = sum(1 for _, _, _, case in top_items if case['íŒì •êµ¬ë¶„'] == 'ë©´ì±…')
                                        st.metric("ë©´ì±… ì‚¬ë¡€", exemption_count)
                                    
                                    with col2:
                                        avg_similarity = sum(score for score, _, _, _ in top_items) / len(top_items)
                                        st.metric("í‰ê·  ìœ ì‚¬ë„", f"{avg_similarity*100:.1f}%")
                                    
                                    with col3:
                                        max_similarity = max(score for score, _, _, _ in top_items)
                                        st.metric("ìµœê³  ìœ ì‚¬ë„", f"{max_similarity*100:.1f}%")
                                    
                                    # ê²€ìƒ‰ ë°©ì‹ë³„ íŠ¹ì§• ì„¤ëª…
                                    st.info(f"""
                                    **ğŸ” {search_method}**
                                    - ê²€ìƒ‰ ëŒ€ìƒ: {len(candidates_df)}ê±´
                                    - ê²€ìƒ‰ ê²°ê³¼: {len(top_items)}ê±´
                                    - ì£¼ìš” íŠ¹ì§•: {'í•´ë‹¹ ë©´ì±…ì‚¬ìœ  ì‚¬ë¡€ë“¤ ì¤‘ì—ì„œ ìœ ì‚¬ë„ ê¸°ë°˜ ì •ë ¬' if 'ë°©ì‹ A' in search_method else 'ì „ì²´ ë°ì´í„°ì—ì„œ ë©´ì±…ì‚¬ìœ  ê´€ë ¨ì„± ê³ ë ¤' if 'ë°©ì‹ B' in search_method else 'ë³µí•© ì¡°ê±´ + ìœ ì‚¬ë„ ê²€ìƒ‰'}
                                    """)
                                    
                                else:
                                    st.warning("âŒ ìœ ì‚¬í•œ ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                    
                            except Exception as e:
                                st.error(f"âŒ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    else:
                        st.warning("ê²€ìƒ‰í•  ì‚¬ê³ ì„¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                
                # ìƒì„¸ ë¶„ì„
                st.subheader("ğŸ“Š ì„ íƒëœ ë©´ì±…ì‚¬ìœ  ìƒì„¸ ë¶„ì„")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # ìˆ˜ì…êµ­ë³„ ë¶„í¬
                    country_dist = display_cases['ìˆ˜ì…êµ­'].value_counts().head(10)
                    fig_country = px.pie(
                        values=country_dist.values,
                        names=country_dist.index,
                        title=f"ìˆ˜ì…êµ­ë³„ ë¶„í¬ (ìƒìœ„ 10ê°œ)"
                    )
                    st.plotly_chart(fig_country, use_container_width=True)
                
                with col2:
                    # ë³´í—˜ì¢…ëª©ë³„ ë¶„í¬
                    insurance_dist = display_cases['ë³´í—˜ì¢…ëª©'].value_counts().head(10)
                    fig_insurance = px.pie(
                        values=insurance_dist.values,
                        names=insurance_dist.index,
                        title=f"ë³´í—˜ì¢…ëª©ë³„ ë¶„í¬ (ìƒìœ„ 10ê°œ)"
                    )
                    st.plotly_chart(fig_insurance, use_container_width=True)
                
                # ì‚¬ê³ ê¸ˆì•¡ ë¶„í¬
                if display_cases['ì›í™”ì‚¬ê³ ê¸ˆì•¡'].notna().any():
                    fig_amount = px.histogram(
                        display_cases,
                        x='ì›í™”ì‚¬ê³ ê¸ˆì•¡',
                        nbins=20,
                        title=f"ì‚¬ê³ ê¸ˆì•¡ ë¶„í¬",
                        labels={'ì›í™”ì‚¬ê³ ê¸ˆì•¡': 'ì‚¬ê³ ê¸ˆì•¡ (ì›)', 'count': 'ì‚¬ë¡€ ìˆ˜'}
                    )
                    st.plotly_chart(fig_amount, use_container_width=True)
                
                # íŒì •íšŒì°¨ë³„ ë¶„í¬
                fig_rounds = px.bar(
                    x=display_cases['íŒì •íšŒì°¨'].value_counts().index,
                    y=display_cases['íŒì •íšŒì°¨'].value_counts().values,
                    title=f"íŒì •íšŒì°¨ë³„ ë¶„í¬",
                    labels={'x': 'íŒì •íšŒì°¨', 'y': 'ì‚¬ë¡€ ìˆ˜'}
                )
                st.plotly_chart(fig_rounds, use_container_width=True)
                
            else:
                st.warning("ì„ íƒí•œ í•„í„° ì¡°ê±´ì— ë§ëŠ” ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning(f"'{selected_reason}' ë©´ì±…ì‚¬ìœ ë¡œ ë©´ì±…ëœ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ë©´ì±…ì‚¬ìœ ë¥¼ ì„ íƒí•˜ë©´ í•´ë‹¹ ì‚¬ìœ ë¡œ ë©´ì±…ëœ ì‚¬ë¡€ë“¤ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ë°ì´í„° ë¡œë“œ
    df = load_data()
    if df is None:
        st.error("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê°œì„ ëœ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if 'improved_system' not in st.session_state:
        st.session_state.improved_system = ImprovedInsuranceSystem()
    
    system = st.session_state.improved_system
    
    # ë©”ì¸ í—¤ë”
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“‹ êµ­ì™¸ ì²­êµ¬ ì‹¬ì‚¬ ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰ </h1>
        <p>ìœ ì‚¬ ì‚¬ê³  ì‚¬ë¡€ ê²€ìƒ‰ ì‹œìŠ¤í…œ</p>
    </div>
    """, unsafe_allow_html=True)
    
    # íƒ­ êµ¬ì„±
    tab1, tab2, tab3 = st.tabs([
        "ğŸ” ì‚¬ë¡€ ê²€ìƒ‰",
        "ğŸ›¡ï¸ ë©´ì±…ì‚¬ìœ ë³„ ì‚¬ë¡€ì¡°íšŒ",
        "ğŸŒ êµ­ê°€ ë¶„ì„"        
    ])
    
    with tab1:
        create_similarity_search_interface(system, df)
    
    with tab2:
        create_exemption_reason_tab(df)
    
    with tab3:
        create_country_analysis_tab(df, system.country_processor)
        
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #6c757d; padding: 1rem;">
        <p>ğŸ“‹ ë³´í—˜ì‚¬ê³  ë¶„ì„ ì‹œìŠ¤í…œ</p>
        <small>ê³„ì¸µì  êµ­ê°€ ì²˜ë¦¬ + ë² ì´ì§€ì•ˆ ì‹ ë¢°ë„ + ìŠ¤ë§ˆíŠ¸ í•„í„°ë§</small>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()