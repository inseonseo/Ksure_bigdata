import sys
import os

# KoBERT ê²½ë¡œ ì¶”ê°€
sys.path.append('./KoBERT')

try:
    import torch
    import numpy as np
    from transformers import AutoTokenizer, AutoModel
    
    print("âœ… PyTorchì™€ transformersê°€ ì •ìƒì ìœ¼ë¡œ importë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"PyTorch ë²„ì „: {torch.__version__}")
    
    # ê°„ë‹¨í•œ ë¬¸ì¥ ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
    def test_sentence_similarity():
        print("\nğŸ” ë¬¸ì¥ ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤
        sentences = [
            "í•œ ë‚¨ìê°€ ìŒì‹ì„ ë¨¹ëŠ”ë‹¤.",
            "í•œ ë‚¨ìê°€ ë¹µ í•œ ì¡°ê°ì„ ë¨¹ëŠ”ë‹¤.",
            "ê·¸ ì—¬ìê°€ ì•„ì´ë¥¼ ëŒë³¸ë‹¤.",
            "í•œ ë‚¨ìê°€ ë§ì„ íƒ„ë‹¤.",
            "í•œ ì—¬ìê°€ ë°”ì´ì˜¬ë¦°ì„ ì—°ì£¼í•œë‹¤."
        ]
        
        print("í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤:")
        for i, sentence in enumerate(sentences, 1):
            print(f"{i}. {sentence}")
        
        # ê°„ë‹¨í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜
        def cosine_similarity(a, b):
            return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
        
        # ì„ì‹œë¡œ ëœë¤ ì„ë² ë”©ì„ ì‚¬ìš©í•œ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ëª¨ë¸ì´ ì—†ì„ ê²½ìš°)
        print("\nğŸ“Š ìœ ì‚¬ë„ ê³„ì‚° ê²°ê³¼ (ëœë¤ ì„ë² ë”© ê¸°ë°˜):")
        np.random.seed(42)
        
        for i in range(len(sentences)):
            for j in range(i+1, len(sentences)):
                # ëœë¤ ì„ë² ë”© ìƒì„± (ì‹¤ì œë¡œëŠ” ëª¨ë¸ì—ì„œ ìƒì„±)
                emb1 = np.random.randn(768)
                emb2 = np.random.randn(768)
                
                similarity = cosine_similarity(emb1, emb2)
                print(f"'{sentences[i]}' vs '{sentences[j]}': {similarity:.4f}")
        
        print("\nâœ… ê¸°ë³¸ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    test_sentence_similarity()
    
except ImportError as e:
    print(f"âŒ Import ì˜¤ë¥˜: {e}")
    print("í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

print("\nğŸ¯ KoSimCSE ëª¨ë¸ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!") 