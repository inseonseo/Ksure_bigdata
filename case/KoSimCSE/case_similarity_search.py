import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import LabelEncoder, StandardScaler
import re
from datetime import datetime
import torch
from transformers import AutoTokenizer, AutoModel
import pickle
import os

class CaseSimilaritySearch:
    def __init__(self, data_path='data/testy.csv', fast_mode=False):
        """
        ì‚¬ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        
        Args:
            data_path: í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            fast_mode: ë¹ ë¥¸ ëª¨ë“œ (KoSimCSE ì„ë² ë”© ìƒëµ)
        """
        self.data_path = data_path
        self.fast_mode = fast_mode
        self.data = None
        self.case_summary = None
        self.label_encoders = {}
        self.scaler = None
        self.kosimcse_model = None
        self.kosimcse_tokenizer = None
        self.text_embeddings = None
        
        # ì„ë² ë”© ìºì‹œ íŒŒì¼ ê²½ë¡œ (í˜„ì¬ íŒŒì¼ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬)
        import os
        current_dir = os.path.dirname(os.path.abspath(__file__))
        self.embedding_cache_path = os.path.join(current_dir, 'kosimcse_embeddings_cache.pkl')
        
        # ì…ë ¥ í•„ë“œ ì •ì˜
        self.input_fields = {
            'ì‹ ì²­ëŒ€ìƒêµ¬ë¶„': 'dropdown',
            'ì‹ ì²­ì': 'text', 
            'ë³´í—˜ì¢…ëª©': 'dropdown',
            'ì‚¬ê³ ìœ í˜•ëª…': 'dropdown',
            'ìˆ˜ì¶œì': 'text',
            'ìˆ˜ì…êµ­': 'dropdown'
        }
        
        self.optional_fields = {
            'ì‚¬ê³ ê²½ìœ„': 'textarea',
            'ì‚¬ê³ ì„¤ëª…': 'textarea'
        }
        
        # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        self.load_and_preprocess_data()
    
    def load_kosimcse_model(self):
        """KoSimCSE ëª¨ë¸ ë¡œë“œ"""
        print("ğŸ¤– KoSimCSE ëª¨ë¸ ë¡œë“œ ì¤‘...")
        try:
            # KoSimCSE ëª¨ë¸ ê²½ë¡œ (Hugging Face ëª¨ë¸ ì‚¬ìš©)
            model_path = 'BM-K/KoSimCSE-roberta'
            
            self.kosimcse_tokenizer = AutoTokenizer.from_pretrained(model_path)
            self.kosimcse_model = AutoModel.from_pretrained(model_path)
            print("âœ… KoSimCSE ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                
        except Exception as e:
            print(f"âš ï¸ KoSimCSE ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            print("âš ï¸ KoSimCSE ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.kosimcse_model = None
            self.kosimcse_tokenizer = None
    
    def encode_text_with_kosimcse(self, texts):
        """KoSimCSEë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        if self.kosimcse_model is None or self.kosimcse_tokenizer is None:
            return None
        
        try:
            # ë°°ì¹˜ í¬ê¸° ì¦ê°€ (8 -> 32)
            batch_size = 32
            embeddings = []
            
            print(f"ğŸ¤– KoSimCSE ì„ë² ë”© ìƒì„± ì¤‘... (ì´ {len(texts)}ê°œ, ë°°ì¹˜ í¬ê¸°: {batch_size})")
            
            import time
            start_time = time.time()
            last_reported_progress = -1  # ë§ˆì§€ë§‰ìœ¼ë¡œ ë³´ê³ ëœ ì§„í–‰ë¥  ì¶”ì 
            
            for i in range(0, len(texts), batch_size):
                batch_start_time = time.time()
                batch_texts = texts[i:i+batch_size]
                
                # ì§„í–‰ë¥  ë° ë‚¨ì€ ì‹œê°„ í‘œì‹œ (10%ë§ˆë‹¤ í•œ ë²ˆë§Œ í‘œì‹œ)
                progress = (i / len(texts)) * 100
                progress_milestone = int(progress // 10) * 10  # 10ì˜ ë°°ìˆ˜ë¡œ ë°˜ì˜¬ë¦¼
                
                if (i == 0 or progress_milestone > last_reported_progress) and progress_milestone <= 100:
                    elapsed_time = time.time() - start_time
                    
                    if progress > 0:
                        # ë‚¨ì€ ì‹œê°„ ê³„ì‚°
                        estimated_total_time = elapsed_time / (progress / 100)
                        remaining_time = estimated_total_time - elapsed_time
                        
                        # ì‹œê°„ í¬ë§·íŒ…
                        if remaining_time > 3600:  # 1ì‹œê°„ ì´ìƒ
                            remaining_str = f"{remaining_time/3600:.1f}ì‹œê°„"
                        elif remaining_time > 60:  # 1ë¶„ ì´ìƒ
                            remaining_str = f"{remaining_time/60:.1f}ë¶„"
                        else:
                            remaining_str = f"{remaining_time:.0f}ì´ˆ"
                        
                        print(f"   ì§„í–‰ë¥ : {progress_milestone}% ({i}/{len(texts)}) - ë‚¨ì€ ì‹œê°„: ì•½ {remaining_str}")
                    else:
                        print(f"   ì§„í–‰ë¥ : {progress_milestone}% ({i}/{len(texts)})")
                    
                    last_reported_progress = progress_milestone
                
                # í† í¬ë‚˜ì´ì§•
                inputs = self.kosimcse_tokenizer(
                    batch_texts,
                    padding=True,
                    truncation=True,
                    max_length=256,  # ìµœëŒ€ ê¸¸ì´ ë‹¨ì¶• (512 -> 256)
                    return_tensors="pt"
                )
                
                # ì„ë² ë”© ìƒì„±
                with torch.no_grad():
                    outputs = self.kosimcse_model(**inputs)
                    # [CLS] í† í°ì˜ ì„ë² ë”© ì‚¬ìš©
                    batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()
                    embeddings.extend(batch_embeddings)
                
                # ë°°ì¹˜ë³„ ì²˜ë¦¬ ì‹œê°„ í‘œì‹œ (ë””ë²„ê¹…ìš©)
                batch_time = time.time() - batch_start_time
                if i % (batch_size * 20) == 0:  # 20ë°°ì¹˜ë§ˆë‹¤
                    print(f"   ë°°ì¹˜ ì²˜ë¦¬ ì‹œê°„: {batch_time:.2f}ì´ˆ")
            
            total_time = time.time() - start_time
            print(f"âœ… KoSimCSE ì„ë² ë”© ìƒì„± ì™„ë£Œ! (ì´ ì†Œìš”ì‹œê°„: {total_time/60:.1f}ë¶„)")
            return np.array(embeddings)
            
        except Exception as e:
            print(f"âš ï¸ KoSimCSE ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return None
    
    def load_and_preprocess_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì‚¬ê±´ë³„ ì „ì²˜ë¦¬"""
        print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ë°ì´í„° ë¡œë“œ
        self.data = pd.read_csv(self.data_path, encoding='cp949')
        
        # KoSimCSE ëª¨ë¸ ë¡œë“œ
        self.load_kosimcse_model()
        
        # ì‚¬ê±´ë³„ë¡œ ê·¸ë£¹í•‘í•˜ì—¬ ìš”ì•½ ì •ë³´ ìƒì„±
        self.create_case_summary()
        
        # í…ìŠ¤íŠ¸ ë° ë²”ì£¼í˜• ë³€ìˆ˜ ì „ì²˜ë¦¬
        self.preprocess_features()
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.case_summary)}ê°œ ì‚¬ê±´")
    
    def create_case_summary(self):
        """ì‚¬ê±´ë³„ë¡œ ëª¨ë“  íŒì •ì„ ë¬¶ì–´ì„œ ìš”ì•½ ì •ë³´ ìƒì„±"""
        print("ğŸ”§ ì‚¬ê±´ë³„ ìš”ì•½ ì •ë³´ ìƒì„± ì¤‘...")
        
        # testy.csvì˜ ì»¬ëŸ¼ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
        # ì‹¤ì œ ì»¬ëŸ¼ëª…ì„ í™•ì¸í•˜ê³  ìˆ˜ì • í•„ìš”
        if 'ë³´ìƒíŒŒì¼ë²ˆí˜¸' in self.data.columns and 'ì‚¬ê³ ë²ˆí˜¸' in self.data.columns:
            # ì‚¬ê±´ë³„ ê·¸ë£¹í•‘
            case_groups = self.data.groupby(['ë³´ìƒíŒŒì¼ë²ˆí˜¸', 'ì‚¬ê³ ë²ˆí˜¸']).agg({
                # ê¸°ë³¸ ì‚¬ê³  ì •ë³´ (ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©)
                'ì‚¬ê³ ì ‘ìˆ˜ì¼ì': 'first' if 'ì‚¬ê³ ì ‘ìˆ˜ì¼ì' in self.data.columns else None,
                'ì‚¬ê³ ê¸ˆì•¡': 'first' if 'ì‚¬ê³ ê¸ˆì•¡' in self.data.columns else None,
                'ì‚¬ê³ ìœ í˜•ëª…': 'first' if 'ì‚¬ê³ ìœ í˜•ëª…' in self.data.columns else None,
                'ìˆ˜ì…êµ­': 'first' if 'ìˆ˜ì…êµ­' in self.data.columns else None,
                'ì‚¬ê³ ì„¤ëª…': 'first' if 'ì‚¬ê³ ì„¤ëª…' in self.data.columns else None,
                'ìˆ˜ì¶œì': 'first' if 'ìˆ˜ì¶œì' in self.data.columns else None,
                'ë³´í—˜ì¢…ëª©': 'first' if 'ë³´í—˜ì¢…ëª©' in self.data.columns else None,
                'ê²°ì œê¸ˆì•¡': 'first' if 'ê²°ì œê¸ˆì•¡' in self.data.columns else None,
                'ìˆ˜ì…ìëª…': 'first' if 'ìˆ˜ì…ìëª…' in self.data.columns else None,
                
                # íŒì • ê³¼ì • ì •ë³´ (ëª¨ë“  íŒì • í¬í•¨)
                'íŒì •ì¼': list if 'íŒì •ì¼' in self.data.columns else None,
                'íŒì •êµ¬ë¶„': list if 'íŒì •êµ¬ë¶„' in self.data.columns else None,
                'íŒì •ì‚¬ìœ ': list if 'íŒì •ì‚¬ìœ ' in self.data.columns else None,
                'íŒì •ê¸ˆì•¡': list if 'íŒì •ê¸ˆì•¡' in self.data.columns else None,
                'íŒì •ì§„í–‰ìƒíƒœ': list if 'íŒì •ì§„í–‰ìƒíƒœ' in self.data.columns else None,
                'íŒì •íšŒì°¨': list if 'íŒì •íšŒì°¨' in self.data.columns else None
            }).reset_index()
            
            # None ê°’ ì œê±°
            case_groups = case_groups.dropna(axis=1, how='all')
        else:
            # ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ì „ì²´ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ì‚¬ê±´ìœ¼ë¡œ ì²˜ë¦¬
            case_groups = self.data.copy()
            case_groups['ë³´ìƒíŒŒì¼ë²ˆí˜¸'] = 'default'
            case_groups['ì‚¬ê³ ë²ˆí˜¸'] = range(len(case_groups))
        
        # íŒì • íŒ¨í„´ ë¶„ì„
        case_groups = self.analyze_decision_patterns(case_groups)
        
        self.case_summary = case_groups
        print(f"âœ… ì‚¬ê±´ë³„ ìš”ì•½ ì™„ë£Œ: {len(self.case_summary)}ê°œ ì‚¬ê±´")
    
    def analyze_decision_patterns(self, case_groups):
        """íŒì • ê³¼ì •ì˜ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ë¶„ë¥˜"""
        print("ğŸ” íŒì • íŒ¨í„´ ë¶„ì„ ì¤‘...")
        
        for idx, case in case_groups.iterrows():
            if 'íŒì •êµ¬ë¶„' in case and isinstance(case['íŒì •êµ¬ë¶„'], list):
                íŒì •êµ¬ë¶„_list = case['íŒì •êµ¬ë¶„']
                íŒì •ê¸ˆì•¡_list = case.get('íŒì •ê¸ˆì•¡', []) if 'íŒì •ê¸ˆì•¡' in case else []
                
                # íŒ¨í„´ ë¶„ë¥˜
                if len(íŒì •êµ¬ë¶„_list) == 1:
                    pattern = "ë‹¨ì¼íŒì •"
                    summary = f"ë‹¨ì¼ íŒì •: {íŒì •êµ¬ë¶„_list[0]}"
                elif len(set(íŒì •êµ¬ë¶„_list)) == 1:
                    pattern = "ë™ì¼íŒì •_ë°˜ë³µ"
                    summary = f"ë™ì¼ íŒì • ë°˜ë³µ: {íŒì •êµ¬ë¶„_list[0]} ({len(íŒì •êµ¬ë¶„_list)}íšŒ)"
                elif "ë©´ì±…" in íŒì •êµ¬ë¶„_list and "ì§€ê¸‰" in íŒì •êµ¬ë¶„_list:
                    pattern = "ë©´ì±…ì§€ê¸‰_í˜¼ì¬"
                    ë©´ì±…_íšŸìˆ˜ = íŒì •êµ¬ë¶„_list.count("ë©´ì±…")
                    ì§€ê¸‰_íšŸìˆ˜ = íŒì •êµ¬ë¶„_list.count("ì§€ê¸‰")
                    summary = f"í˜¼ì¬ íŒì •: ë©´ì±… {ë©´ì±…_íšŸìˆ˜}íšŒ, ì§€ê¸‰ {ì§€ê¸‰_íšŸìˆ˜}íšŒ"
                else:
                    pattern = "ê¸°íƒ€"
                    summary = f"ë³µí•© íŒì •: {len(íŒì •êµ¬ë¶„_list)}íšŒ íŒì •"
                
                case_groups.at[idx, 'íŒì •íŒ¨í„´'] = pattern
                case_groups.at[idx, 'íŒì •ìš”ì•½'] = summary
                case_groups.at[idx, 'íŒì •íšŸìˆ˜'] = len(íŒì •êµ¬ë¶„_list)
            else:
                # íŒì • ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
                case_groups.at[idx, 'íŒì •íŒ¨í„´'] = "ì •ë³´ì—†ìŒ"
                case_groups.at[idx, 'íŒì •ìš”ì•½'] = "íŒì • ì •ë³´ ì—†ìŒ"
                case_groups.at[idx, 'íŒì •íšŸìˆ˜'] = 0
        
        return case_groups
    
    def preprocess_features(self):
        """í…ìŠ¤íŠ¸ ë° ë²”ì£¼í˜• ë³€ìˆ˜ ì „ì²˜ë¦¬"""
        print("ğŸ”§ íŠ¹ì„± ì „ì²˜ë¦¬ ì¤‘...")
        
        # í…ìŠ¤íŠ¸ í•„ë“œ ê²°í•© (ì‚¬ê³ ì„¤ëª… ì¤‘ì‹¬ìœ¼ë¡œ ë³€ê²½)
        text_columns = []
        
        # ì‚¬ê³ ì„¤ëª…ì„ ìš°ì„ ì ìœ¼ë¡œ í¬í•¨
        if 'ì‚¬ê³ ì„¤ëª…' in self.case_summary.columns:
            text_columns.append('ì‚¬ê³ ì„¤ëª…')
        
        # ìˆ˜ì¶œì/ìˆ˜ì…ìëŠ” ë³´ì¡° ì •ë³´ë¡œë§Œ ì‚¬ìš© (ê°€ì¤‘ì¹˜ ë‚®ì¶¤)
        # ì‹¤ì œë¡œëŠ” ì‚¬ê³ ì„¤ëª…ì— ì—…ì¢… ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŒ
        if 'ìˆ˜ì¶œì' in self.case_summary.columns:
            text_columns.append('ìˆ˜ì¶œì')
        
        if text_columns:
            self.case_summary['combined_text'] = self.case_summary[text_columns].fillna('').agg(' '.join, axis=1)
        else:
            self.case_summary['combined_text'] = ''
        
        # KoSimCSE ì„ë² ë”© ìƒì„±
        if not self.fast_mode and self.kosimcse_model is not None and 'combined_text' in self.case_summary.columns:
            print("ğŸ¤– KoSimCSE ì„ë² ë”© ì²˜ë¦¬ ì¤‘...")
            
            # ìºì‹œì—ì„œ ë¡œë“œ ì‹œë„
            if not self.load_embeddings_cache():
                # ìºì‹œê°€ ì—†ê±°ë‚˜ ë°ì´í„°ê°€ ë³€ê²½ëœ ê²½ìš° ìƒˆë¡œ ìƒì„±
                print("ğŸ”„ ìƒˆë¡œìš´ KoSimCSE ì„ë² ë”© ìƒì„± ì¤‘...")
                texts = self.case_summary['combined_text'].fillna('').tolist()
                self.text_embeddings = self.encode_text_with_kosimcse(texts)
                
                if self.text_embeddings is not None:
                    print(f"âœ… KoSimCSE ì„ë² ë”© ìƒì„± ì™„ë£Œ: {self.text_embeddings.shape}")
                    # ìºì‹œì— ì €ì¥
                    self.save_embeddings_cache()
                else:
                    print("âš ï¸ KoSimCSE ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
            else:
                print("âœ… ìºì‹œëœ KoSimCSE ì„ë² ë”© ì‚¬ìš©")
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”© (ê²€ìƒ‰ ì…ë ¥ ì •ë³´ë§Œ)
        categorical_columns = ['ì‚¬ê³ ìœ í˜•ëª…', 'ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©', 'ê²°ì œë°©ë²•', 'ê²°ì œë°©ë²•ì„¤ëª…', 'ê²°ì œì¡°ê±´', 'í–¥í›„ê²°ì œì „ë§']
        for col in categorical_columns:
            if col in self.case_summary.columns:
                le = LabelEncoder()
                self.case_summary[f'{col}_encoded'] = le.fit_transform(
                    self.case_summary[col].astype(str)
                )
                self.label_encoders[col] = le
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ (ê²€ìƒ‰ ì…ë ¥ ì •ë³´ë§Œ)
        numerical_columns = []
        for col in ['ì‚¬ê³ ê¸ˆì•¡', 'ê²°ì œê¸ˆì•¡', 'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡']:
            if col in self.case_summary.columns:
                numerical_columns.append(col)
        
        if numerical_columns:
            self.scaler = StandardScaler()
            scaled_values = self.scaler.fit_transform(
                self.case_summary[numerical_columns].fillna(0)
            )
            # ìŠ¤ì¼€ì¼ë§ëœ ê°’ì„ ë³„ë„ ì»¬ëŸ¼ìœ¼ë¡œ ì €ì¥
            for i, col in enumerate(numerical_columns):
                self.case_summary[f'{col}_scaled'] = scaled_values[:, i]
        
        print("âœ… íŠ¹ì„± ì „ì²˜ë¦¬ ì™„ë£Œ")
    
    def get_available_options(self):
        """ë“œë¡­ë‹¤ìš´ ì˜µì…˜ë“¤ ë°˜í™˜"""
        options = {}
        
        for field in self.input_fields:
            if self.input_fields[field] == 'dropdown':
                if field in self.case_summary.columns:
                    options[field] = sorted(self.case_summary[field].dropna().unique().tolist())
        
        return options
    
    def search_similar_cases(self, query, top_k=5, verbose=True):
        """
        ìœ ì‚¬í•œ ì‚¬ê³  ì‚¬ë¡€ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (ë”•ì…”ë„ˆë¦¬) - ê²€ìƒ‰ ì…ë ¥ ì •ë³´ë§Œ
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜
            verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
        
        Returns:
            ìœ ì‚¬í•œ ì‚¬ë¡€ë“¤ì˜ ë¦¬ìŠ¤íŠ¸ (íŒì •ì‚¬ìœ , íŒì •êµ¬ë¶„ì€ ì˜ˆì¸¡ ê²°ê³¼ë¡œ í‘œì‹œ)
        """
        if verbose:
            print(f"ğŸ” ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ ì¤‘... (ìƒìœ„ {top_k}ê°œ)")
            print(f"ğŸ“ ê²€ìƒ‰ ì…ë ¥: {list(query.keys())}")
        
        # ì¿¼ë¦¬ ì „ì²˜ë¦¬
        processed_query = self.preprocess_query(query)
        
        # ìœ ì‚¬ë„ ê³„ì‚° (ê²€ìƒ‰ ì…ë ¥ ì •ë³´ë§Œ ì‚¬ìš©)
        similarities = self.calculate_similarity(processed_query)
        
        # ìƒìœ„ kê°œ ì„ íƒ
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        results = []
        for i, idx in enumerate(top_indices):
            case = self.case_summary.iloc[idx]
            similarity = similarities[idx]
            
            # ìƒì„¸ íŒì • ê³¼ì • êµ¬ì„±
            decision_process = self.create_decision_process(case)
            
            result = {
                'rank': i + 1,
                'similarity': float(similarity),
                'case_id': f"{case['ë³´ìƒíŒŒì¼ë²ˆí˜¸']}_{case['ì‚¬ê³ ë²ˆí˜¸']}",
                'íŒì •íšŸìˆ˜': int(case.get('íŒì •íšŸìˆ˜', 0)),
                'decision_process': decision_process,
                'case_info': {
                    'ì‚¬ê³ ì ‘ìˆ˜ì¼ì': case.get('ì‚¬ê³ ì ‘ìˆ˜ì¼ì', 'N/A'),
                    'ì‚¬ê³ ê¸ˆì•¡': case.get('ì‚¬ê³ ê¸ˆì•¡', 0),
                    'ì‚¬ê³ ìœ í˜•ëª…': case.get('ì‚¬ê³ ìœ í˜•ëª…', 'N/A'),
                    'ìˆ˜ì…êµ­': case.get('ìˆ˜ì…êµ­', 'N/A'),
                    'ìˆ˜ì¶œì': case.get('ìˆ˜ì¶œì', 'N/A'),
                    'ë³´í—˜ì¢…ëª©': case.get('ë³´í—˜ì¢…ëª©', 'N/A'),
                    'ê²°ì œê¸ˆì•¡': case.get('ê²°ì œê¸ˆì•¡', 0),
                    'ìˆ˜ì…ìëª…': case.get('ìˆ˜ì…ìëª…', 'N/A'),
                    'ì‚¬ê³ ì„¤ëª…': case.get('ì‚¬ê³ ì„¤ëª…', 'N/A')
                },
                # ì˜ˆì¸¡ ê²°ê³¼ (ì°¾ê³ ì í•˜ëŠ” ì •ë³´)
                'predicted_results': {
                    'íŒì •êµ¬ë¶„': self.get_prediction_from_similar_cases(case, 'íŒì •êµ¬ë¶„'),
                    'íŒì •ì‚¬ìœ ': self.get_prediction_from_similar_cases(case, 'íŒì •ì‚¬ìœ ')
                }
            }
            
            results.append(result)
            
            if verbose:
                self.print_case_result(result)
        
        return results
    
    def preprocess_query(self, query):
        """ê²€ìƒ‰ ì¿¼ë¦¬ ì „ì²˜ë¦¬"""
        processed = {}
        
        # í…ìŠ¤íŠ¸ í•„ë“œ ê²°í•© (ì‚¬ê³ ì„¤ëª… ì¤‘ì‹¬)
        text_parts = []
        
        # ì‚¬ê³ ì„¤ëª…ì„ ìš°ì„ ì ìœ¼ë¡œ í¬í•¨
        if 'ì‚¬ê³ ì„¤ëª…' in query and query['ì‚¬ê³ ì„¤ëª…']:
            text_parts.append(str(query['ì‚¬ê³ ì„¤ëª…']))
        
        # ìˆ˜ì¶œìëŠ” ë³´ì¡° ì •ë³´ë¡œë§Œ ì‚¬ìš©
        if 'ìˆ˜ì¶œì' in query and query['ìˆ˜ì¶œì']:
            text_parts.append(str(query['ìˆ˜ì¶œì']))
        
        processed['combined_text'] = ' '.join(text_parts)
        
        # KoSimCSE ì„ë² ë”© ìƒì„± (ì¿¼ë¦¬ìš©)
        if not self.fast_mode and self.kosimcse_model is not None and processed['combined_text']:
            query_embedding = self.encode_text_with_kosimcse([processed['combined_text']])
            if query_embedding is not None:
                processed['text_embedding'] = query_embedding[0]
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        for field in ['ì‚¬ê³ ìœ í˜•ëª…', 'ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©']:
            if field in query and query[field]:
                if field in self.label_encoders:
                    try:
                        processed[f'{field}_encoded'] = self.label_encoders[field].transform([query[field]])[0]
                    except:
                        processed[f'{field}_encoded'] = -1  # ì•Œ ìˆ˜ ì—†ëŠ” ê°’
                else:
                    processed[f'{field}_encoded'] = 0
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§
        numerical_values = []
        for field in ['ì‚¬ê³ ê¸ˆì•¡', 'ê²°ì œê¸ˆì•¡']:
            if field in query and query[field]:
                numerical_values.append(float(query[field]))
            else:
                numerical_values.append(0.0)
        
        if self.scaler:
            processed['numerical_features'] = self.scaler.transform([numerical_values])[0]
        
        return processed
    
    def calculate_similarity(self, processed_query):
        """ìœ ì‚¬ë„ ê³„ì‚° (ê²€ìƒ‰ ì…ë ¥ ì •ë³´ë§Œ ì‚¬ìš©)"""
        similarities = []
        
        for idx, case in self.case_summary.iterrows():
            # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ (KoSimCSE ì‚¬ìš©)
            text_similarity = 0
            if not self.fast_mode and 'text_embedding' in processed_query and self.text_embeddings is not None:
                query_embedding = processed_query['text_embedding']
                case_embedding = self.text_embeddings[idx]
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = cosine_similarity([query_embedding], [case_embedding])[0][0]
                text_similarity = max(0, similarity)  # ìŒìˆ˜ ê°’ ë°©ì§€
            elif 'combined_text' in processed_query and processed_query['combined_text']:
                # KoSimCSEê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
                query_text = processed_query['combined_text']
                case_text = case.get('combined_text', '')
                
                # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„
                query_words = set(query_text.lower().split())
                case_words = set(case_text.lower().split())
                
                if query_words and case_words:
                    intersection = query_words.intersection(case_words)
                    union = query_words.union(case_words)
                    text_similarity = len(intersection) / len(union) if union else 0
            
            # ë²”ì£¼í˜• ë³€ìˆ˜ ìœ ì‚¬ë„ (ê²€ìƒ‰ ì…ë ¥ ì •ë³´ë§Œ)
            categorical_similarity = 0
            categorical_matches = 0
            total_categorical = 0
            
            # ê²€ìƒ‰ ì…ë ¥ ì •ë³´ë§Œ ì‚¬ìš©
            search_fields = ['ì‚¬ê³ ìœ í˜•ëª…', 'ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©']
            for field in search_fields:
                if f'{field}_encoded' in processed_query:
                    total_categorical += 1
                    if processed_query[f'{field}_encoded'] == case.get(f'{field}_encoded', -1):
                        categorical_matches += 1
            
            if total_categorical > 0:
                categorical_similarity = categorical_matches / total_categorical
            
            # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìœ ì‚¬ë„ (ê²€ìƒ‰ ì…ë ¥ ì •ë³´ë§Œ)
            numerical_similarity = 0
            if 'numerical_features' in processed_query:
                query_numerical = processed_query['numerical_features']
                case_numerical = []
                # ê²€ìƒ‰ ì…ë ¥ ì •ë³´ë§Œ ì‚¬ìš© - ìŠ¤ì¼€ì¼ë§ëœ ê°’ ì‚¬ìš©
                for col in ['ì‚¬ê³ ê¸ˆì•¡', 'ê²°ì œê¸ˆì•¡']:
                    if f'{col}_scaled' in case:
                        case_numerical.append(case[f'{col}_scaled'])
                    else:
                        case_numerical.append(0)  # ìŠ¤ì¼€ì¼ë§ëœ ê°’ì´ ì—†ìœ¼ë©´ 0
                
                if len(case_numerical) == len(query_numerical):
                    # ìœ í´ë¦¬ë“œ ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                    distance = np.sqrt(np.sum((query_numerical - case_numerical) ** 2))
                    numerical_similarity = 1 / (1 + distance)
                else:
                    numerical_similarity = 0
            
            # ê°€ì¤‘ í‰ê·  (ì‚¬ê³ ì„¤ëª… ì¤‘ì‹¬ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì¡°ì •)
            if not self.fast_mode and self.text_embeddings is not None:
                final_similarity = (
                    0.7 * text_similarity +  # ì‚¬ê³ ì„¤ëª… ì¤‘ì‹¬ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ (ê°€ì¤‘ì¹˜ ì¦ê°€)
                    0.25 * categorical_similarity +  # ë²”ì£¼í˜• ìœ ì‚¬ë„
                    0.05 * numerical_similarity  # ìˆ˜ì¹˜í˜• ìœ ì‚¬ë„ (ê°€ì¤‘ì¹˜ ê°ì†Œ)
                )
            else:
                final_similarity = (
                    0.5 * text_similarity +  # ê¸°ë³¸ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
                    0.4 * categorical_similarity +  # ë²”ì£¼í˜• ìœ ì‚¬ë„
                    0.1 * numerical_similarity  # ìˆ˜ì¹˜í˜• ìœ ì‚¬ë„
                )
            
            similarities.append(final_similarity)
        
        return np.array(similarities)
    
    def create_decision_process(self, case):
        """íŒì • ê³¼ì • ìƒì„¸ ì •ë³´ ìƒì„±"""
        process = []
        
        # íŒì • ê´€ë ¨ ì»¬ëŸ¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸
        íŒì •_ì»¬ëŸ¼ë“¤ = ['íŒì •ì¼', 'íŒì •êµ¬ë¶„', 'íŒì •ì‚¬ìœ ', 'íŒì •ê¸ˆì•¡', 'íŒì •ì§„í–‰ìƒíƒœ', 'íŒì •íšŒì°¨']
        
        if all(col in case for col in íŒì •_ì»¬ëŸ¼ë“¤):
            íŒì •ì¼_list = case['íŒì •ì¼'] if isinstance(case['íŒì •ì¼'], list) else [case['íŒì •ì¼']]
            íŒì •êµ¬ë¶„_list = case['íŒì •êµ¬ë¶„'] if isinstance(case['íŒì •êµ¬ë¶„'], list) else [case['íŒì •êµ¬ë¶„']]
            íŒì •ì‚¬ìœ _list = case['íŒì •ì‚¬ìœ '] if isinstance(case['íŒì •ì‚¬ìœ '], list) else [case['íŒì •ì‚¬ìœ ']]
            íŒì •ê¸ˆì•¡_list = case['íŒì •ê¸ˆì•¡'] if isinstance(case['íŒì •ê¸ˆì•¡'], list) else [case['íŒì •ê¸ˆì•¡']]
            íŒì •ì§„í–‰ìƒíƒœ_list = case['íŒì •ì§„í–‰ìƒíƒœ'] if isinstance(case['íŒì •ì§„í–‰ìƒíƒœ'], list) else [case['íŒì •ì§„í–‰ìƒíƒœ']]
            íŒì •íšŒì°¨_list = case['íŒì •íšŒì°¨'] if isinstance(case['íŒì •íšŒì°¨'], list) else [case['íŒì •íšŒì°¨']]
            
            for i in range(len(íŒì •êµ¬ë¶„_list)):
                process.append({
                    'íšŒì°¨': íŒì •íšŒì°¨_list[i] if i < len(íŒì •íšŒì°¨_list) else i+1,
                    'ë‚ ì§œ': íŒì •ì¼_list[i] if i < len(íŒì •ì¼_list) else 'N/A',
                    'íŒì •êµ¬ë¶„': íŒì •êµ¬ë¶„_list[i] if i < len(íŒì •êµ¬ë¶„_list) else 'N/A',
                    'íŒì •ê¸ˆì•¡': íŒì •ê¸ˆì•¡_list[i] if i < len(íŒì •ê¸ˆì•¡_list) else 0,
                    'íŒì •ì‚¬ìœ ': íŒì •ì‚¬ìœ _list[i] if i < len(íŒì •ì‚¬ìœ _list) else 'N/A',
                    'ì§„í–‰ìƒíƒœ': íŒì •ì§„í–‰ìƒíƒœ_list[i] if i < len(íŒì •ì§„í–‰ìƒíƒœ_list) else 'N/A'
                })
        else:
            # íŒì • ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
            process.append({
                'íšŒì°¨': 1,
                'ë‚ ì§œ': 'N/A',
                'íŒì •êµ¬ë¶„': 'ì •ë³´ì—†ìŒ',
                'íŒì •ê¸ˆì•¡': 0,
                'íŒì •ì‚¬ìœ ': 'ì •ë³´ì—†ìŒ',
                'ì§„í–‰ìƒíƒœ': 'ì •ë³´ì—†ìŒ'
            })
        
        return process
    
    def print_case_result(self, result):
        """ì‚¬ë¡€ ê²°ê³¼ ì¶œë ¥"""
        print(f"\n{'='*60}")
        print(f"ğŸ† ìˆœìœ„: {result['rank']} (ìœ ì‚¬ë„: {result['similarity']:.3f})")
        print(f"ğŸ“‹ ì‚¬ê±´ ID: {result['case_id']}")
        
        # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
        predicted = result.get('predicted_results', {})
        print(f"ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼:")
        print(f"   - íŒì •êµ¬ë¶„: {predicted.get('íŒì •êµ¬ë¶„', 'N/A')}")
        print(f"   - íŒì •ì‚¬ìœ : {predicted.get('íŒì •ì‚¬ìœ ', 'N/A')}")
        
        print(f"ğŸ”„ íŒì • íšŸìˆ˜: {result['íŒì •íšŸìˆ˜']}íšŒ")
        
        print(f"\nğŸ“‹ ì‚¬ê±´ ì •ë³´:")
        case_info = result['case_info']
        print(f"   - ì‚¬ê³ ì ‘ìˆ˜ì¼ì: {case_info['ì‚¬ê³ ì ‘ìˆ˜ì¼ì']}")
        print(f"   - ì‚¬ê³ ìœ í˜•: {case_info['ì‚¬ê³ ìœ í˜•ëª…']}")
        print(f"   - ìˆ˜ì…êµ­: {case_info['ìˆ˜ì…êµ­']}")
        print(f"   - ìˆ˜ì¶œì: {case_info['ìˆ˜ì¶œì']}")
        print(f"   - ë³´í—˜ì¢…ëª©: {case_info['ë³´í—˜ì¢…ëª©']}")
        print(f"   - ì‚¬ê³ ê¸ˆì•¡: {case_info['ì‚¬ê³ ê¸ˆì•¡']:,.0f}")
        print(f"   - ê²°ì œê¸ˆì•¡: {case_info['ê²°ì œê¸ˆì•¡']:,.0f}")
        
        print(f"\nğŸ“‹ íŒì • ê³¼ì •:")
        for i, decision in enumerate(result['decision_process']):
            print(f"   {i+1}ì°¨ íŒì •:")
            print(f"     - ë‚ ì§œ: {decision['ë‚ ì§œ']}")
            print(f"     - íŒì •: {decision['íŒì •êµ¬ë¶„']}")
            print(f"     - ê¸ˆì•¡: {decision['íŒì •ê¸ˆì•¡']:,.0f}")
            print(f"     - ì‚¬ìœ : {decision['íŒì •ì‚¬ìœ ']}")
            print(f"     - ìƒíƒœ: {decision['ì§„í–‰ìƒíƒœ']}")
        
        print(f"{'='*60}")

    def get_prediction_from_similar_cases(self, case, field):
        """ìœ ì‚¬í•œ ì‚¬ë¡€ë“¤ì˜ íŒì • ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡"""
        if field in case and isinstance(case[field], list):
            # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (ì—¬ëŸ¬ íŒì •ì´ ìˆëŠ” ê²½ìš°)
            if len(case[field]) > 0:
                # ê°€ì¥ ìµœê·¼ íŒì • ë˜ëŠ” ê°€ì¥ ë¹ˆë„ê°€ ë†’ì€ íŒì • ë°˜í™˜
                return case[field][-1] if len(case[field]) > 0 else 'N/A'
            else:
                return 'N/A'
        elif field in case:
            # ë‹¨ì¼ ê°’ì¸ ê²½ìš°
            return case[field]
        else:
            return 'N/A'

    def save_embeddings_cache(self):
        """KoSimCSE ì„ë² ë”©ì„ ìºì‹œ íŒŒì¼ì— ì €ì¥"""
        if self.text_embeddings is not None:
            try:
                cache_data = {
                    'embeddings': self.text_embeddings,
                    'data_hash': hash(str(self.case_summary['combined_text'].tolist()))
                }
                with open(self.embedding_cache_path, 'wb') as f:
                    pickle.dump(cache_data, f)
                print(f"ğŸ’¾ ì„ë² ë”© ìºì‹œ ì €ì¥ ì™„ë£Œ: {self.embedding_cache_path}")
            except Exception as e:
                print(f"âš ï¸ ì„ë² ë”© ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def load_embeddings_cache(self):
        """KoSimCSE ì„ë² ë”© ìºì‹œ íŒŒì¼ì—ì„œ ë¡œë“œ"""
        try:
            if os.path.exists(self.embedding_cache_path):
                with open(self.embedding_cache_path, 'rb') as f:
                    cache_data = pickle.load(f)
                
                # ìºì‹œ ë°ì´í„° êµ¬ì¡° í™•ì¸
                if 'embeddings' in cache_data and 'data_hash' in cache_data:
                    # ë°ì´í„° í•´ì‹œ í™•ì¸ (ë°ì´í„°ê°€ ë³€ê²½ë˜ì—ˆëŠ”ì§€ ì²´í¬)
                    if 'combined_text' in self.case_summary.columns:
                        current_hash = hash(str(self.case_summary['combined_text'].tolist()))
                        if cache_data['data_hash'] == current_hash:
                            self.text_embeddings = cache_data['embeddings']
                            print(f"ğŸ“‚ ì„ë² ë”© ìºì‹œ ë¡œë“œ ì™„ë£Œ: {self.text_embeddings.shape}")
                            return True
                        else:
                            print("âš ï¸ ë°ì´í„°ê°€ ë³€ê²½ë˜ì–´ ìºì‹œë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤.")
                            return False
                    else:
                        print("âš ï¸ combined_text ì»¬ëŸ¼ì´ ì—†ì–´ ìºì‹œë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤.")
                        return False
                else:
                    print("âš ï¸ ìºì‹œ íŒŒì¼ êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    return False
        except Exception as e:
            print(f"âš ï¸ ì„ë² ë”© ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
    search_engine = CaseSimilaritySearch()
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ í™•ì¸
    options = search_engine.get_available_options()
    print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜:")
    for field, values in options.items():
        print(f"   {field}: {len(values)}ê°œ ì˜µì…˜")
    
    # ê²€ìƒ‰ ì˜ˆì‹œ
    query = {
        'ì‚¬ê³ ìœ í˜•ëª…': 'ì§€ê¸‰ê±°ì ˆ',
        'ìˆ˜ì…êµ­': 'ë¯¸êµ­',
        'ë³´í—˜ì¢…ëª©': 'ë‹¨ê¸°ìˆ˜ì¶œë³´í—˜',
        'ì‚¬ê³ ì„¤ëª…': 'ìˆ˜ì…ìê°€ ì§€ê¸‰ì„ ê±°ì ˆí•¨'
    }
    
    results = search_engine.search_similar_cases(query, top_k=3) 