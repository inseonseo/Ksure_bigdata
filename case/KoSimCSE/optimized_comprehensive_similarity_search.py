import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import LabelEncoder, StandardScaler
import re
from datetime import datetime
import torch
from transformers import AutoTokenizer, AutoModel
import pickle
import os
import time
from typing import Dict, List, Tuple, Optional
import hashlib

class OptimizedComprehensiveSimilaritySearch:
    def __init__(self, data_path='data/testy.csv'):
        """
        ìµœì í™”ëœ ì¢…í•© ì‚¬ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        
        Args:
            data_path: í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        """
        self.data_path = data_path
        self.data = None
        self.case_summary = None
        self.label_encoders = {}
        self.scaler = None
        self.kosimcse_model = None
        self.kosimcse_tokenizer = None
        self.text_embeddings = None
        
        # ì„ë² ë”© ìºì‹œ íŒŒì¼ ê²½ë¡œ
        current_dir = os.path.dirname(os.path.abspath(__file__))
        self.embedding_cache_path = os.path.join(current_dir, 'optimized_comprehensive_embeddings_cache.pkl')
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_stats = {
            'data_load_time': 0,
            'preprocessing_time': 0,
            'embedding_time': 0,
            'cache_load_time': 0
        }
        
        # ì…ë ¥ í•„ë“œ ì •ì˜
        self.input_fields = {
            'ì‹ ì²­ëŒ€ìƒêµ¬ë¶„': 'dropdown',
            'ì‹ ì²­ì': 'text', 
            'ë³´í—˜ì¢…ëª©': 'dropdown',
            'ì‚¬ê³ ìœ í˜•ëª…': 'dropdown',
            'ìˆ˜ì¶œì': 'text',
            'ìˆ˜ì…êµ­': 'dropdown'
        }
        
        self.optional_fields = {
            'ì‚¬ê³ ê²½ìœ„': 'textarea',
            'ì‚¬ê³ ì„¤ëª…': 'textarea'
        }
        
        # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        self.load_and_preprocess_data()

    def get_data_hash(self) -> str:
        """ë°ì´í„° í•´ì‹œ ìƒì„± (ë³€ê²½ ê°ì§€ìš©)"""
        if self.case_summary is None or 'combined_text' not in self.case_summary.columns:
            return ""
        
        text_data = str(self.case_summary['combined_text'].tolist())
        return hashlib.md5(text_data.encode()).hexdigest()

    def load_kosimcse_model(self):
        """KoSimCSE ëª¨ë¸ ë¡œë“œ (ìµœì í™”)"""
        start_time = time.time()
        print("ğŸ¤– KoSimCSE ëª¨ë¸ ë¡œë“œ ì¤‘...")
        
        try:
            # ëª¨ë¸ ê²½ë¡œ
            model_path = 'BM-K/KoSimCSE-roberta'
            
            # GPU ì‚¬ìš© ê°€ëŠ¥ì‹œ GPU ì‚¬ìš©
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            print(f"ğŸ“± ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
            
            self.kosimcse_tokenizer = AutoTokenizer.from_pretrained(model_path)
            self.kosimcse_model = AutoModel.from_pretrained(model_path).to(device)
            
            # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
            self.kosimcse_model.eval()
            
            load_time = time.time() - start_time
            print(f"âœ… KoSimCSE ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({load_time:.2f}ì´ˆ)")
                
        except Exception as e:
            print(f"âš ï¸ KoSimCSE ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            print("âš ï¸ KoSimCSE ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.kosimcse_model = None
            self.kosimcse_tokenizer = None

    def load_embeddings_cache(self) -> bool:
        """ì„ë² ë”© ìºì‹œ ë¡œë“œ (ê°œì„ ëœ ë²„ì „)"""
        start_time = time.time()
        
        try:
            if not os.path.exists(self.embedding_cache_path):
                print("ğŸ“‚ ìºì‹œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                return False
            
            print("ğŸ“‚ ì„ë² ë”© ìºì‹œ ë¡œë“œ ì¤‘...")
            with open(self.embedding_cache_path, 'rb') as f:
                cache_data = pickle.load(f)
            
            # ìºì‹œ êµ¬ì¡° ê²€ì¦
            required_keys = ['embeddings', 'data_hash', 'model_name', 'created_at']
            if not all(key in cache_data for key in required_keys):
                print("âš ï¸ ìºì‹œ íŒŒì¼ êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return False
            
            # ë°ì´í„° ë³€ê²½ í™•ì¸
            current_hash = self.get_data_hash()
            if cache_data['data_hash'] != current_hash:
                print("âš ï¸ ë°ì´í„°ê°€ ë³€ê²½ë˜ì–´ ìºì‹œë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤.")
                return False
            
            # ìºì‹œ ë¡œë“œ
            self.text_embeddings = cache_data['embeddings']
            
            cache_time = time.time() - start_time
            self.performance_stats['cache_load_time'] = cache_time
            
            print(f"âœ… ì„ë² ë”© ìºì‹œ ë¡œë“œ ì™„ë£Œ: {self.text_embeddings.shape} ({cache_time:.2f}ì´ˆ)")
            print(f"ğŸ“… ìºì‹œ ìƒì„±ì¼: {cache_data['created_at']}")
            
            return True
            
        except Exception as e:
            print(f"âš ï¸ ì„ë² ë”© ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False

    def save_embeddings_cache(self):
        """ì„ë² ë”© ìºì‹œ ì €ì¥ (ê°œì„ ëœ ë²„ì „)"""
        if self.text_embeddings is None:
            return
        
        try:
            cache_data = {
                'embeddings': self.text_embeddings,
                'data_hash': self.get_data_hash(),
                'model_name': 'BM-K/KoSimCSE-roberta',
                'created_at': datetime.now().isoformat(),
                'data_size': len(self.case_summary),
                'embedding_shape': self.text_embeddings.shape
            }
            
            with open(self.embedding_cache_path, 'wb') as f:
                pickle.dump(cache_data, f)
            
            print(f"ğŸ’¾ ì„ë² ë”© ìºì‹œ ì €ì¥ ì™„ë£Œ: {self.embedding_cache_path}")
            
        except Exception as e:
            print(f"âš ï¸ ì„ë² ë”© ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

    def encode_text_with_kosimcse(self, texts: List[str]) -> Optional[np.ndarray]:
        """KoSimCSEë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (ìƒì„¸ ì§„í–‰ë¥  í‘œì‹œ)"""
        if self.kosimcse_model is None or self.kosimcse_tokenizer is None:
            return None
        
        start_time = time.time()
        total_texts = len(texts)
        
        # GPU/CPU ê°ì§€ ë° ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
        device = next(self.kosimcse_model.parameters()).device
        is_gpu = device.type == 'cuda'
        estimated_time = (total_texts / 1000) * (2 if is_gpu else 6)  # GPU: 2ì´ˆ/1k, CPU: 6ì´ˆ/1k
        
        print(f"ğŸ¤– KoSimCSE ì„ë² ë”© ìƒì„± ì‹œì‘")
        print(f"   ğŸ“Š ì´ í…ìŠ¤íŠ¸: {total_texts:,}ê°œ")
        print(f"   ğŸ’» ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
        print(f"   â±ï¸  ì˜ˆìƒ ì†Œìš”ì‹œê°„: {estimated_time/60:.1f}ë¶„")
        print(f"   {'='*50}")
        
        try:
            batch_size = 32 if is_gpu else 16  # GPUì¼ ë•Œ ë” í° ë°°ì¹˜ ì‚¬ìš©
            embeddings = []
            last_reported_progress = -1
            
            for i in range(0, total_texts, batch_size):
                batch_texts = texts[i:i+batch_size]
                
                # 10%ë§ˆë‹¤ ì§„í–‰ë¥  í‘œì‹œ
                progress = (i / total_texts) * 100
                if progress >= last_reported_progress + 10:
                    elapsed_time = time.time() - start_time
                    remaining_time = (elapsed_time / (i + 1)) * (total_texts - i - 1) if i > 0 else estimated_time
                    
                    print(f"   ğŸ”„ ì§„í–‰ë¥ : {progress:.0f}% ({i:,}/{total_texts:,})")
                    print(f"      â±ï¸  ê²½ê³¼: {elapsed_time:.0f}ì´ˆ | ë‚¨ì€ì‹œê°„: {remaining_time:.0f}ì´ˆ")
                    last_reported_progress = progress
                
                # í† í¬ë‚˜ì´ì§•
                inputs = self.kosimcse_tokenizer(
                    batch_texts,
                    padding=True,
                    truncation=True,
                    max_length=512,
                    return_tensors="pt"
                ).to(device)
                
                # ì„ë² ë”© ìƒì„±
                with torch.no_grad():
                    outputs = self.kosimcse_model(**inputs)
                    batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()
                    embeddings.extend(batch_embeddings)
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del inputs, outputs
                if is_gpu:
                    torch.cuda.empty_cache()
            
            embedding_time = time.time() - start_time
            self.performance_stats['embedding_time'] = embedding_time
            
            print(f"   ğŸ‰ 100% ì™„ë£Œ!")
            print(f"   {'='*50}")
            print(f"âœ… KoSimCSE ì„ë² ë”© ìƒì„± ì™„ë£Œ")
            print(f"   ğŸ“Š ìƒì„±ëœ ì„ë² ë”©: {len(embeddings):,}ê°œ")
            print(f"   â±ï¸  ì‹¤ì œ ì†Œìš”ì‹œê°„: {embedding_time/60:.1f}ë¶„")
            print(f"   ğŸ’¾ ì„ë² ë”© í¬ê¸°: {np.array(embeddings).nbytes / 1024 / 1024:.1f}MB")
            
            return np.array(embeddings)
            
        except Exception as e:
            print(f"âŒ KoSimCSE ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return None

    def load_and_preprocess_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (ìµœì í™”)"""
        start_time = time.time()
        print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        try:
            # ë°ì´í„° ë¡œë“œ
            self.data = pd.read_csv(self.data_path, encoding='cp949')
            
            data_load_time = time.time() - start_time
            self.performance_stats['data_load_time'] = data_load_time
            
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.data)}ê°œ ë ˆì½”ë“œ ({data_load_time:.2f}ì´ˆ)")
            
            # ì‚¬ë¡€ ìš”ì•½ ìƒì„±
            preprocess_start = time.time()
            self.create_case_summary()
            
            # ìºì‹œ ë¨¼ì € ì‹œë„
            cache_loaded = False
            if self.case_summary is not None and 'combined_text' in self.case_summary.columns:
                cache_loaded = self.load_embeddings_cache()
            
            # ìºì‹œê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš°ì—ë§Œ ëª¨ë¸ ë¡œë“œ
            if not cache_loaded:
                self.load_kosimcse_model()
            
            # íŠ¹ì„± ì „ì²˜ë¦¬
            self.preprocess_features(skip_embeddings=cache_loaded)
            
            preprocess_time = time.time() - preprocess_start
            self.performance_stats['preprocessing_time'] = preprocess_time
            
            print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ ({preprocess_time:.2f}ì´ˆ)")
            
            # ì„±ëŠ¥ í†µê³„ ì¶œë ¥
            self.print_performance_stats()
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise

    def create_case_summary(self):
        """ì‚¬ê±´ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì‚¬ë¡€ ìš”ì•½ ìƒì„±"""
        print("ğŸ“‹ ì‚¬ë¡€ ìš”ì•½ ìƒì„± ì¤‘...")
        
        required_columns = ['ë³´ìƒíŒŒì¼ë²ˆí˜¸', 'ì‚¬ê³ ë²ˆí˜¸']
        available_columns = [col for col in required_columns if col in self.data.columns]
        
        if len(available_columns) < 2:
            print("âš ï¸ ë³´ìƒíŒŒì¼ë²ˆí˜¸ ë˜ëŠ” ì‚¬ê³ ë²ˆí˜¸ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.case_summary = self.data.copy()
            return
        
        # ì‚¬ê±´ë³„ ê·¸ë£¹í™”
        case_groups = self.data.groupby(['ë³´ìƒíŒŒì¼ë²ˆí˜¸', 'ì‚¬ê³ ë²ˆí˜¸'])
        
        case_summaries = []
        total_groups = len(case_groups)
        
        for idx, ((ë³´ìƒíŒŒì¼ë²ˆí˜¸, ì‚¬ê³ ë²ˆí˜¸), group) in enumerate(case_groups):
            if idx % 1000 == 0:  # ì§„í–‰ë¥  í‘œì‹œ
                progress = (idx / total_groups) * 100
                print(f"   ì§„í–‰ë¥ : {progress:.1f}% ({idx}/{total_groups})")
            
            case_summary = {
                'ë³´ìƒíŒŒì¼ë²ˆí˜¸': ë³´ìƒíŒŒì¼ë²ˆí˜¸,
                'ì‚¬ê³ ë²ˆí˜¸': ì‚¬ê³ ë²ˆí˜¸
            }
            
            # ë‹¨ì¼ ê°’ ì»¬ëŸ¼ë“¤
            single_value_columns = [
                'ì‚¬ê³ ì ‘ìˆ˜ì¼ì', 'ì‚¬ê³ ìœ í˜•ëª…', 'ìˆ˜ì…êµ­', 'ìˆ˜ì¶œì', 'ë³´í—˜ì¢…ëª©',
                'ì‚¬ê³ ê¸ˆì•¡', 'ê²°ì œê¸ˆì•¡', 'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡', 'ì‚¬ê³ ì„¤ëª…', 'ìˆ˜ì…ìëª…'
            ]
            
            for col in single_value_columns:
                if col in group.columns:
                    case_summary[col] = group[col].iloc[0] if not group[col].isna().all() else None
            
            # ë¦¬ìŠ¤íŠ¸ ì»¬ëŸ¼ë“¤
            list_columns = [
                'íŒì •ì¼', 'íŒì •ê²°ì¬ì¼', 'íŒì •ì§„í–‰ìƒíƒœ', 'ì‚¬ê³ ì§„í–‰ìƒíƒœ',
                'íŒì •êµ¬ë¶„', 'íŒì •ê¸ˆì•¡', 'íŒì •ì‚¬ìœ ', 'íŒì •íšŒì°¨',
                'ê²°ì œë°©ë²•', 'ê²°ì œë°©ë²•ì„¤ëª…', 'ê²°ì œì¡°ê±´', 'í–¥í›„ê²°ì œì „ë§',
                'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡í†µí™”', 'ê²°ì œê¸ˆì•¡í†µí™”', 'ì‚¬ê³ ê¸ˆì•¡í†µí™”', 'íŒì •ê¸ˆì•¡í†µí™”'
            ]
            
            for col in list_columns:
                if col in group.columns:
                    values = group[col].dropna().unique().tolist()
                    case_summary[col] = values if values else []
            
            case_summaries.append(case_summary)

        self.case_summary = pd.DataFrame(case_summaries)
        print(f"âœ… ì‚¬ë¡€ ìš”ì•½ ìƒì„± ì™„ë£Œ: {len(self.case_summary)}ê°œ ì‚¬ë¡€")

    def preprocess_features(self, skip_embeddings=False):
        """íŠ¹ì„± ì „ì²˜ë¦¬ (ìµœì í™”)"""
        print("ğŸ”§ íŠ¹ì„± ì „ì²˜ë¦¬ ì¤‘...")
        
        # í…ìŠ¤íŠ¸ í•„ë“œ ê²°í•©
        text_columns = ['ì‚¬ê³ ì„¤ëª…']
        available_text_columns = [col for col in text_columns if col in self.case_summary.columns]
        
        if available_text_columns:
            self.case_summary['combined_text'] = self.case_summary[available_text_columns].fillna('').agg(' '.join, axis=1)
        else:
            self.case_summary['combined_text'] = ''
        
        # KoSimCSE ì„ë² ë”© ìƒì„± (ìºì‹œë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ)
        if not skip_embeddings and self.kosimcse_model is not None:
            texts = self.case_summary['combined_text'].fillna('').tolist()
            self.text_embeddings = self.encode_text_with_kosimcse(texts)
            
            if self.text_embeddings is not None:
                # ìƒˆë¡œ ìƒì„±ëœ ì„ë² ë”© ìºì‹œ ì €ì¥
                self.save_embeddings_cache()
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        categorical_columns = [
            'íŒì •ì§„í–‰ìƒíƒœ', 'ì‚¬ê³ ì§„í–‰ìƒíƒœ', 'ìˆ˜ì¶œì', 'ìˆ˜ì…ì', 
            'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡í†µí™”', 'ê²°ì œê¸ˆì•¡í†µí™”', 'ì‚¬ê³ ê¸ˆì•¡í†µí™”', 
            'ì‚¬ê³ ìœ í˜•ëª…', 'ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©', 'ê²°ì œë°©ë²•', 
            'ê²°ì œë°©ë²•ì„¤ëª…', 'ê²°ì œì¡°ê±´', 'í–¥í›„ê²°ì œì „ë§', 'ìˆ˜ì…ìëª…',
            'íŒì •êµ¬ë¶„', 'íŒì •ì‚¬ìœ '
        ]
        
        for col in categorical_columns:
            if col in self.case_summary.columns:
                if self.case_summary[col].apply(lambda x: isinstance(x, list)).any():
                    values = self.case_summary[col].apply(
                        lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None
                    )
                else:
                    values = self.case_summary[col]
                
                le = LabelEncoder()
                self.case_summary[f'{col}_encoded'] = le.fit_transform(values.astype(str))
                self.label_encoders[col] = le
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§
        numerical_columns = []
        for col in ['ì‚¬ê³ ê¸ˆì•¡', 'ê²°ì œê¸ˆì•¡', 'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡', 'íŒì •ê¸ˆì•¡']:
            if col in self.case_summary.columns:
                if self.case_summary[col].apply(lambda x: isinstance(x, list)).any():
                    values = self.case_summary[col].apply(
                        lambda x: x[0] if isinstance(x, list) and len(x) > 0 else 0
                    )
                else:
                    values = self.case_summary[col]
                
                self.case_summary[col] = values
                numerical_columns.append(col)
        
        if numerical_columns:
            self.scaler = StandardScaler()
            self.case_summary[numerical_columns] = self.scaler.fit_transform(
                self.case_summary[numerical_columns].fillna(0)
            )
        
        print("âœ… íŠ¹ì„± ì „ì²˜ë¦¬ ì™„ë£Œ")

    def print_performance_stats(self):
        """ì„±ëŠ¥ í†µê³„ ì¶œë ¥"""
        print("\nğŸ“Š ì„±ëŠ¥ í†µê³„:")
        print(f"   ë°ì´í„° ë¡œë“œ: {self.performance_stats['data_load_time']:.2f}ì´ˆ")
        print(f"   ì „ì²˜ë¦¬: {self.performance_stats['preprocessing_time']:.2f}ì´ˆ")
        print(f"   ì„ë² ë”© ìƒì„±: {self.performance_stats['embedding_time']:.2f}ì´ˆ")
        print(f"   ìºì‹œ ë¡œë“œ: {self.performance_stats['cache_load_time']:.2f}ì´ˆ")
        
        total_time = sum(self.performance_stats.values())
        print(f"   ì´ ì‹œê°„: {total_time:.2f}ì´ˆ")

    def search_similar_cases(self, query: Dict, top_k: int = 5, verbose: bool = True) -> List[Dict]:
        """ìœ ì‚¬í•œ ì‚¬ê³  ì‚¬ë¡€ ê²€ìƒ‰ (ê°œì„ ëœ ë²„ì „)"""
        search_start = time.time()
        
        if verbose:
            print(f"\nğŸ” ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ ì¤‘... (ìƒìœ„ {top_k}ê°œ)")
            print(f"ğŸ“ ê²€ìƒ‰ ì…ë ¥: {list(query.keys())}")
        
        # ì¿¼ë¦¬ ì „ì²˜ë¦¬
        processed_query = self.preprocess_query(query)
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        similarities, similarity_details = self.calculate_similarity_with_details(processed_query)
        
        # ìƒìœ„ kê°œ ì„ íƒ
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        results = []
        for i, idx in enumerate(top_indices):
            case = self.case_summary.iloc[idx]
            similarity = similarities[idx]
            details = similarity_details[idx]
            
            # ìƒì„¸ íŒì • ê³¼ì • êµ¬ì„±
            decision_process = self.create_decision_process(case)
            
            result = {
                'rank': i + 1,
                'similarity': float(similarity),
                'case_id': f"{case['ë³´ìƒíŒŒì¼ë²ˆí˜¸']}_{case['ì‚¬ê³ ë²ˆí˜¸']}",
                'case_info': {
                    'ì‚¬ê³ ì ‘ìˆ˜ì¼ì': case.get('ì‚¬ê³ ì ‘ìˆ˜ì¼ì', 'N/A'),
                    'ì‚¬ê³ ìœ í˜•ëª…': case.get('ì‚¬ê³ ìœ í˜•ëª…', 'N/A'),
                    'ìˆ˜ì…êµ­': case.get('ìˆ˜ì…êµ­', 'N/A'),
                    'ìˆ˜ì¶œì': case.get('ìˆ˜ì¶œì', 'N/A'),
                    'ë³´í—˜ì¢…ëª©': case.get('ë³´í—˜ì¢…ëª©', 'N/A'),
                    'ì‚¬ê³ ê¸ˆì•¡': case.get('ì‚¬ê³ ê¸ˆì•¡', 0),
                    'ê²°ì œê¸ˆì•¡': case.get('ê²°ì œê¸ˆì•¡', 0),
                    'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡': case.get('ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡', 0),
                    'íŒì •ê¸ˆì•¡': case.get('íŒì •ê¸ˆì•¡', 0),
                    'ì‚¬ê³ ì„¤ëª…': case.get('ì‚¬ê³ ì„¤ëª…', 'N/A')
                },
                'decision_process': decision_process,
                'similarity_details': details  # ìœ ì‚¬ë„ ê·¼ê±° ì¶”ê°€
            }
            
            results.append(result)
        
        search_time = time.time() - search_start
        
        if verbose:
            print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼ ({search_time:.2f}ì´ˆ)")
        
        return results

    def calculate_similarity_with_details(self, processed_query: Dict) -> Tuple[np.ndarray, List[Dict]]:
        """ìœ ì‚¬ë„ ê³„ì‚° (ìƒì„¸ ì •ë³´ í¬í•¨)"""
        similarities = []
        similarity_details = []
        
        for idx, case in self.case_summary.iterrows():
            details = {
                'text_similarity': 0,
                'categorical_similarity': 0,
                'numerical_similarity': 0,
                'categorical_matches': {},
                'numerical_differences': {}
            }
            
            # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
            text_similarity = 0
            if 'text_embedding' in processed_query and self.text_embeddings is not None:
                query_embedding = processed_query['text_embedding']
                case_embedding = self.text_embeddings[idx]
                
                similarity = cosine_similarity([query_embedding], [case_embedding])[0][0]
                text_similarity = max(0, similarity)
                details['text_similarity'] = text_similarity
            
            # ë²”ì£¼í˜• ë³€ìˆ˜ ìœ ì‚¬ë„
            categorical_similarity = 0
            categorical_matches = 0
            total_categorical = 0
            
            categorical_columns = [
                'íŒì •ì§„í–‰ìƒíƒœ', 'ì‚¬ê³ ì§„í–‰ìƒíƒœ', 'ìˆ˜ì¶œì', 'ìˆ˜ì…ì', 
                'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡í†µí™”', 'ê²°ì œê¸ˆì•¡í†µí™”', 'ì‚¬ê³ ê¸ˆì•¡í†µí™”', 
                'ì‚¬ê³ ìœ í˜•ëª…', 'ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©', 'ê²°ì œë°©ë²•', 
                'ê²°ì œë°©ë²•ì„¤ëª…', 'ê²°ì œì¡°ê±´', 'í–¥í›„ê²°ì œì „ë§', 'ìˆ˜ì…ìëª…',
                'íŒì •êµ¬ë¶„', 'íŒì •ì‚¬ìœ '
            ]
            
            for field in categorical_columns:
                if f'{field}_encoded' in processed_query:
                    total_categorical += 1
                    query_value = processed_query[f'{field}_encoded']
                    case_value = case.get(f'{field}_encoded', -1)
                    
                    if query_value == case_value:
                        categorical_matches += 1
                        details['categorical_matches'][field] = True
                    else:
                        details['categorical_matches'][field] = False
            
            if total_categorical > 0:
                categorical_similarity = categorical_matches / total_categorical
                details['categorical_similarity'] = categorical_similarity
            
            # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìœ ì‚¬ë„
            numerical_similarity = 0
            if 'numerical_features' in processed_query:
                query_numerical = processed_query['numerical_features']
                case_numerical = []
                
                numerical_columns = ['ì‚¬ê³ ê¸ˆì•¡', 'ê²°ì œê¸ˆì•¡', 'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡', 'íŒì •ê¸ˆì•¡']
                for i, col in enumerate(numerical_columns):
                    case_value = case.get(col, 0)
                    case_numerical.append(case_value)
                    
                    # ê°œë³„ ì°¨ì´ ì €ì¥
                    if i < len(query_numerical):
                        details['numerical_differences'][col] = abs(query_numerical[i] - case_value)
                
                distance = np.sqrt(np.sum((query_numerical - case_numerical) ** 2))
                numerical_similarity = 1 / (1 + distance)
                details['numerical_similarity'] = numerical_similarity
            
            # ê°€ì¤‘ í‰ê· 
            if self.text_embeddings is not None:
                final_similarity = (
                    0.6 * text_similarity +
                    0.3 * categorical_similarity +
                    0.1 * numerical_similarity
                )
            else:
                final_similarity = (
                    0.4 * text_similarity +
                    0.4 * categorical_similarity +
                    0.2 * numerical_similarity
                )
            
            similarities.append(final_similarity)
            similarity_details.append(details)
        
        return np.array(similarities), similarity_details

    def preprocess_query(self, query: Dict) -> Dict:
        """ê²€ìƒ‰ ì¿¼ë¦¬ ì „ì²˜ë¦¬"""
        processed_query = {}
        
        # í…ìŠ¤íŠ¸ í•„ë“œ ì²˜ë¦¬
        text_parts = []
        for field in ['ì‚¬ê³ ì„¤ëª…']:
            if field in query and query[field]:
                text_parts.append(str(query[field]))
        
        if text_parts:
            combined_text = ' '.join(text_parts)
            processed_query['combined_text'] = combined_text
            
            # KoSimCSE ì„ë² ë”© ìƒì„±
            if self.kosimcse_model is not None:
                query_embedding = self.encode_text_with_kosimcse([combined_text])
                if query_embedding is not None:
                    processed_query['text_embedding'] = query_embedding[0]
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        categorical_columns = [
            'íŒì •ì§„í–‰ìƒíƒœ', 'ì‚¬ê³ ì§„í–‰ìƒíƒœ', 'ìˆ˜ì¶œì', 'ìˆ˜ì…ì', 
            'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡í†µí™”', 'ê²°ì œê¸ˆì•¡í†µí™”', 'ì‚¬ê³ ê¸ˆì•¡í†µí™”', 
            'ì‚¬ê³ ìœ í˜•ëª…', 'ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©', 'ê²°ì œë°©ë²•', 
            'ê²°ì œë°©ë²•ì„¤ëª…', 'ê²°ì œì¡°ê±´', 'í–¥í›„ê²°ì œì „ë§', 'ìˆ˜ì…ìëª…',
            'íŒì •êµ¬ë¶„', 'íŒì •ì‚¬ìœ '
        ]
        
        for col in categorical_columns:
            if col in query and query[col]:
                if col in self.label_encoders:
                    try:
                        encoded_value = self.label_encoders[col].transform([str(query[col])])[0]
                        processed_query[f'{col}_encoded'] = encoded_value
                    except:
                        processed_query[f'{col}_encoded'] = -1
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì²˜ë¦¬
        numerical_features = []
        for col in ['ì‚¬ê³ ê¸ˆì•¡', 'ê²°ì œê¸ˆì•¡', 'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡', 'íŒì •ê¸ˆì•¡']:
            if col in query and query[col]:
                try:
                    value = float(query[col])
                    numerical_features.append(value)
                except:
                    numerical_features.append(0)
            else:
                numerical_features.append(0)
        
        if self.scaler is not None:
            numerical_features = self.scaler.transform([numerical_features])[0]
        
        processed_query['numerical_features'] = np.array(numerical_features)
        
        return processed_query

    def create_decision_process(self, case):
        """íŒì • ê³¼ì • ìƒì„¸ ì •ë³´ ìƒì„±"""
        process = []
        
        íŒì •_ì»¬ëŸ¼ë“¤ = ['íŒì •ì¼', 'íŒì •êµ¬ë¶„', 'íŒì •ì‚¬ìœ ', 'íŒì •ê¸ˆì•¡', 'íŒì •ì§„í–‰ìƒíƒœ', 'íŒì •íšŒì°¨']
        
        if all(col in case for col in íŒì •_ì»¬ëŸ¼ë“¤):
            íŒì •ì¼_list = case['íŒì •ì¼'] if isinstance(case['íŒì •ì¼'], list) else [case['íŒì •ì¼']]
            íŒì •êµ¬ë¶„_list = case['íŒì •êµ¬ë¶„'] if isinstance(case['íŒì •êµ¬ë¶„'], list) else [case['íŒì •êµ¬ë¶„']]
            íŒì •ì‚¬ìœ _list = case['íŒì •ì‚¬ìœ '] if isinstance(case['íŒì •ì‚¬ìœ '], list) else [case['íŒì •ì‚¬ìœ ']]
            íŒì •ê¸ˆì•¡_list = case['íŒì •ê¸ˆì•¡'] if isinstance(case['íŒì •ê¸ˆì•¡'], list) else [case['íŒì •ê¸ˆì•¡']]
            íŒì •ì§„í–‰ìƒíƒœ_list = case['íŒì •ì§„í–‰ìƒíƒœ'] if isinstance(case['íŒì •ì§„í–‰ìƒíƒœ'], list) else [case['íŒì •ì§„í–‰ìƒíƒœ']]
            íŒì •íšŒì°¨_list = case['íŒì •íšŒì°¨'] if isinstance(case['íŒì •íšŒì°¨'], list) else [case['íŒì •íšŒì°¨']]
            
            for i in range(len(íŒì •êµ¬ë¶„_list)):
                process.append({
                    'íšŒì°¨': íŒì •íšŒì°¨_list[i] if i < len(íŒì •íšŒì°¨_list) else i+1,
                    'ë‚ ì§œ': íŒì •ì¼_list[i] if i < len(íŒì •ì¼_list) else 'N/A',
                    'íŒì •êµ¬ë¶„': íŒì •êµ¬ë¶„_list[i] if i < len(íŒì •êµ¬ë¶„_list) else 'N/A',
                    'íŒì •ê¸ˆì•¡': íŒì •ê¸ˆì•¡_list[i] if i < len(íŒì •ê¸ˆì•¡_list) else 0,
                    'íŒì •ì‚¬ìœ ': íŒì •ì‚¬ìœ _list[i] if i < len(íŒì •ì‚¬ìœ _list) else 'N/A',
                    'ì§„í–‰ìƒíƒœ': íŒì •ì§„í–‰ìƒíƒœ_list[i] if i < len(íŒì •ì§„í–‰ìƒíƒœ_list) else 'N/A'
                })
        else:
            process.append({
                'íšŒì°¨': 1,
                'ë‚ ì§œ': 'N/A',
                'íŒì •êµ¬ë¶„': 'ì •ë³´ì—†ìŒ',
                'íŒì •ê¸ˆì•¡': 0,
                'íŒì •ì‚¬ìœ ': 'ì •ë³´ì—†ìŒ',
                'ì§„í–‰ìƒíƒœ': 'ì •ë³´ì—†ìŒ'
            })
        
        return process

    def print_detailed_result(self, result: Dict):
        """ìƒì„¸ ê²°ê³¼ ì¶œë ¥ (ìœ ì‚¬ë„ ê·¼ê±° í¬í•¨)"""
        print(f"\n{'='*80}")
        print(f"ğŸ† ìˆœìœ„: {result['rank']} (ì „ì²´ ìœ ì‚¬ë„: {result['similarity']:.3f})")
        print(f"ğŸ“‹ ì‚¬ê±´ ID: {result['case_id']}")
        
        # ìœ ì‚¬ë„ ìƒì„¸ ë¶„ì„
        details = result['similarity_details']
        print(f"\nğŸ“Š ìœ ì‚¬ë„ ë¶„ì„:")
        print(f"   ğŸ“ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„: {details['text_similarity']:.3f}")
        print(f"   ğŸ·ï¸  ë²”ì£¼í˜• ìœ ì‚¬ë„: {details['categorical_similarity']:.3f}")
        print(f"   ğŸ”¢ ìˆ˜ì¹˜í˜• ìœ ì‚¬ë„: {details['numerical_similarity']:.3f}")
        
        # ë²”ì£¼í˜• ë§¤ì¹­ ìƒì„¸
        if details['categorical_matches']:
            print(f"\nğŸ·ï¸  ë²”ì£¼í˜• í•„ë“œ ë§¤ì¹­:")
            for field, match in details['categorical_matches'].items():
                status = "âœ…" if match else "âŒ"
                print(f"   {status} {field}")
        
        # ì‚¬ê±´ ì •ë³´
        print(f"\nğŸ“‹ ì‚¬ê±´ ì •ë³´:")
        case_info = result['case_info']
        for key, value in case_info.items():
            if key == 'ì‚¬ê³ ì„¤ëª…':
                # ì‚¬ê³ ì„¤ëª…ì€ ê¸¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¼ë¶€ë§Œ í‘œì‹œ
                display_value = str(value)[:100] + "..." if len(str(value)) > 100 else value
                print(f"   - {key}: {display_value}")
            elif isinstance(value, (int, float)) and key.endswith('ê¸ˆì•¡'):
                print(f"   - {key}: {value:,.0f}")
            else:
                print(f"   - {key}: {value}")
        
        # íŒì • ê³¼ì •
        print(f"\nğŸ“‹ íŒì • ê³¼ì •:")
        for i, decision in enumerate(result['decision_process']):
            print(f"   {i+1}ì°¨ íŒì •:")
            print(f"     - ë‚ ì§œ: {decision['ë‚ ì§œ']}")
            print(f"     - íŒì •: {decision['íŒì •êµ¬ë¶„']}")
            print(f"     - ê¸ˆì•¡: {decision['íŒì •ê¸ˆì•¡']:,.0f}")
            print(f"     - ì‚¬ìœ : {decision['íŒì •ì‚¬ìœ ']}")
            print(f"     - ìƒíƒœ: {decision['ì§„í–‰ìƒíƒœ']}")
        
        print(f"{'='*80}")

    def get_available_options(self) -> Dict:
        """ë“œë¡­ë‹¤ìš´ ì˜µì…˜ë“¤ ë°˜í™˜"""
        options = {}
        
        for field in self.input_fields:
            if self.input_fields[field] == 'dropdown':
                if field in self.case_summary.columns:
                    options[field] = sorted(self.case_summary[field].dropna().unique().tolist())
        
        return options

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    print("ğŸš€ ìµœì í™”ëœ ì¢…í•© ìœ ì‚¬ë„ ê²€ìƒ‰ê¸° ì‹œì‘")
    
    # ê²€ìƒ‰ê¸° ì´ˆê¸°í™” (ì²« ì‹¤í–‰ì‹œ ì‹œê°„ì´ ê±¸ë¦¬ì§€ë§Œ, ë‘ ë²ˆì§¸ë¶€í„°ëŠ” ìºì‹œ ì‚¬ìš©)
    search_engine = OptimizedComprehensiveSimilaritySearch()
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ í™•ì¸
    options = search_engine.get_available_options()
    print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜:")
    for field, values in options.items():
        print(f"   {field}: {len(values)}ê°œ ì˜µì…˜")
    
    # ê²€ìƒ‰ ì˜ˆì‹œ
    query = {
        'ì‚¬ê³ ìœ í˜•ëª…': 'ì§€ê¸‰ê±°ì ˆ',
        'ìˆ˜ì…êµ­': 'ë¯¸êµ­',
        'ë³´í—˜ì¢…ëª©': 'ë‹¨ê¸°ìˆ˜ì¶œë³´í—˜',
        'ì‚¬ê³ ì„¤ëª…': 'ìˆ˜ì…ìê°€ ì§€ê¸‰ì„ ê±°ì ˆí•¨'
    }
    
    print(f"\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
    results = search_engine.search_similar_cases(query, top_k=3)
    
    # ê²°ê³¼ ì¶œë ¥
    for result in results:
        search_engine.print_detailed_result(result)