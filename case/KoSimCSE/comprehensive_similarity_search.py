import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import LabelEncoder, StandardScaler
import re
from datetime import datetime
import torch
from transformers import AutoTokenizer, AutoModel
import pickle
import os

class ComprehensiveSimilaritySearch:
    def __init__(self, data_path='data/testy.csv'):
        """
        ì¢…í•© ì‚¬ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ê¸° ì´ˆê¸°í™” (ëª¨ë“  íŠ¹ì„± ì‚¬ìš©)
        
        Args:
            data_path: í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        """
        self.data_path = data_path
        self.data = None
        self.case_summary = None
        self.label_encoders = {}
        self.scaler = None
        self.kosimcse_model = None
        self.kosimcse_tokenizer = None
        self.text_embeddings = None
        
        # ì„ë² ë”© ìºì‹œ íŒŒì¼ ê²½ë¡œ (í˜„ì¬ íŒŒì¼ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬)
        current_dir = os.path.dirname(os.path.abspath(__file__))
        self.embedding_cache_path = os.path.join(current_dir, 'comprehensive_embeddings_cache.pkl')
        
        # ì…ë ¥ í•„ë“œ ì •ì˜
        self.input_fields = {
            'ì‹ ì²­ëŒ€ìƒêµ¬ë¶„': 'dropdown',
            'ì‹ ì²­ì': 'text', 
            'ë³´í—˜ì¢…ëª©': 'dropdown',
            'ì‚¬ê³ ìœ í˜•ëª…': 'dropdown',
            'ìˆ˜ì¶œì': 'text',
            'ìˆ˜ì…êµ­': 'dropdown'
        }
        
        self.optional_fields = {
            'ì‚¬ê³ ê²½ìœ„': 'textarea',
            'ì‚¬ê³ ì„¤ëª…': 'textarea'
        }
        
        # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        self.load_and_preprocess_data()
    
 

    def load_kosimcse_model(self):
        """KoSimCSE ëª¨ë¸ ë¡œë“œ"""
        print("ğŸ¤– KoSimCSE ëª¨ë¸ ë¡œë“œ ì¤‘...")
        try:
            # KoSimCSE ëª¨ë¸ ê²½ë¡œ (Hugging Face ëª¨ë¸ ì‚¬ìš©)
            model_path = 'BM-K/KoSimCSE-roberta'
            
            self.kosimcse_tokenizer = AutoTokenizer.from_pretrained(model_path)
            self.kosimcse_model = AutoModel.from_pretrained(model_path)
            print("âœ… KoSimCSE ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                
        except Exception as e:
            print(f"âš ï¸ KoSimCSE ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            print("âš ï¸ KoSimCSE ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.kosimcse_model = None
            self.kosimcse_tokenizer = None
    
    def encode_text_with_kosimcse(self, texts):
        """KoSimCSEë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        if self.kosimcse_model is None or self.kosimcse_tokenizer is None:
            return None
        
        try:
            # ë°°ì¹˜ í¬ê¸° ì„¤ì •
            batch_size = 32
            embeddings = []
            
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i+batch_size]
                
                # í† í¬ë‚˜ì´ì§•
                inputs = self.kosimcse_tokenizer(
                    batch_texts,
                    padding=True,
                    truncation=True,
                    max_length=512,
                    return_tensors="pt"
                )
                
                # ì„ë² ë”© ìƒì„±
                with torch.no_grad():
                    outputs = self.kosimcse_model(**inputs)
                    # [CLS] í† í°ì˜ ì„ë² ë”© ì‚¬ìš©
                    batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()
                    embeddings.extend(batch_embeddings)
            
            return np.array(embeddings)
            
        except Exception as e:
            print(f"âš ï¸ KoSimCSE ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return None
    
    def load_and_preprocess_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        try:
            # testy.csv íŒŒì¼ ë¡œë“œ (cp949 ì¸ì½”ë”©)
            self.data = pd.read_csv(self.data_path, encoding='cp949')
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.data)}ê°œ ë ˆì½”ë“œ")
            
            # KoSimCSE ëª¨ë¸ ë¡œë“œ
            self.load_kosimcse_model()
            
            # ì‚¬ë¡€ ìš”ì•½ ìƒì„±
            self.create_case_summary()
            
            # íŠ¹ì„± ì „ì²˜ë¦¬
            self.preprocess_features()
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def create_case_summary(self):
        """ì‚¬ê±´ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì‚¬ë¡€ ìš”ì•½ ìƒì„±"""
        print("ğŸ“‹ ì‚¬ë¡€ ìš”ì•½ ìƒì„± ì¤‘...")
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸
        required_columns = ['ë³´ìƒíŒŒì¼ë²ˆí˜¸', 'ì‚¬ê³ ë²ˆí˜¸']
        available_columns = [col for col in required_columns if col in self.data.columns]
        
        if len(available_columns) < 2:
            print("âš ï¸ ë³´ìƒíŒŒì¼ë²ˆí˜¸ ë˜ëŠ” ì‚¬ê³ ë²ˆí˜¸ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.case_summary = self.data.copy()
            return
        
        # ì‚¬ê±´ë³„ ê·¸ë£¹í™” (ë³´ìƒíŒŒì¼ë²ˆí˜¸ + ì‚¬ê³ ë²ˆí˜¸)
        case_groups = self.data.groupby(['ë³´ìƒíŒŒì¼ë²ˆí˜¸', 'ì‚¬ê³ ë²ˆí˜¸'])
        
        case_summaries = []
        for (ë³´ìƒíŒŒì¼ë²ˆí˜¸, ì‚¬ê³ ë²ˆí˜¸), group in case_groups:
            case_summary = {
                'ë³´ìƒíŒŒì¼ë²ˆí˜¸': ë³´ìƒíŒŒì¼ë²ˆí˜¸,
                'ì‚¬ê³ ë²ˆí˜¸': ì‚¬ê³ ë²ˆí˜¸
            }
            
            # ë‹¨ì¼ ê°’ ì»¬ëŸ¼ë“¤ (ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©)
            single_value_columns = [
                'ì‚¬ê³ ì ‘ìˆ˜ì¼ì', 'ì‚¬ê³ ìœ í˜•ëª…', 'ìˆ˜ì…êµ­', 'ìˆ˜ì¶œì', 'ë³´í—˜ì¢…ëª©',
                'ì‚¬ê³ ê¸ˆì•¡', 'ê²°ì œê¸ˆì•¡', 'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡', 'ì‚¬ê³ ì„¤ëª…', 'ìˆ˜ì…ìëª…'
            ]
            
            for col in single_value_columns:
                if col in group.columns:
                    case_summary[col] = group[col].iloc[0] if not group[col].isna().all() else None
            
            # ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥í•  ì»¬ëŸ¼ë“¤ (ëª¨ë“  íŒì • ì •ë³´)
            list_columns = [
                'íŒì •ì¼', 'íŒì •ê²°ì¬ì¼', 'íŒì •ì§„í–‰ìƒíƒœ', 'ì‚¬ê³ ì§„í–‰ìƒíƒœ',
                'íŒì •êµ¬ë¶„', 'íŒì •ê¸ˆì•¡', 'íŒì •ì‚¬ìœ ', 'íŒì •íšŒì°¨',
                'ê²°ì œë°©ë²•', 'ê²°ì œë°©ë²•ì„¤ëª…', 'ê²°ì œì¡°ê±´', 'í–¥í›„ê²°ì œì „ë§',
                'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡í†µí™”', 'ê²°ì œê¸ˆì•¡í†µí™”', 'ì‚¬ê³ ê¸ˆì•¡í†µí™”', 'íŒì •ê¸ˆì•¡í†µí™”'
            ]
            
            for col in list_columns:
                if col in group.columns:
                    values = group[col].dropna().unique().tolist()
                    case_summary[col] = values if values else []
            
            case_summaries.append(case_summary)

        self.case_summary = pd.DataFrame(case_summaries)
        print(f"âœ… ì‚¬ë¡€ ìš”ì•½ ìƒì„± ì™„ë£Œ: {len(self.case_summary)}ê°œ ì‚¬ë¡€")
    
    def analyze_decision_patterns(self, case_group):
        """íŒì • íŒ¨í„´ ë¶„ì„"""
        if 'íŒì •êµ¬ë¶„' not in case_group.columns:
            return {'íŒ¨í„´': 'ì •ë³´ì—†ìŒ', 'ìš”ì•½': 'íŒì • ì •ë³´ ì—†ìŒ'}
        
        íŒì •êµ¬ë¶„ë“¤ = case_group['íŒì •êµ¬ë¶„'].dropna().tolist()
        
        if not íŒì •êµ¬ë¶„ë“¤:
            return {'íŒ¨í„´': 'ì •ë³´ì—†ìŒ', 'ìš”ì•½': 'íŒì • ì •ë³´ ì—†ìŒ'}
        
        # íŒ¨í„´ ë¶„ì„
        unique_íŒì •êµ¬ë¶„ = list(set(íŒì •êµ¬ë¶„ë“¤))
        
        if len(unique_íŒì •êµ¬ë¶„) == 1:
            íŒ¨í„´ = f"ë‹¨ì¼ íŒì •: {unique_íŒì •êµ¬ë¶„[0]}"
        else:
            íŒ¨í„´ = f"ë³µí•© íŒì •: {' â†’ '.join(unique_íŒì •êµ¬ë¶„)}"
        
        # ìš”ì•½ ìƒì„±
        íŒì •_ë¹ˆë„ = {}
        for íŒì • in íŒì •êµ¬ë¶„ë“¤:
            íŒì •_ë¹ˆë„[íŒì •] = íŒì •_ë¹ˆë„.get(íŒì •, 0) + 1
        
        ìš”ì•½ = ", ".join([f"{íŒì •}({ë¹ˆë„}íšŒ)" for íŒì •, ë¹ˆë„ in íŒì •_ë¹ˆë„.items()])
        
        return {'íŒ¨í„´': íŒ¨í„´, 'ìš”ì•½': ìš”ì•½}
    
    def preprocess_features(self):
        """í…ìŠ¤íŠ¸ ë° ë²”ì£¼í˜• ë³€ìˆ˜ ì „ì²˜ë¦¬ (ëª¨ë“  íŠ¹ì„± ì‚¬ìš©)"""
        print("ğŸ”§ íŠ¹ì„± ì „ì²˜ë¦¬ ì¤‘...")
        
        # í…ìŠ¤íŠ¸ í•„ë“œ ê²°í•© (ëª¨ë“  í…ìŠ¤íŠ¸ ì •ë³´ í¬í•¨)
        text_columns = []
        for col in ['ì‚¬ê³ ì„¤ëª…']:
            if col in self.case_summary.columns:
                text_columns.append(col)
        
        if text_columns:
            self.case_summary['combined_text'] = self.case_summary[text_columns].fillna('').agg(' '.join, axis=1)
        else:
            self.case_summary['combined_text'] = ''
        
        # KoSimCSE ì„ë² ë”© ìƒì„±
        if self.kosimcse_model is not None and 'combined_text' in self.case_summary.columns:
            print("ğŸ¤– KoSimCSE ì„ë² ë”© ìƒì„± ì¤‘...")
            texts = self.case_summary['combined_text'].fillna('').tolist()
            self.text_embeddings = self.encode_text_with_kosimcse(texts)
            
            if self.text_embeddings is not None:
                print(f"âœ… KoSimCSE ì„ë² ë”© ìƒì„± ì™„ë£Œ: {self.text_embeddings.shape}")
            else:
                print("âš ï¸ KoSimCSE ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”© (ì‚¬ìš©ìê°€ ìš”ì²­í•œ ëª¨ë“  íŠ¹ì„± í¬í•¨)
        categorical_columns = [
            'íŒì •ì§„í–‰ìƒíƒœ', 'ì‚¬ê³ ì§„í–‰ìƒíƒœ', 'ìˆ˜ì¶œì', 'ìˆ˜ì…ì', 
            'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡í†µí™”', 'ê²°ì œê¸ˆì•¡í†µí™”', 'ì‚¬ê³ ê¸ˆì•¡í†µí™”', 
            'ì‚¬ê³ ìœ í˜•ëª…', 'ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©', 'ê²°ì œë°©ë²•', 
            'ê²°ì œë°©ë²•ì„¤ëª…', 'ê²°ì œì¡°ê±´', 'í–¥í›„ê²°ì œì „ë§', 'ìˆ˜ì…ìëª…',
            'íŒì •êµ¬ë¶„', 'íŒì •ì‚¬ìœ '  # ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì¶”ê°€ íŠ¹ì„±
        ]
        
        for col in categorical_columns:
            if col in self.case_summary.columns:
                # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ì»¬ëŸ¼ì€ ì²« ë²ˆì§¸ ê°’ë§Œ ì‚¬ìš©
                if self.case_summary[col].apply(lambda x: isinstance(x, list)).any():
                    # ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ê°’ ë˜ëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° None
                    values = self.case_summary[col].apply(
                        lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None
                    )
                else:
                    values = self.case_summary[col]
                
                le = LabelEncoder()
                self.case_summary[f'{col}_encoded'] = le.fit_transform(
                    values.astype(str)
                )
                self.label_encoders[col] = le
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ (ëª¨ë“  ìˆ˜ì¹˜í˜• íŠ¹ì„± í¬í•¨)
        numerical_columns = []
        for col in ['ì‚¬ê³ ê¸ˆì•¡', 'ê²°ì œê¸ˆì•¡', 'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡', 'íŒì •ê¸ˆì•¡']:
            if col in self.case_summary.columns:
                # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ì»¬ëŸ¼ì€ ì²« ë²ˆì§¸ ê°’ë§Œ ì‚¬ìš©
                if self.case_summary[col].apply(lambda x: isinstance(x, list)).any():
                    values = self.case_summary[col].apply(
                        lambda x: x[0] if isinstance(x, list) and len(x) > 0 else 0
                    )
                else:
                    values = self.case_summary[col]
                
                self.case_summary[col] = values
                numerical_columns.append(col)
        
        if numerical_columns:
            self.scaler = StandardScaler()
            self.case_summary[numerical_columns] = self.scaler.fit_transform(
                self.case_summary[numerical_columns].fillna(0)
            )
        
        print("âœ… íŠ¹ì„± ì „ì²˜ë¦¬ ì™„ë£Œ")
    
    def get_available_options(self):
        """ë“œë¡­ë‹¤ìš´ ì˜µì…˜ë“¤ ë°˜í™˜"""
        options = {}
        
        for field in self.input_fields:
            if self.input_fields[field] == 'dropdown':
                if field in self.case_summary.columns:
                    options[field] = sorted(self.case_summary[field].dropna().unique().tolist())
        
        return options
    
    def search_similar_cases(self, query, top_k=5, verbose=True):
        """
        ìœ ì‚¬í•œ ì‚¬ê³  ì‚¬ë¡€ ê²€ìƒ‰ (ëª¨ë“  íŠ¹ì„± ì‚¬ìš©)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (ë”•ì…”ë„ˆë¦¬)
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜
            verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
        
        Returns:
            ìœ ì‚¬í•œ ì‚¬ë¡€ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """
        if verbose:
            print(f"ğŸ” ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ ì¤‘... (ìƒìœ„ {top_k}ê°œ)")
            print(f"ğŸ“ ê²€ìƒ‰ ì…ë ¥: {list(query.keys())}")
        
        # ì¿¼ë¦¬ ì „ì²˜ë¦¬
        processed_query = self.preprocess_query(query)
        
        # ìœ ì‚¬ë„ ê³„ì‚° (ëª¨ë“  íŠ¹ì„± ì‚¬ìš©)
        similarities = self.calculate_similarity(processed_query)
        
        # ìƒìœ„ kê°œ ì„ íƒ
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        results = []
        for i, idx in enumerate(top_indices):
            case = self.case_summary.iloc[idx]
            similarity = similarities[idx]
            
            # ìƒì„¸ íŒì • ê³¼ì • êµ¬ì„±
            decision_process = self.create_decision_process(case)
            
            result = {
                'rank': i + 1,
                'similarity': float(similarity),
                'case_id': f"{case['ë³´ìƒíŒŒì¼ë²ˆí˜¸']}_{case['ì‚¬ê³ ë²ˆí˜¸']}",
                'case_info': {
                    'ì‚¬ê³ ì ‘ìˆ˜ì¼ì': case.get('ì‚¬ê³ ì ‘ìˆ˜ì¼ì', 'N/A'),
                    'ì‚¬ê³ ìœ í˜•ëª…': case.get('ì‚¬ê³ ìœ í˜•ëª…', 'N/A'),
                    'ìˆ˜ì…êµ­': case.get('ìˆ˜ì…êµ­', 'N/A'),
                    'ìˆ˜ì¶œì': case.get('ìˆ˜ì¶œì', 'N/A'),
                    'ë³´í—˜ì¢…ëª©': case.get('ë³´í—˜ì¢…ëª©', 'N/A'),
                    'ì‚¬ê³ ê¸ˆì•¡': case.get('ì‚¬ê³ ê¸ˆì•¡', 0),
                    'ê²°ì œê¸ˆì•¡': case.get('ê²°ì œê¸ˆì•¡', 0),
                    'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡': case.get('ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡', 0),
                    'íŒì •ê¸ˆì•¡': case.get('íŒì •ê¸ˆì•¡', 0)
                },
                'decision_process': decision_process
            }
            
            results.append(result)
        
        if verbose:
            print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
        
        return results
    
    def preprocess_query(self, query):
        """ê²€ìƒ‰ ì¿¼ë¦¬ ì „ì²˜ë¦¬"""
        processed_query = {}
        
        # í…ìŠ¤íŠ¸ í•„ë“œ ì²˜ë¦¬
        text_parts = []
        for field in ['ì‚¬ê³ ì„¤ëª…']:
            if field in query and query[field]:
                text_parts.append(str(query[field]))
        
        if text_parts:
            combined_text = ' '.join(text_parts)
            processed_query['combined_text'] = combined_text
            
            # KoSimCSE ì„ë² ë”© ìƒì„±
            if self.kosimcse_model is not None:
                query_embedding = self.encode_text_with_kosimcse([combined_text])
                if query_embedding is not None:
                    processed_query['text_embedding'] = query_embedding[0]
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        categorical_columns = [
            'íŒì •ì§„í–‰ìƒíƒœ', 'ì‚¬ê³ ì§„í–‰ìƒíƒœ', 'ìˆ˜ì¶œì', 'ìˆ˜ì…ì', 
            'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡í†µí™”', 'ê²°ì œê¸ˆì•¡í†µí™”', 'ì‚¬ê³ ê¸ˆì•¡í†µí™”', 
            'ì‚¬ê³ ìœ í˜•ëª…', 'ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©', 'ê²°ì œë°©ë²•', 
            'ê²°ì œë°©ë²•ì„¤ëª…', 'ê²°ì œì¡°ê±´', 'í–¥í›„ê²°ì œì „ë§', 'ìˆ˜ì…ìëª…',
            'íŒì •êµ¬ë¶„', 'íŒì •ì‚¬ìœ '
        ]
        
        for col in categorical_columns:
            if col in query and query[col]:
                if col in self.label_encoders:
                    try:
                        encoded_value = self.label_encoders[col].transform([str(query[col])])[0]
                        processed_query[f'{col}_encoded'] = encoded_value
                    except:
                        processed_query[f'{col}_encoded'] = -1
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì²˜ë¦¬
        numerical_features = []
        for col in ['ì‚¬ê³ ê¸ˆì•¡', 'ê²°ì œê¸ˆì•¡', 'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡', 'íŒì •ê¸ˆì•¡']:
            if col in query and query[col]:
                try:
                    value = float(query[col])
                    numerical_features.append(value)
                except:
                    numerical_features.append(0)
            else:
                numerical_features.append(0)
        
        if self.scaler is not None:
            numerical_features = self.scaler.transform([numerical_features])[0]
        
        processed_query['numerical_features'] = np.array(numerical_features)
        
        return processed_query
    
    def calculate_similarity(self, processed_query):
        """ìœ ì‚¬ë„ ê³„ì‚° (ëª¨ë“  íŠ¹ì„± ì‚¬ìš©)"""
        similarities = []
        
        for idx, case in self.case_summary.iterrows():
            # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ (KoSimCSE ì‚¬ìš©)
            text_similarity = 0
            if 'text_embedding' in processed_query and self.text_embeddings is not None:
                query_embedding = processed_query['text_embedding']
                case_embedding = self.text_embeddings[idx]
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = cosine_similarity([query_embedding], [case_embedding])[0][0]
                text_similarity = max(0, similarity)  # ìŒìˆ˜ ê°’ ë°©ì§€
            elif 'combined_text' in processed_query and processed_query['combined_text']:
                # KoSimCSEê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
                query_text = processed_query['combined_text']
                case_text = case.get('combined_text', '')
                
                # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„
                query_words = set(query_text.lower().split())
                case_words = set(case_text.lower().split())
                
                if query_words and case_words:
                    intersection = query_words.intersection(case_words)
                    union = query_words.union(case_words)
                    text_similarity = len(intersection) / len(union) if union else 0
            
            # ë²”ì£¼í˜• ë³€ìˆ˜ ìœ ì‚¬ë„ (ëª¨ë“  ë²”ì£¼í˜• íŠ¹ì„± ì‚¬ìš©)
            categorical_similarity = 0
            categorical_matches = 0
            total_categorical = 0
            
            categorical_columns = [
                'íŒì •ì§„í–‰ìƒíƒœ', 'ì‚¬ê³ ì§„í–‰ìƒíƒœ', 'ìˆ˜ì¶œì', 'ìˆ˜ì…ì', 
                'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡í†µí™”', 'ê²°ì œê¸ˆì•¡í†µí™”', 'ì‚¬ê³ ê¸ˆì•¡í†µí™”', 
                'ì‚¬ê³ ìœ í˜•ëª…', 'ìˆ˜ì…êµ­', 'ë³´í—˜ì¢…ëª©', 'ê²°ì œë°©ë²•', 
                'ê²°ì œë°©ë²•ì„¤ëª…', 'ê²°ì œì¡°ê±´', 'í–¥í›„ê²°ì œì „ë§', 'ìˆ˜ì…ìëª…',
                'íŒì •êµ¬ë¶„', 'íŒì •ì‚¬ìœ '
            ]
            
            for field in categorical_columns:
                if f'{field}_encoded' in processed_query:
                    total_categorical += 1
                    if processed_query[f'{field}_encoded'] == case.get(f'{field}_encoded', -1):
                        categorical_matches += 1
            
            if total_categorical > 0:
                categorical_similarity = categorical_matches / total_categorical
            
            # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìœ ì‚¬ë„ (ëª¨ë“  ìˆ˜ì¹˜í˜• íŠ¹ì„± ì‚¬ìš©)
            numerical_similarity = 0
            if 'numerical_features' in processed_query:
                query_numerical = processed_query['numerical_features']
                case_numerical = []
                
                for col in ['ì‚¬ê³ ê¸ˆì•¡', 'ê²°ì œê¸ˆì•¡', 'ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡', 'íŒì •ê¸ˆì•¡']:
                    case_numerical.append(case.get(col, 0))
                
                # ìœ í´ë¦¬ë“œ ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                distance = np.sqrt(np.sum((query_numerical - case_numerical) ** 2))
                numerical_similarity = 1 / (1 + distance)
            
            # ê°€ì¤‘ í‰ê·  (KoSimCSEê°€ ìˆìœ¼ë©´ í…ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ì¦ê°€)
            if self.text_embeddings is not None:
                final_similarity = (
                    0.6 * text_similarity +  # KoSimCSE ì‚¬ìš©ì‹œ í…ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ì¦ê°€
                    0.3 * categorical_similarity +
                    0.1 * numerical_similarity
                )
            else:
                final_similarity = (
                    0.4 * text_similarity +
                    0.4 * categorical_similarity +
                    0.2 * numerical_similarity
                )
            
            similarities.append(final_similarity)
        
        return np.array(similarities)
    
    def create_decision_process(self, case):
        """íŒì • ê³¼ì • ìƒì„¸ ì •ë³´ ìƒì„±"""
        process = []
        
        # íŒì • ê´€ë ¨ ì»¬ëŸ¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸
        íŒì •_ì»¬ëŸ¼ë“¤ = ['íŒì •ì¼', 'íŒì •êµ¬ë¶„', 'íŒì •ì‚¬ìœ ', 'íŒì •ê¸ˆì•¡', 'íŒì •ì§„í–‰ìƒíƒœ', 'íŒì •íšŒì°¨']
        
        if all(col in case for col in íŒì •_ì»¬ëŸ¼ë“¤):
            íŒì •ì¼_list = case['íŒì •ì¼'] if isinstance(case['íŒì •ì¼'], list) else [case['íŒì •ì¼']]
            íŒì •êµ¬ë¶„_list = case['íŒì •êµ¬ë¶„'] if isinstance(case['íŒì •êµ¬ë¶„'], list) else [case['íŒì •êµ¬ë¶„']]
            íŒì •ì‚¬ìœ _list = case['íŒì •ì‚¬ìœ '] if isinstance(case['íŒì •ì‚¬ìœ '], list) else [case['íŒì •ì‚¬ìœ ']]
            íŒì •ê¸ˆì•¡_list = case['íŒì •ê¸ˆì•¡'] if isinstance(case['íŒì •ê¸ˆì•¡'], list) else [case['íŒì •ê¸ˆì•¡']]
            íŒì •ì§„í–‰ìƒíƒœ_list = case['íŒì •ì§„í–‰ìƒíƒœ'] if isinstance(case['íŒì •ì§„í–‰ìƒíƒœ'], list) else [case['íŒì •ì§„í–‰ìƒíƒœ']]
            íŒì •íšŒì°¨_list = case['íŒì •íšŒì°¨'] if isinstance(case['íŒì •íšŒì°¨'], list) else [case['íŒì •íšŒì°¨']]
            
            for i in range(len(íŒì •êµ¬ë¶„_list)):
                process.append({
                    'íšŒì°¨': íŒì •íšŒì°¨_list[i] if i < len(íŒì •íšŒì°¨_list) else i+1,
                    'ë‚ ì§œ': íŒì •ì¼_list[i] if i < len(íŒì •ì¼_list) else 'N/A',
                    'íŒì •êµ¬ë¶„': íŒì •êµ¬ë¶„_list[i] if i < len(íŒì •êµ¬ë¶„_list) else 'N/A',
                    'íŒì •ê¸ˆì•¡': íŒì •ê¸ˆì•¡_list[i] if i < len(íŒì •ê¸ˆì•¡_list) else 0,
                    'íŒì •ì‚¬ìœ ': íŒì •ì‚¬ìœ _list[i] if i < len(íŒì •ì‚¬ìœ _list) else 'N/A',
                    'ì§„í–‰ìƒíƒœ': íŒì •ì§„í–‰ìƒíƒœ_list[i] if i < len(íŒì •ì§„í–‰ìƒíƒœ_list) else 'N/A'
                })
        else:
            # íŒì • ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
            process.append({
                'íšŒì°¨': 1,
                'ë‚ ì§œ': 'N/A',
                'íŒì •êµ¬ë¶„': 'ì •ë³´ì—†ìŒ',
                'íŒì •ê¸ˆì•¡': 0,
                'íŒì •ì‚¬ìœ ': 'ì •ë³´ì—†ìŒ',
                'ì§„í–‰ìƒíƒœ': 'ì •ë³´ì—†ìŒ'
            })
        
        return process
    
    def print_case_result(self, result):
        """ì‚¬ë¡€ ê²°ê³¼ ì¶œë ¥"""
        print(f"\n{'='*60}")
        print(f"ğŸ† ìˆœìœ„: {result['rank']} (ìœ ì‚¬ë„: {result['similarity']:.3f})")
        print(f"ğŸ“‹ ì‚¬ê±´ ID: {result['case_id']}")
        
        print(f"ğŸ“ íŒì • ìš”ì•½: {result['íŒì •ìš”ì•½']}")
        print(f"ğŸ”„ íŒì • íšŸìˆ˜: {result['íŒì •íšŸìˆ˜']}íšŒ")
        
        print(f"\nğŸ“‹ ì‚¬ê±´ ì •ë³´:")
        case_info = result['case_info']
        print(f"   - ì‚¬ê³ ì ‘ìˆ˜ì¼ì: {case_info['ì‚¬ê³ ì ‘ìˆ˜ì¼ì']}")
        print(f"   - ì‚¬ê³ ìœ í˜•: {case_info['ì‚¬ê³ ìœ í˜•ëª…']}")
        print(f"   - ìˆ˜ì…êµ­: {case_info['ìˆ˜ì…êµ­']}")
        print(f"   - ìˆ˜ì¶œì: {case_info['ìˆ˜ì¶œì']}")
        print(f"   - ë³´í—˜ì¢…ëª©: {case_info['ë³´í—˜ì¢…ëª©']}")
        print(f"   - ì‚¬ê³ ê¸ˆì•¡: {case_info['ì‚¬ê³ ê¸ˆì•¡']:,.0f}")
        print(f"   - ê²°ì œê¸ˆì•¡: {case_info['ê²°ì œê¸ˆì•¡']:,.0f}")
        print(f"   - ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡: {case_info['ìˆ˜ì¶œë³´ì¦ê¸ˆì•¡']:,.0f}")
        print(f"   - íŒì •ê¸ˆì•¡: {case_info['íŒì •ê¸ˆì•¡']:,.0f}")
        
        print(f"\nğŸ“‹ íŒì • ê³¼ì •:")
        for i, decision in enumerate(result['decision_process']):
            print(f"   {i+1}ì°¨ íŒì •:")
            print(f"     - ë‚ ì§œ: {decision['ë‚ ì§œ']}")
            print(f"     - íŒì •: {decision['íŒì •êµ¬ë¶„']}")
            print(f"     - ê¸ˆì•¡: {decision['íŒì •ê¸ˆì•¡']:,.0f}")
            print(f"     - ì‚¬ìœ : {decision['íŒì •ì‚¬ìœ ']}")
            print(f"     - ìƒíƒœ: {decision['ì§„í–‰ìƒíƒœ']}")
        
        print(f"{'='*60}")

    def save_embeddings_cache(self):
        """KoSimCSE ì„ë² ë”©ì„ ìºì‹œ íŒŒì¼ì— ì €ì¥"""
        if self.text_embeddings is not None:
            try:
                cache_data = {
                    'embeddings': self.text_embeddings,
                    'data_hash': hash(str(self.case_summary['combined_text'].tolist()))
                }
                with open(self.embedding_cache_path, 'wb') as f:
                    pickle.dump(cache_data, f)
                print(f"ğŸ’¾ ì„ë² ë”© ìºì‹œ ì €ì¥ ì™„ë£Œ: {self.embedding_cache_path}")
            except Exception as e:
                print(f"âš ï¸ ì„ë² ë”© ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def load_embeddings_cache(self):
        """KoSimCSE ì„ë² ë”© ìºì‹œ íŒŒì¼ì—ì„œ ë¡œë“œ"""
        try:
            if os.path.exists(self.embedding_cache_path):
                with open(self.embedding_cache_path, 'rb') as f:
                    cache_data = pickle.load(f)
                
                # ìºì‹œ ë°ì´í„° êµ¬ì¡° í™•ì¸
                if 'embeddings' in cache_data and 'data_hash' in cache_data:
                    # ë°ì´í„° í•´ì‹œ í™•ì¸ (ë°ì´í„°ê°€ ë³€ê²½ë˜ì—ˆëŠ”ì§€ ì²´í¬)
                    if 'combined_text' in self.case_summary.columns:
                        current_hash = hash(str(self.case_summary['combined_text'].tolist()))
                        if cache_data['data_hash'] == current_hash:
                            self.text_embeddings = cache_data['embeddings']
                            print(f"ğŸ“‚ ì„ë² ë”© ìºì‹œ ë¡œë“œ ì™„ë£Œ: {self.text_embeddings.shape}")
                            return True
                        else:
                            print("âš ï¸ ë°ì´í„°ê°€ ë³€ê²½ë˜ì–´ ìºì‹œë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤.")
                            return False
                    else:
                        print("âš ï¸ combined_text ì»¬ëŸ¼ì´ ì—†ì–´ ìºì‹œë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤.")
                        return False
                else:
                    print("âš ï¸ ìºì‹œ íŒŒì¼ êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    return False
        except Exception as e:
            print(f"âš ï¸ ì„ë² ë”© ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
    search_engine = ComprehensiveSimilaritySearch()
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ í™•ì¸
    options = search_engine.get_available_options()
    print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜:")
    for field, values in options.items():
        print(f"   {field}: {len(values)}ê°œ ì˜µì…˜")
    
    # ê²€ìƒ‰ ì˜ˆì‹œ
    query = {
        'ì‚¬ê³ ìœ í˜•ëª…': 'ì§€ê¸‰ê±°ì ˆ',
        'ìˆ˜ì…êµ­': 'ë¯¸êµ­',
        'ë³´í—˜ì¢…ëª©': 'ë‹¨ê¸°ìˆ˜ì¶œë³´í—˜',
        'ì‚¬ê³ ì„¤ëª…': 'ìˆ˜ì…ìê°€ ì§€ê¸‰ì„ ê±°ì ˆí•¨'
    }
    
    results = search_engine.search_similar_cases(query, top_k=3)
    
    # ê²°ê³¼ ì¶œë ¥
    for result in results:
        search_engine.print_case_result(result) 